<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>EnsembleKalmanSchemes · DataAssimilationBenchmarks</title><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">DataAssimilationBenchmarks</a></span></div><form class="docs-search" action="../../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><span class="tocitem">DataAssimilationBenchmarks</span><ul><li><a class="tocitem" href="../../../home/Introduction/">Introduction</a></li><li><a class="tocitem" href="../../../home/Getting Started/">Getting Started</a></li><li><a class="tocitem" href="../../../home/DataAssimilationBenchmarks/">Global Types</a></li></ul></li><li><span class="tocitem">Submodules</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox"/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">Models</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../models/L96/">L96</a></li><li><a class="tocitem" href="../../models/IEEE39bus/">IEEE39bus</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox" checked/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../DeSolvers/">DeSolvers</a></li><li class="is-active"><a class="tocitem" href>EnsembleKalmanSchemes</a><ul class="internal"><li><a class="tocitem" href="#API-for-data-assimilation-solvers"><span>API for data assimilation solvers</span></a></li><li><a class="tocitem" href="#Methods"><span>Methods</span></a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Experiments</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../experiments/GenerateTimeSeries/">GenerateTimeSeries</a></li><li><a class="tocitem" href="../../experiments/FilterExps/">FilterExps</a></li><li><a class="tocitem" href="../../experiments/SmootherExps/">SmootherExps</a></li><li><a class="tocitem" href="../../experiments/SingleExperimentDriver/">SingleExperimentDriver</a></li><li><a class="tocitem" href="../../experiments/Slurm/">Slurm</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Analysis</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../analysis/ProcessExperimentData/">ProcessExperimentData</a></li><li><a class="tocitem" href="../../analysis/PlotExperimentData/">PlotExperimentData</a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Submodules</a></li><li><a class="is-disabled">Methods</a></li><li class="is-active"><a href>EnsembleKalmanSchemes</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>EnsembleKalmanSchemes</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/cgrudz/DataAssimilationBenchmarks.jl/blob/master/docs/src/submodules/methods/EnsembleKalmanSchemes.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Ensemble-Kalman-Schemes"><a class="docs-heading-anchor" href="#Ensemble-Kalman-Schemes">Ensemble Kalman Schemes</a><a id="Ensemble-Kalman-Schemes-1"></a><a class="docs-heading-anchor-permalink" href="#Ensemble-Kalman-Schemes" title="Permalink"></a></h1><h2 id="API-for-data-assimilation-solvers"><a class="docs-heading-anchor" href="#API-for-data-assimilation-solvers">API for data assimilation solvers</a><a id="API-for-data-assimilation-solvers-1"></a><a class="docs-heading-anchor-permalink" href="#API-for-data-assimilation-solvers" title="Permalink"></a></h2><p>There are currently four families of data assimilation solvers available in this package, which define the outer-loop of the data assimilation cycle.  Particularly, these define how the sequential data assimilation cycle will pass over a time series of observations.  Ensemble filters run only forward-in-time.  The classic lag-shift smoother runs identically to the filter in its forecast and filter steps, but includes an additional retrospective analysis to past ensemble states stored in memory.  The single iteration smoother follows the same convention as the classic smoother, except in that new cycles are initiated from a past, reanlyzed ensemble state.  The Gauss-Newton iterative smoothers are 4D smoothers, which iteratively optimize the initial condition at the beginning of a data assimilation cycle, and propagate this initial condition to initialize the subsequent cycle.  A full discussion of these methods can be found in <a href="https://gmd.copernicus.org/preprints/gmd-2021-306/">Grudzien, et al. 2021</a>.</p><p>For each outer-loop method defining the data assimilation cycle, different types of analyses can be specified within their arguments.  Likewise, these outer-loop methods require arguments such as the ensemble state or the range of ensemble states to analyze, an observation to assimilate or a range of observations to assimilate, as the observation error covariances, the ensemble covariance inflation parameter and key word arguments for running the underlying dynamical state model. Examples of the syntax are below:</p><pre><code class="language- hljs">ensemble_filter(analysis::String, ens::ArView(T), obs::VecA(T), obs_cov::CovM(T),
    state_infl::Float64, kwargs::StepKwargs) where T &lt;: Float64

ls_smoother_classic(analysis::String, ens::ArView(T), obs::ArView(T), obs_cov::CovM(T),
    state_infl::Float64, kwargs::StepKwargs) where T &lt;: Float64

ls_smoother_single_iteration(analysis::String, ens::ArView(T), obs::ArView(T),
    obs_cov::CovM(T), state_infl::Float64, kwargs::StepKwargs) where T &lt;: Float64

ls_smoother_gauss_newton(analysis::String, ens::ArView(T), obs::ArView(T), obs_cov::CovM(T),
    state_infl::Float64, kwargs::StepKwargs; ϵ::Float64=0.0001, tol::Float64=0.001,
		max_iter::Int64=10) where T &lt;: Float64


&quot;&quot;&quot;
analysis   -- string name analysis scheme given to the transform sub-routine
ens        -- ensemble matrix defined by the array with columns given by the replicates of
              the model state
obs        -- observation vector for the current analysis in ensemble_filter / array with
              columns given by the observation vectors for the ordered sequence of analysis
							times in the current smoothing window
obs_cov    -- observation error covariance matrix
state_infl -- multiplicative covariance inflation factor for the state variable covariance
kwargs     -- keyword arguments for parameter estimation or other functionality, including
              integration parameters for the state model in smoothing schemes
&quot;&quot;&quot;</code></pre><p>The type of analysis to be passed to the transform step is specified with the <code>analysis</code> string, with partiuclar analysis methods described below.  Observations for the filter schemes correspond to information available at a single analysis time giving an observation of the state vector of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.VecA-Tuple{Any}"><code>VecA</code></a>. The ls (lag-shift) smoothers require an array of observations of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ArView-Tuple{Any}"><code>ArView</code></a> corresponding to all analysis times within the DAW. Observation covariances are typed as <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.CovM-Tuple{Any}"><code>CovM</code></a> for efficiency. The <code>state_infl</code> is a required tuneable parameter for multiplicative covariance inflation.   Extended parameter state covariance inflation can be specified in <code>kwargs</code>.  These outer-loops will pass the required values to the <a href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.transform_R-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Vector{T1}, SubArray{T1, 1}} where T1&lt;:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1&lt;:T, Dict{String, Any}}} where T&lt;:Float64"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.transform_R</code></a> method that generates the ensemble transform for conditioning on observations. Utility scripts to generate observation operators, analyze ensemble statistics, etc, are included in the below. </p><h2 id="Methods"><a class="docs-heading-anchor" href="#Methods">Methods</a><a id="Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Methods" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_obs_operator-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Int64, Dict{String, Any}}} where T&lt;:Real" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_obs_operator-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Int64, Dict{String, Any}}} where T&lt;:Real"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_obs_operator</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">alternating_obs_operator(ens::ArView(T), obs_dim::Int64,
                         kwargs::StepKwargs) where T &lt;: Real</code></pre><p>This produces observations of alternating state vector components for generating pseudo-data.</p><pre><code class="nohighlight hljs">return obs::ArView(T)</code></pre><p>This operator takes either a truth twin time series or an ensemble of states of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ArView-Tuple{Any}"><code>ArView</code></a>, and maps this data to the observation space.  The truth twin in this version is assumed to be 2D, where the first index corresponds to the state dimension and the second index corresponds to the time dimension.  The ensemble is assumed to be 2D where the first index corresponds to the state dimension and the second index corresponds to the ensemble dimension.  The operator selects components of the state dimension to observe based on the observation dimension, adjusting if parameter estimation is being performed.  Model parameters are always assumed unobservable, and statistical replicates of model parameters in the ensemble will be first truncated out of the ensemble matrix before mapping the state vectors to the observation space. States correpsonding to even state dimension indices are removed from the state vector until the observation dimension is appropriate.  If the observation dimension is less than half the state dimension, states corresponding to odd state dimension idices are subsequently removed until the observation dimension is appropriate.</p><p>The <code>γ</code> parameter (optional) in <code>kwargs</code> of type  <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.StepKwargs"><code>StepKwargs</code></a> controls the component-wise transformation of the remaining state vector components mapped to the observation space.  For <code>γ=1.0</code>, there is no transformation applied, and the observation operator acts as a linear projection onto the remaining components of the state vector, equivalent to not specifying <code>γ</code>. For <code>γ&gt;1.0</code>, the nonlinear observation operator of  <a href="https://epubs.siam.org/doi/book/10.1137/1.9781611974546">Asch, et al. (2016).</a>, pg. 181 is applied, which limits to the identity for <code>γ=1.0</code>.  If <code>γ=0.0</code>, the quadratic observation operator of <a href="https://journals.ametsoc.org/view/journals/mwre/140/2/2011mwr3640.1.xml">Hoteit, et al. (2012).</a> is applied to the remaining state components.  If <code>γ&lt;0.0</code>, the exponential observation operator of <a href="https://npg.copernicus.org/articles/21/955/2014/">Wu, et al. (2014).</a> is applied to the remaining state vector components.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_obs_operator-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1&lt;:T, Int64, Dict{String, Any}}} where T&lt;:Real" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_obs_operator-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1&lt;:T, Int64, Dict{String, Any}}} where T&lt;:Real"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_obs_operator</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">alternating_obs_operator(x::VecA(T), obs_dim::Int64, kwargs::StepKwargs) where T &lt;: Real</code></pre><p>This produces observations of alternating state vector components for generating pseudo-data.</p><pre><code class="nohighlight hljs">return obs::VecA(T)</code></pre><p>This operator takes a single model state <code>x</code> of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.VecA-Tuple{Any}"><code>VecA</code></a> and maps this data to the observation space.  The operator selects components of the state dimension to observe based on the observation dimension, adjusting if the state vector includes parameter values. Model parameters are always assumed unobservable, and parameters in the state vector will be first truncated out of the  before mapping the state vectors to the observation space. States correpsonding to even state dimension indices are removed from the state vector until the observation dimension is appropriate.  If the observation dimension is less than half the state dimension, states corresponding to odd state dimension idices are subsequently removed until the observation dimension is appropriate.</p><p>The <code>γ</code> parameter (optional) in <code>kwargs</code> of type  <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.StepKwargs"><code>StepKwargs</code></a> controls the component-wise transformation of the remaining state vector components mapped to the observation space.  For <code>γ=1.0</code>, there is no transformation applied, and the observation operator acts as a linear projection onto the remaining components of the state vector, equivalent to not specifying <code>γ</code>. For <code>γ&gt;1.0</code>, the nonlinear observation operator of  <a href="https://epubs.siam.org/doi/book/10.1137/1.9781611974546">Asch, et al. (2016).</a>, pg. 181 is applied, which limits to the identity for <code>γ=1.0</code>.  If <code>γ=0.0</code>, the quadratic observation operator of <a href="https://journals.ametsoc.org/view/journals/mwre/140/2/2011mwr3640.1.xml">Hoteit, et al. (2012).</a> is applied to the remaining state components.  If <code>γ&lt;0.0</code>, the exponential observation operator of <a href="https://npg.copernicus.org/articles/21/955/2014/">Wu, et al. (2014).</a> is applied to the remaining state vector components.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Vector{T1}, SubArray{T1, 1}} where T1&lt;:T}} where T&lt;:Float64" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Vector{T1}, SubArray{T1, 1}} where T1&lt;:T}} where T&lt;:Float64"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">analyze_ens(ens::ArView(T), truth::VecA(T)) where T &lt;: Float64</code></pre><p>Computes the ensemble state RMSE as compared with truth twin, and the ensemble spread.</p><pre><code class="nohighlight hljs">return rmse::Float64, spread::Float64</code></pre><p>Note: the ensemble <code>ens</code> should only include the state vector components to compare with the truth twin state vector <code>truth</code>, without replicates of the model parameters.  These can be passed as an <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ArView-Tuple{Any}"><code>ArView</code></a> for efficient memory usage.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens_param-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Vector{T1}, SubArray{T1, 1}} where T1&lt;:T}} where T&lt;:Float64" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens_param-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Vector{T1}, SubArray{T1, 1}} where T1&lt;:T}} where T&lt;:Float64"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens_param</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">analyze_ens_param(ens::ArView(T), truth::VecA(T)) where T &lt;: Float64</code></pre><p>Computes the ensemble parameter RMSE as compared with truth twin, and the ensemble spread.</p><pre><code class="nohighlight hljs">return rmse::Float64, spread::Float64</code></pre><p>Note: the ensemble <code>ens</code> should only include the extended state vector components consisting of model parameter replicates to compare with the truth twin&#39;s governing model parameters <code>truth</code>.  These can be passed as an <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ArView-Tuple{Any}"><code>ArView</code></a> for efficient memory usage.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_gauss_newton-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Vector{T1}, SubArray{T1, 1}} where T1&lt;:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1&lt;:T, Dict{String, Any}}} where T&lt;:Float64" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_gauss_newton-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Vector{T1}, SubArray{T1, 1}} where T1&lt;:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1&lt;:T, Dict{String, Any}}} where T&lt;:Float64"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_gauss_newton</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ens_gauss_newton(analysis::String, ens::ArView(T), obs::VecA(T), 
                 obs_cov::CovM(T), kwargs::StepKwargs;
                 conditioning::ConM(T)=1000.0I, 
                 m_err::ArView(T)=(1.0 ./ zeros(1,1)),
                 tol::Float64 = 0.0001,
                 j_max::Int64=40,
                 Q::CovM(T)=1.0I) where T &lt;: Float64</code></pre><p>Computes the ensemble estimated gradient and Hessian terms for nonlinear least-squares</p><pre><code class="nohighlight hljs">return ∇_J::ArView(T), Hess_J::ArView(T)</code></pre><p><code>m_err</code>, <code>tol</code>, <code>j_max</code>, <code>Q</code> are optional arguments depending on the <code>analysis</code>, with  default values provided.</p><p>Serves as an auxilliary function for IEnKS(-N), where &quot;analysis&quot; is a string which determines the method of transform update ensemble Gauss-Newton calculation.  The observation error covariance <code>obs_cov</code> is of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.CovM-Tuple{Any}"><code>CovM</code></a>, the conditioning matrix <code>conditioning</code> is of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ConM-Tuple{Any}"><code>ConM</code></a>, the keyword arguments dictionary <code>kwargs</code> is of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.StepKwargs"><code>StepKwargs</code></a> and the model error covariance matrix <code>Q</code> is of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.CovM-Tuple{Any}"><code>CovM</code></a>.</p><p>Currently validated <code>analysis</code> options:</p><ul><li><code>analysis == &quot;ienks-bundle&quot; || &quot;ienks-n-bundle&quot; || &quot;ienks-transform&quot; || &quot;ienks-n-transform&quot;</code> computes the weighted observed anomalies as per the   bundle or transform version of the IEnKS, described in <a href="https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.2236">Bocquet &amp; Sakov 2013</a>, <a href="https://gmd.copernicus.org/preprints/gmd-2021-306/">Grudzien, et al. 2021</a>. Bundle versus tranform versions of the scheme are specified by the trailing <code>analysis</code> string as <code>-bundle</code> or <code>-transform</code>.  The bundle version uses a small uniform  scalar <code>ϵ</code>, whereas the transform version uses a matrix square root inverse as the conditioning operator. This form of analysis differs from other schemes by returning a sequential-in-time value for the cost function gradient and Hessian, which will is utilized within the iterative smoother optimization.  A finite-size inflation scheme, based on the EnKF-N above, can be utilized by appending additionally a <code>-n</code> to the <code>-bundle</code> or <code>-transform</code> version of the IEnKS scheme specified in <code>analysis</code>.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_update_RT!-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Tuple{LinearAlgebra.Symmetric{T1, Matrix{T1}}, Vector{T1}, Matrix{T1}}, Tuple{LinearAlgebra.Symmetric{T1, Matrix{T1}}, Matrix{T1}, Matrix{T1}}} where T1&lt;:T}} where T&lt;:Float64" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_update_RT!-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Tuple{LinearAlgebra.Symmetric{T1, Matrix{T1}}, Vector{T1}, Matrix{T1}}, Tuple{LinearAlgebra.Symmetric{T1, Matrix{T1}}, Matrix{T1}, Matrix{T1}}} where T1&lt;:T}} where T&lt;:Float64"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_update_RT!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ens_update_RT!(ens::ArView(T), transform::TransM(T)) where T &lt;: Float64</code></pre><p>Updates forecast ensemble to the analysis ensemble by right transform (RT) method. </p><pre><code class="nohighlight hljs">return ens::ArView(T)</code></pre><p>Arguments include the ensemble of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ArView-Tuple{Any}"><code>ArView</code></a> and the 3-tuple including the right transform for the anomalies, the weights for the mean and the random, mean-preserving orthogonal matrix, type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.TransM-Tuple{Any}"><code>TransM</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.ensemble_filter-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Vector{T1}, SubArray{T1, 1}} where T1&lt;:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1&lt;:T, Float64, Dict{String, Any}}} where T&lt;:Float64" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ensemble_filter-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Vector{T1}, SubArray{T1, 1}} where T1&lt;:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1&lt;:T, Float64, Dict{String, Any}}} where T&lt;:Float64"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.ensemble_filter</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ensemble_filter(analysis::String, ens::ArView(T), obs::VecA(T), obs_cov::CovM(T),
                s_infl::Float64, kwargs::StepKwargs) where T &lt;: Float64</code></pre><p>General filter analysis step, wrapping the right transform / update, and inflation steps. Optional keyword argument includes state_dim for extended state including parameters. In this case, a value for the parameter covariance inflation should be included in addition to the state covariance inflation.</p><pre><code class="nohighlight hljs">return Dict{String,Array{Float64,2}}(&quot;ens&quot; =&gt; ens)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_param!-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Float64, Int64, Int64}} where T&lt;:Float64" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_param!-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Float64, Int64, Int64}} where T&lt;:Float64"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_param!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">inflate_param!(ens::ArView(T), inflation::Float64, sys_dim::Int64,
               state_dim::Int64) where T &lt;: Float64</code></pre><p>Applies multiplicative covariance inflation to parameter replicates in the ensemble matrix.</p><pre><code class="nohighlight hljs">return ens::ArView(T)</code></pre><p>The first index of the ensemble matrix <code>ens</code> corresponds to the length <code>sys_dim</code> (extended) state dimension while the second index corresponds to the ensemble dimension.  Dynamic state variables are assumed to be in the leading <code>state_dim</code> rows of <code>ens</code>, while extended state parameter replicates are after. Multiplicative inflation is performed only in the trailing  <code>state_dim + 1: state_dim</code> components of the ensemble anomalies from the ensemble mean, in-place in memory.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_state!-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Float64, Int64, Int64}} where T&lt;:Float64" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_state!-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Float64, Int64, Int64}} where T&lt;:Float64"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_state!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">inflate_state!(ens::ArView(T), inflation::Float64, sys_dim::Int64,
               state_dim::Int64) where T &lt;: Float64</code></pre><p>Applies multiplicative covariance inflation to the state components of the ensemble matrix.</p><pre><code class="nohighlight hljs">return ens::ArView(T)</code></pre><p>The first index of the ensemble matrix <code>ens</code> corresponds to the length <code>sys_dim</code> (extended) state dimension while the second index corresponds to the ensemble dimension.  Dynamic state variables are assumed to be in the leading <code>state_dim</code> rows of <code>ens</code>, while extended state parameter replicates are after. Multiplicative inflation is performed only in the leading components of the ensemble anomalies from the ensemble mean, in-place in memory.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_classic-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1&lt;:T, Float64, Dict{String, Any}}} where T&lt;:Float64" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_classic-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1&lt;:T, Float64, Dict{String, Any}}} where T&lt;:Float64"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_classic</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ls_smoother_classic(analysis::String, ens::ArView(T), obs::ArView(T),
                    obs_cov::CovM(T), s_infl::Float64,
                    kwargs::StepKwargs) where T &lt;: Float64</code></pre><p>Lag-shift ensemble Kalman smoother analysis step, classical version.</p><p>Classic EnKS uses the last filtered state for the forecast, different from the  iterative schemes which use the once or multiple-times re-analized posterior for the initial condition for the forecast of the states to the next shift.</p><p>Optional argument includes state dimension for extended state including parameters. In this case, a value for the parameter covariance inflation should be included in addition to the state covariance inflation.</p><pre><code class="nohighlight hljs">return Dict{String,Array{Float64}}(
                                   &quot;ens&quot; =&gt; ens, 
                                   &quot;post&quot; =&gt;  posterior, 
                                   &quot;fore&quot; =&gt; forecast, 
                                   &quot;filt&quot; =&gt; filtered
                                  ) </code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_gauss_newton-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1&lt;:T, Float64, Dict{String, Any}}} where T&lt;:Float64" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_gauss_newton-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1&lt;:T, Float64, Dict{String, Any}}} where T&lt;:Float64"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_gauss_newton</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ls_smoother_gauss_newton(analysis::String, ens::ArView(T),
                         obs::ArView(T), obs_cov::CovM(T), s_infl::Float64,
                         kwargs::StepKwargs; ϵ::Float64=0.0001,
                         tol::Float64=0.001, max_iter::Int64=5) where T &lt;: Float64</code></pre><p>This implements a lag-shift Gauss-Newton IEnKS analysis step as in algorithm 4 of <a href="https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.2236">Bocquet &amp; Sakov 2014</a>. The IEnKS uses the final re-analyzed initial state in the data assimilation window to generate the forecast, which is subsequently pushed forward in time from the initial conidtion to shift-number of observation times. Optional argument includes state dimension for an extended state including parameters. In this case, a value for the parameter covariance inflation should be included in addition to the state covariance inflation.</p><pre><code class="nohighlight hljs">return Dict{String,Array{Float64}}(
                                   &quot;ens&quot; =&gt; ens, 
                                   &quot;post&quot; =&gt;  posterior, 
                                   &quot;fore&quot; =&gt; forecast, 
                                   &quot;filt&quot; =&gt; filtered
                                  ) </code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_single_iteration-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1&lt;:T, Float64, Dict{String, Any}}} where T&lt;:Float64" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_single_iteration-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1&lt;:T, Float64, Dict{String, Any}}} where T&lt;:Float64"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_single_iteration</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ls_smoother_single_iteration(analysis::String, ens::ArView(T),
                             obs::ArView(T), obs_cov::CovM(T),
                             s_infl::Float64, kwargs::StepKwargs) where T &lt;: Float64</code></pre><p>Lag-shift, single-iteration ensemble Kalman smoother (SIEnKS) analysis step.</p><p>Single-iteration EnKS uses the final re-analyzed posterior initial state for the forecast, which is pushed forward in time to shift-number of observation times. Optional argument includes state dimension for an extended state including parameters. In this case, a value for the parameter covariance inflation should be included in addition to the state covariance inflation.</p><pre><code class="nohighlight hljs">return Dict{String,Array{Float64}}(
                                   &quot;ens&quot; =&gt; ens, 
                                   &quot;post&quot; =&gt;  posterior, 
                                   &quot;fore&quot; =&gt; forecast, 
                                   &quot;filt&quot; =&gt; filtered
                                  ) </code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.rand_orth-Tuple{Int64}" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.rand_orth-Tuple{Int64}"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.rand_orth</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">rand_orth(N_ens::Int64)</code></pre><p>This generates a random, mean-preserving, orthogonal matrix as in <a href="https://journals.ametsoc.org/view/journals/mwre/136/3/2007mwr2021.1.xml">Sakov &amp; Oke 2008</a>, depending on the esemble size <code>N_ens</code>.</p><pre><code class="nohighlight hljs">return U::Array{Float64, 2}</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root-Union{Tuple{LinearAlgebra.UniformScaling{T}}, Tuple{T}} where T&lt;:Real" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root-Union{Tuple{LinearAlgebra.UniformScaling{T}}, Tuple{T}} where T&lt;:Real"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">square_root(M::CovM(T)) where T &lt;: Real</code></pre><p>Computes the square root of covariance matrices with parametric type.</p><p>Multiple dispatches for the method are defined according to the sub-type of <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.CovM-Tuple{Any}"><code>CovM</code></a>, where the square roots of <code>UniformScaling</code> and <code>Diagonal</code> covariance matrices are computed directly, while the square roots of  the more general class of <code>Symmetric</code> covariance matrices are computed via the singular value decomposition, for stability and accuracy for close-to-singular matrices.</p><pre><code class="nohighlight hljs">return S::CovM(T)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root_inv-Union{Tuple{LinearAlgebra.UniformScaling{T}}, Tuple{T}} where T&lt;:Real" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root_inv-Union{Tuple{LinearAlgebra.UniformScaling{T}}, Tuple{T}} where T&lt;:Real"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root_inv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">square_root_inv(M::CovM(T); sq_rt::Bool=false, inverse::Bool=false,
                full::Bool=false) where T &lt;: Real</code></pre><p>Computes the square root inverse of covariance matrices with parametric type.</p><p>Multiple dispatches for the method are defined according to the sub-type of <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.CovM-Tuple{Any}"><code>CovM</code></a>, where the square root inverses of <code>UniformScaling</code> and <code>Diagonal</code> covariance matrices are computed directly, while the square root inverses of the more general class of <code>Symmetric</code> covariance matrices are computed via the singular value decomposition, for stability and accuracy for close-to-singular matrices. This will optionally return a computation of the inverse and the square root itself all as a byproduct of the singular value decomposition for efficient numerical computation of ensemble analysis / update routines. </p><p>Optional keyword arguments are specified as:</p><ul><li><code>sq_rt=true</code> returns the matrix square root in addition to the square root inverse</li><li><code>inverse=true</code> returns the matrix inverse in addition to the square root inverse</li><li><code>full=true</code> returns the square root and the matrix inverse in addition to the square  root inverse</li></ul><p>and are evaluated in the above order.</p><p>Output follows control flow:</p><pre><code class="nohighlight hljs">if sq_rt
    return S_inv::CovM(T), S::CovM(T)
elseif inverse
    return S_inv::CovM(T), M_inv::CovM(T)
elseif full
    return S_inv::CovM(T), S::CovM(T), M_inv::CovM(T)
else
    return S_inv::CovM(T)
end</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="DataAssimilationBenchmarks.EnsembleKalmanSchemes.transform_R-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Vector{T1}, SubArray{T1, 1}} where T1&lt;:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1&lt;:T, Dict{String, Any}}} where T&lt;:Float64" href="#DataAssimilationBenchmarks.EnsembleKalmanSchemes.transform_R-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1&lt;:T, Union{Vector{T1}, SubArray{T1, 1}} where T1&lt;:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1&lt;:T, Dict{String, Any}}} where T&lt;:Float64"><code>DataAssimilationBenchmarks.EnsembleKalmanSchemes.transform_R</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">transform_R(analysis::String, ens::ArView(T), obs::VecA(T),        
            obs_cov::CovM(T), kwargs::StepKwargs; conditioning::ConM=1000.0I, 
            m_err::ArView(T)=(1.0 ./ zeros(1,1)),
            tol::Float64 = 0.0001,
            j_max::Int64=40,
            Q::CovM(T)=1.0I) where T &lt;: Float64</code></pre><p>Computes the ensemble transform and related values for various flavors of ensemble Kalman schemes. The output type is a tuple containing a right transform of the ensemble anomalies, the weights for the mean update and a random orthogonal transformation for stabilization:</p><pre><code class="nohighlight hljs">return (trans, w, U)::TransM(T)</code></pre><p>where the tuple is of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.TransM-Tuple{Any}"><code>TransM</code></a>. <code>m_err</code>, <code>tol</code>, <code>j_max</code>, <code>Q</code> are optional arguments depending on the <code>analysis</code>, with  default values provided.</p><p>Serves as an auxilliary function for EnKF, ETKF(-N), EnKS, ETKS(-N), where &quot;analysis&quot; is a string which determines the type of transform update.  The observation error covariance <code>obs_cov</code> is of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.CovM-Tuple{Any}"><code>CovM</code></a>, the conditioning matrix <code>conditioning</code> is of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ConM-Tuple{Any}"><code>ConM</code></a>, the keyword arguments dictionary <code>kwargs</code> is of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.StepKwargs"><code>StepKwargs</code></a> and the model error covariance matrix <code>Q</code> is of type <a href="../../../home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.CovM-Tuple{Any}"><code>CovM</code></a>.</p><p>Currently validated <code>analysis</code> options:</p><ul><li><code>analysis==&quot;etkf&quot; || analysis==&quot;etks&quot;</code> computes the deterministic ensemble transform  as in the ETKF described in <a href="https://gmd.copernicus.org/preprints/gmd-2021-306/">Grudzien, et al. 2021</a>.</li><li><code>analysis[1:7]==&quot;mlef-ls&quot; || analysis[1:7]==&quot;mles-ls&quot;</code> computes the maximum likelihood ensemble filter transform described in <a href="https://gmd.copernicus.org/preprints/gmd-2021-306/">Grudzien, et al.  2021</a>, optimizing the nonlinear cost function with Newton-based  <a href="https://julianlsolvers.github.io/LineSearches.jl/stable/">line searches</a>.</li><li><code>analysis[1:4]==&quot;mlef&quot; || analysis[1:4]==&quot;mles&quot;</code> computes the maximum likelihood      ensemble filter transform described in <a href="https://gmd.copernicus.org/preprints/gmd-2021-306/">Grudzien, et al. 2021</a>, optimizing the nonlinear cost function with simple Newton-based scheme. </li><li><code>analysis==&quot;enkf-n-dual&quot; || analysis==&quot;enks-n-dual&quot;</code>  computes the dual form of the EnKF-N transform as in <a href="https://npg.copernicus.org/articles/22/645/2015/">Bocquet, et al. 2015</a> Note: this cannot be used with the nonlinear observation operator. This uses the Brent method for the argmin problem as this has been more reliable at finding a global minimum than Newton optimization.</li><li><code>analysis==&quot;enkf-n-primal&quot; || analysis==&quot;enks-n-primal&quot;</code> computes the primal form of the EnKF-N transform as in <a href="https://npg.copernicus.org/articles/22/645/2015/">Bocquet, et al. 2015</a>, <a href="https://gmd.copernicus.org/preprints/gmd-2021-306/">Grudzien, et al. 2021</a>. This differs from the MLEF/S-N in that there is no approximate linearization of the observation operator in the EnKF-N, this only handles the approximation error with respect to the adaptive inflation. This uses a simple Newton-based minimization of the cost function for the adaptive inflation.</li><li><code>analysis==&quot;enkf-n-primal-ls&quot; || analysis==&quot;enks-n-primal-ls&quot;</code> computes the primal form of the EnKF-N transform as in <a href="https://npg.copernicus.org/articles/22/645/2015/">Bocquet, et al. 2015</a>, <a href="https://gmd.copernicus.org/preprints/gmd-2021-306/">Grudzien, et al. 2021</a>. This differs from the MLEF/S-N in that there is no approximate linearization of the observation operator in the EnKF-N, this only handles the approximation error with respect to the adaptive inflation. This uses a Newton-based minimization of the cost function for the adaptive inflation with <a href="https://julianlsolvers.github.io/LineSearches.jl/stable/">line searches</a>.</li></ul></div></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../DeSolvers/">« DeSolvers</a><a class="docs-footer-nextpage" href="../../experiments/GenerateTimeSeries/">GenerateTimeSeries »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.19 on <span class="colophon-date" title="Wednesday 6 July 2022 03:19">Wednesday 6 July 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

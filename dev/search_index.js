var documenterSearchIndex = {"docs":
[{"location":"submodules/methods/EnsembleKalmanSchemes/#Ensemble-Kalman-Schemes","page":"EnsembleKalmanSchemes","title":"Ensemble Kalman Schemes","text":"","category":"section"},{"location":"submodules/methods/EnsembleKalmanSchemes/#API-for-ensemble-Kalman-schemes","page":"EnsembleKalmanSchemes","title":"API for ensemble Kalman schemes","text":"","category":"section"},{"location":"submodules/methods/EnsembleKalmanSchemes/","page":"EnsembleKalmanSchemes","title":"EnsembleKalmanSchemes","text":"There are currently four families of ensemble Kalman estimators available in this package, which define the outer-loop of the data assimilation cycle.  Particularly, these define how the sequential data assimilation cycle will pass over a time series of observations, with more details in the SmootherExps documents.","category":"page"},{"location":"submodules/methods/EnsembleKalmanSchemes/","page":"EnsembleKalmanSchemes","title":"EnsembleKalmanSchemes","text":"Ensemble filters only produce analyses forward-in-time.  The classic lag-shift smoother runsi identically to the filter in its forecast and filter steps, but includes an additional retrospective analysis to past ensemble states stored in memory.  The single iteration smoother follows the same convention as the classic smoother, except in that new cycles are initiated from a past, reanlyzed ensemble state.  The Gauss-Newton iterative smoothers are 4D smoothers, which iteratively optimize the initial condition at the beginning of a data assimilation cycle, and propagate this initial condition to initialize the subsequent cycle. A full discussion of these methods can be found in Grudzien, et al. 2021.","category":"page"},{"location":"submodules/methods/EnsembleKalmanSchemes/","page":"EnsembleKalmanSchemes","title":"EnsembleKalmanSchemes","text":"For each outer-loop method defining the data assimilation cycle, different types of analyses can be specified within their arguments.  Likewise, these outer-loop methods require arguments such as the ensemble state or the range of ensemble states to analyze, an observation to assimilate or a range of observations to assimilate, as the observation operator and observation error covariance and key word arguments for running the underlying dynamical state model. Examples of the syntax are below:","category":"page"},{"location":"submodules/methods/EnsembleKalmanSchemes/","page":"EnsembleKalmanSchemes","title":"EnsembleKalmanSchemes","text":"ensemble_filter(analysis::String, ens::ArView(T), obs::VecA(T), obs_cov::CovM(T),\n    kwargs::StepKwargs) where T <: Float64\n\nls_smoother_classic(analysis::String, ens::ArView(T), obs::ArView(T), obs_cov::CovM(T),\n    kwargs::StepKwargs) where T <: Float64\n\nls_smoother_single_iteration(analysis::String, ens::ArView(T), obs::ArView(T),\n    kwargs::StepKwargs) where T <: Float64\n\nls_smoother_gauss_newton(analysis::String, ens::ArView(T), obs::ArView(T), obs_cov::CovM(T),\n    kwargs::StepKwargs; ϵ::Float64=0.0001, tol::Float64=0.001,\n    max_iter::Int64=10) where T <: Float64","category":"page"},{"location":"submodules/methods/EnsembleKalmanSchemes/","page":"EnsembleKalmanSchemes","title":"EnsembleKalmanSchemes","text":"with conventions defined as follows:","category":"page"},{"location":"submodules/methods/EnsembleKalmanSchemes/","page":"EnsembleKalmanSchemes","title":"EnsembleKalmanSchemes","text":"analysis - string name of the analysis scheme;\nens - ensemble matrix defined by the array with columns given by the replicates of the model state;\nobs - observation vector for the current analysis in ensemble_filter / array with columns given by the observation vectors for the ordered sequence of analysis times in the current smoothing window;\nH_obs - observation model mapping state vectors and ensembles into observed variables;\nobs_cov - observation error covariance matrix;\nkwargs - keyword arguments for inflation, parameter estimation or other functionality, including integration parameters for the state model in smoothing schemes.","category":"page"},{"location":"submodules/methods/EnsembleKalmanSchemes/","page":"EnsembleKalmanSchemes","title":"EnsembleKalmanSchemes","text":"The analysis string is passed to the DataAssimilationBenchmarks.EnsembleKalmanSchemes.transform_R or the  DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_gauss_newton methods below to produce a specialized analysis within the outer-loop controlled by the above filter and smoother methods. Observations for the filter schemes correspond to information available at a single analysis time giving an observation of the state vector of type VecA. The ls (lag-shift) smoothers require an array of observations of type ArView corresponding to all analysis times within the data assimilation window (DAW). Observation covariances are typed as CovM for efficiency.  State covariance multiplicative inflation and extended state parameter covariance multiplicative inflation can be specified in kwargs. Utility scripts to generate observation operators, analyze ensemble statistics, etc, are included in the below. ","category":"page"},{"location":"submodules/methods/EnsembleKalmanSchemes/#Methods","page":"EnsembleKalmanSchemes","title":"Methods","text":"","category":"section"},{"location":"submodules/methods/EnsembleKalmanSchemes/","page":"EnsembleKalmanSchemes","title":"EnsembleKalmanSchemes","text":"Modules = [DataAssimilationBenchmarks.EnsembleKalmanSchemes]","category":"page"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Vector{T1}, SubArray{T1, 1}} where T1<:T}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens","text":"analyze_ens(ens::ArView(T), truth::VecA(T)) where T <: Float64\n\nComputes the ensemble state RMSE as compared with truth twin, and the ensemble spread.\n\nreturn rmse, spread\n\nNote: the ensemble ens should only include the state vector components to compare with the truth twin state vector truth, without replicates of the model parameters.  These can be passed as an ArView for efficient memory usage.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens_param-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Vector{T1}, SubArray{T1, 1}} where T1<:T}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens_param","text":"analyze_ens_param(ens::ArView(T), truth::VecA(T)) where T <: Float64\n\nComputes the ensemble parameter RMSE as compared with truth twin, and the ensemble spread.\n\nreturn rmse, spread\n\nNote: the ensemble ens should only include the extended state vector components consisting of model parameter replicates to compare with the truth twin's governing model parameters truth.  These can be passed as an ArView for efficient memory usage.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_gauss_newton-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Function, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Dict{String, Any}}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_gauss_newton","text":"ens_gauss_newton(analysis::String, ens::ArView(T), obs::VecA(T),\n                 H_obs::Function, obs_cov::CovM(T), kwargs::StepKwargs;\n                 conditioning::ConM(T)=1000.0I,\n                 m_err::ArView(T)=(1.0 ./ zeros(1,1)),\n                 tol::Float64 = 0.0001,\n                 j_max::Int64=40,\n                 Q::CovM(T)=1.0I) where T <: Float64\n\nComputes the ensemble estimated gradient and Hessian terms for nonlinear least-squares\n\nreturn ∇_J, Hess_J\n\nm_err, tol, j_max, Q are optional arguments depending on the analysis, with default values provided.\n\nServes as an auxilliary function for IEnKS(-N), where \"analysis\" is a string which determines the method of transform update ensemble Gauss-Newton calculation.  The observation error covariance obs_cov is of type CovM, the conditioning matrix conditioning is of type ConM, the keyword arguments dictionary kwargs is of type StepKwargs and the model error covariance matrix Q is of type CovM.\n\nCurrently validated analysis options:\n\nanalysis == \"ienks-bundle\" || \"ienks-n-bundle\" || \"ienks-transform\" || \"ienks-n-transform\" computes the weighted observed anomalies as per the bundle or transform version of the IEnKS, described in Bocquet & Sakov 2013, Grudzien, et al. 2021. Bundle versus tranform versions of the scheme are specified by the trailing analysis string as -bundle or -transform.  The bundle version uses a small uniform scalar ϵ, whereas the transform version uses a matrix square root inverse as the conditioning operator. This form of analysis differs from other schemes by returning a sequential-in-time value for the cost function gradient and Hessian, which will is utilized within the iterative smoother optimization.  A finite-size inflation scheme, based on the EnKF-N above, can be utilized by appending additionally a -n to the -bundle or -transform version of the IEnKS scheme specified in analysis.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_update_RT!-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Tuple{LinearAlgebra.Symmetric{T1, Matrix{T1}}, Vector{T1}, Matrix{T1}}, Tuple{LinearAlgebra.Symmetric{T1, Matrix{T1}}, Matrix{T1}, Matrix{T1}}} where T1<:T}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_update_RT!","text":"ens_update_RT!(ens::ArView(T), transform::TransM(T)) where T <: Float64\n\nUpdates forecast ensemble to the analysis ensemble by right transform (RT) method.\n\nreturn ens\n\nArguments include the ensemble of type ArView and the 3-tuple including the right transform for the anomalies, the weights for the mean and the random, mean-preserving orthogonal matrix, type TransM.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ensemble_filter-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Function, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Dict{String, Any}}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.ensemble_filter","text":"ensemble_filter(analysis::String, ens::ArView(T), obs::VecA(T), H_obs::Function,\n                obs_cov::CovM(T), kwargs::StepKwargs) where T <: Float64\n\nGeneral filter analysis step, wrapping the right transform / update, and inflation steps. Optional keyword argument includes state_dim for extended state including parameters. In this case, a value for the parameter covariance inflation should be included in addition to the state covariance inflation.\n\nreturn Dict{String,Array{Float64,2}}(\"ens\" => ens)\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_param!-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Float64, Int64, Int64}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_param!","text":"inflate_param!(ens::ArView(T), inflation::Float64, sys_dim::Int64,\n               state_dim::Int64) where T <: Float64\n\nApplies multiplicative covariance inflation to parameter replicates in the ensemble matrix.\n\nreturn ens\n\nThe first index of the ensemble matrix ens corresponds to the length sys_dim (extended) state dimension while the second index corresponds to the ensemble dimension.  Dynamic state variables are assumed to be in the leading state_dim rows of ens, while extended state parameter replicates are after. Multiplicative inflation is performed only in the trailing state_dim + 1: state_dim components of the ensemble anomalies from the ensemble mean, in-place in memory.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_state!-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Float64, Int64, Int64}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_state!","text":"inflate_state!(ens::ArView(T), inflation::Float64, sys_dim::Int64,\n               state_dim::Int64) where T <: Float64\n\nApplies multiplicative covariance inflation to the state components of the ensemble matrix.\n\nreturn ens\n\nThe first index of the ensemble matrix ens corresponds to the length sys_dim (extended) state dimension while the second index corresponds to the ensemble dimension.  Dynamic state variables are assumed to be in the leading state_dim rows of ens, while extended state parameter replicates are after. Multiplicative inflation is performed only in the leading components of the ensemble anomalies from the ensemble mean, in-place in memory.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_classic-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Function, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Dict{String, Any}}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_classic","text":"ls_smoother_classic(analysis::String, ens::ArView(T), obs::ArView(T), H_obs::Function,\n                    obs_cov::CovM(T),  kwargs::StepKwargs) where T <: Float64\n\nLag-shift ensemble Kalman smoother analysis step, classical version.\n\nClassic EnKS uses the last filtered state for the forecast, different from the iterative schemes which use the once or multiple-times re-analized posterior for the initial condition for the forecast of the states to the next shift.\n\nOptional argument includes state dimension for extended state including parameters. In this case, a value for the parameter covariance inflation should be included in addition to the state covariance inflation.\n\nreturn Dict{String,Array{Float64}}(\n                                   \"ens\" => ens,\n                                   \"post\" =>  posterior,\n                                   \"fore\" => forecast,\n                                   \"filt\" => filtered\n                                  )\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_gauss_newton-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Function, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Dict{String, Any}}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_gauss_newton","text":"ls_smoother_gauss_newton(analysis::String, ens::ArView(T), obs::ArView(T),\n                         H_obs::Function, obs_cov::CovM(T),\n                         kwargs::StepKwargs; ϵ::Float64=0.0001,\n                         tol::Float64=0.001, max_iter::Int64=5) where T <: Float64\n\nThis implements a lag-shift Gauss-Newton IEnKS analysis step as in algorithm 4 of Bocquet & Sakov 2014. The IEnKS uses the final re-analyzed initial state in the data assimilation window to generate the forecast, which is subsequently pushed forward in time from the initial conidtion to shift-number of observation times. Optional argument includes state dimension for an extended state including parameters. In this case, a value for the parameter covariance inflation should be included in addition to the state covariance inflation.\n\nreturn Dict{String,Array{Float64}}(\n                                   \"ens\" => ens,\n                                   \"post\" =>  posterior,\n                                   \"fore\" => forecast,\n                                   \"filt\" => filtered\n                                  )\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_single_iteration-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Function, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Dict{String, Any}}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_single_iteration","text":"ls_smoother_single_iteration(analysis::String, ens::ArView(T),\n                             H_obs::Function, obs::ArView(T), obs_cov::CovM(T),\n                             kwargs::StepKwargs) where T <: Float64\n\nLag-shift, single-iteration ensemble Kalman smoother (SIEnKS) analysis step.\n\nSingle-iteration EnKS uses the final re-analyzed posterior initial state for the forecast, which is pushed forward in time to shift-number of observation times. Optional argument includes state dimension for an extended state including parameters. In this case, a value for the parameter covariance inflation should be included in addition to the state covariance inflation.\n\nreturn Dict{String,Array{Float64}}(\n                                   \"ens\" => ens,\n                                   \"post\" =>  posterior,\n                                   \"fore\" => forecast,\n                                   \"filt\" => filtered\n                                  )\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.rand_orth-Tuple{Int64}","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.rand_orth","text":"rand_orth(N_ens::Int64)\n\nThis generates a random, mean-preserving, orthogonal matrix as in Sakov & Oke 2008, depending on the esemble size N_ens.\n\nreturn U\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root-Union{Tuple{LinearAlgebra.UniformScaling{T}}, Tuple{T}} where T<:Real","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root","text":"square_root(M::CovM(T)) where T <: Real\n\nComputes the square root of covariance matrices with parametric type.\n\nMultiple dispatches for the method are defined according to the sub-type of CovM, where the square roots of UniformScaling and Diagonal covariance matrices are computed directly, while the square roots of  the more general class of Symmetric covariance matrices are computed via the singular value decomposition, for stability and accuracy for close-to-singular matrices.\n\nreturn S\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root_inv-Union{Tuple{LinearAlgebra.UniformScaling{T}}, Tuple{T}} where T<:Real","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root_inv","text":"square_root_inv(M::CovM(T); sq_rt::Bool=false, inverse::Bool=false,\n                full::Bool=false) where T <: Real\n\nComputes the square root inverse of covariance matrices with parametric type.\n\nMultiple dispatches for the method are defined according to the sub-type of CovM, where the square root inverses of UniformScaling and Diagonal covariance matrices are computed directly, while the square root inverses of the more general class of Symmetric covariance matrices are computed via the singular value decomposition, for stability and accuracy for close-to-singular matrices. This will optionally return a computation of the inverse and the square root itself all as a byproduct of the singular value decomposition for efficient numerical computation of ensemble analysis / update routines.\n\nOptional keyword arguments are specified as:\n\nsq_rt=true returns the matrix square root in addition to the square root inverse\ninverse=true returns the matrix inverse in addition to the square root inverse\nfull=true returns the square root and the matrix inverse in addition to the square  root inverse\n\nand are evaluated in the above order.\n\nOutput follows control flow:\n\nif sq_rt\n    return S_inv, S\nelseif inverse\n    return S_inv, M_inv\nelseif full\n    return S_inv, S, M_inv\nelse\n    return S_inv\nend\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.transform_R-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Function, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Dict{String, Any}}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.transform_R","text":"transform_R(analysis::String, ens::ArView(T), obs::VecA(T), H_obs::Function,\n            obs_cov::CovM(T), kwargs::StepKwargs; conditioning::ConM=1000.0I,\n            m_err::ArView(T)=(1.0 ./ zeros(1,1)),\n            tol::Float64 = 0.0001,\n            j_max::Int64=40,\n            Q::CovM(T)=1.0I) where T <: Float64\n\nComputes the ensemble transform and related values for various flavors of ensemble Kalman schemes. The output type is a tuple containing a right transform of the ensemble anomalies, the weights for the mean update and a random orthogonal transformation for stabilization:\n\nreturn trans, w, U\n\nwhere the tuple is of type TransM. m_err, tol, j_max, Q are optional arguments depending on the analysis, with default values provided.\n\nServes as an auxilliary function for EnKF, ETKF(-N), EnKS, ETKS(-N), where \"analysis\" is a string which determines the type of transform update.  The observation error covariance obs_cov is of type CovM, the conditioning matrix conditioning is of type ConM, the keyword arguments dictionary kwargs is of type StepKwargs and the model error covariance matrix Q is of type CovM.\n\nCurrently validated analysis options:\n\nanalysis==\"etkf\" || analysis==\"etks\" computes the deterministic ensemble transform as in the ETKF described in Grudzien, et al. 2021.\nanalysis[1:7]==\"mlef-ls\" || analysis[1:7]==\"mles-ls\" computes the maximum likelihood ensemble filter transform described in Grudzien, et al. 2021, optimizing the nonlinear cost function with Newton-based line searches.\nanalysis[1:4]==\"mlef\" || analysis[1:4]==\"mles\" computes the maximum likelihood ensemble filter transform described in Grudzien, et al. 2021, optimizing the nonlinear cost function with simple Newton-based scheme.\nanalysis==\"enkf-n-dual\" || analysis==\"enks-n-dual\" computes the dual form of the EnKF-N transform as in Bocquet, et al. 2015 Note: this cannot be used with the nonlinear observation operator. This uses the Brent method for the argmin problem as this has been more reliable at finding a global minimum than Newton optimization.\nanalysis==\"enkf-n-primal\" || analysis==\"enks-n-primal\" computes the primal form of the EnKF-N transform as in Bocquet, et al. 2015, Grudzien, et al. 2021. This differs from the MLEF/S-N in that there is no approximate linearization of the observation operator in the EnKF-N, this only handles the approximation error with respect to the adaptive inflation. This uses a simple Newton-based minimization of the cost function for the adaptive inflation.\nanalysis==\"enkf-n-primal-ls\" || analysis==\"enks-n-primal-ls\" computes the primal form of the EnKF-N transform as in Bocquet, et al. 2015, Grudzien, et al. 2021. This differs from the MLEF/S-N in that there is no approximate linearization of the observation operator in the EnKF-N, this only handles the approximation error with respect to the adaptive inflation. This uses a Newton-based minimization of the cost function for the adaptive inflation with line searches.\n\n\n\n\n\n","category":"method"},{"location":"home/DataAssimilationBenchmarks/#Global-Types","page":"Global Types","title":"Global Types","text":"","category":"section"},{"location":"home/DataAssimilationBenchmarks/","page":"Global Types","title":"Global Types","text":"The following type and type constructors are declared for optimizing numerical routines, for using multiple dispatch of functions with different specified input forms and for passing arguments between inner / outer loop steps of the DA twin experiment. Type constructors are designed to be flexible enough to handle multiple dispactch for automatic code differentiation, though seek to ensure type consistency within mehtods for improved performance.","category":"page"},{"location":"home/DataAssimilationBenchmarks/","page":"Global Types","title":"Global Types","text":"Modules = [DataAssimilationBenchmarks]","category":"page"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ParamSample","page":"Global Types","title":"DataAssimilationBenchmarks.ParamSample","text":"ParamSample = Dict{String, Vector{UnitRange{Int64}}}\n\nDictionary containing key and index pairs to subset the state vector and then merge a statistical sample of parameters that govern the equations of motion with the ParamDict dx_params in parameter estimation problems.\n\n\n\n\n\n","category":"type"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.StepKwargs","page":"Global Types","title":"DataAssimilationBenchmarks.StepKwargs","text":"StepKwargs = Dict{String,Any}\n\nKey word arguments for twin experiment time stepping. Arguments are given as:\n\nREQUIRED:\n\ndx_dt     - time derivative function with arguments x and dx_params\ndx_params - parameters necessary to resolve dx_dt, not including parameters to be estimated in the extended state vector;\nh - numerical time discretization step size\n\nOPTIONAL:\n\ndiffusion - tunes the standard deviation of the Wiener process, equal to sqrt(h) * diffusion;\ndiff_mat - structure matrix for the diffusion coefficients, replaces the default uniform scaling;\ns_infl - ensemble anomalies of state components are scaled by this parameter for calculation of emperical covariance;\np_infl - ensemble anomalies of extended-state components for parameter sample replicates are scaled by this parameter for calculation of emperical covariance, state_dim must be defined below;\nstate_dim - keyword for parameter estimation, specifying the dimension of the dynamic state, less than the dimension of full extended state;\nparam_sample - ParamSample dictionary for merging extended state with dx_params;\nξ - random array size state_dim, can be defined in kwargs to provide a particular realization for method validation;\nγ - controls nonlinearity of the alternatingobsoperatori.\n\nSee DataAssimilationBenchmarks.ObsOperators.alternating_obs_operator for a discusssion of the γ parameter.\n\n\n\n\n\n","category":"type"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ArView-Tuple{Any}","page":"Global Types","title":"DataAssimilationBenchmarks.ArView","text":"function ArView(type)\n    Union{Array{T, 2}, SubArray{T, 2}} where T <: type\nend\n\nType constructor for union of Arrays and SubArrays for use within ensemble conditioning operations, integration schemes and other array operations.\n\n\n\n\n\n","category":"method"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ConM-Tuple{Any}","page":"Global Types","title":"DataAssimilationBenchmarks.ConM","text":"function ConM(type)\n    Union{UniformScaling{T}, Symmetric{T}} where T <: type\nend\n\nType union of conditioning matrix types, which are used for optimization routines in the transform method.\n\n\n\n\n\n","category":"method"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.CovM-Tuple{Any}","page":"Global Types","title":"DataAssimilationBenchmarks.CovM","text":"function CovM(type)\n    Union{UniformScaling{T}, Diagonal{T, Vector{T}},\n          Symmetric{T, Matrix{T}}} where T <: type\nend\n\nType constructor for union of covariance matrix types, for multiple dispatch based on their special characteristics as symmetric, positive definite operators.\n\n\n\n\n\n","category":"method"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ParamDict-Tuple{Any}","page":"Global Types","title":"DataAssimilationBenchmarks.ParamDict","text":"function ParamDict(type)\n    Union{Dict{String, Array{T}}, Dict{String, Vector{T}}} where T <: type\nend\n\nType constructor for Dictionary of model parameters to be passed to derivative functions by name.  This allows one to pass both vector parameters (and scalars written as vectors), as well as matrix valued parameters such as diffusion arrays.\n\n\n\n\n\n","category":"method"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.TransM-Tuple{Any}","page":"Global Types","title":"DataAssimilationBenchmarks.TransM","text":"function TransM(type)\n    Union{Tuple{Symmetric{T,Array{T,2}},Array{T,1},Array{T,2}},\n          Tuple{Symmetric{T,Array{T,2}},Array{T,2},Array{T,2}}} where T <: type\nend\n\nType union constructor for tuples representing the ensemble update step with a right ensemble anomaly transformation, mean update weights and mean-preserving orthogonal transformation.\n\n\n\n\n\n","category":"method"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.VecA-Tuple{Any}","page":"Global Types","title":"DataAssimilationBenchmarks.VecA","text":"function VecA(type)\n    Union{Vector{T}, SubArray{T, 1}} where T <: type\nend\n\nType constructor for union of Vectors and 1-D SubArrays.  This is utilzed  in order to pass columns of an ensemble maxtrix into integration schemes and related array operations.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SingleExperimentDriver/#SingleExperimentDriver","page":"SingleExperimentDriver","title":"SingleExperimentDriver","text":"","category":"section"},{"location":"submodules/experiments/SingleExperimentDriver/#SingleExperimentDriver-API","page":"SingleExperimentDriver","title":"SingleExperimentDriver API","text":"","category":"section"},{"location":"submodules/experiments/SingleExperimentDriver/","page":"SingleExperimentDriver","title":"SingleExperimentDriver","text":"While the above filter experiments and smoother experiments configure twin experiments, run them and save the outputs, the SingleExperimentDriver.jl and ParallelExperimentDriver.jl can be used as wrappers to run generic model settings for debugging and validation, or to use built-in Julia parallelism to run a collection experiments over a parameter grid. The SingleExperimentDriver.jl is primarily for debugging purposes with tools like BenchmarkTools.jl and Debugger.jl, so that standard inputs can be run with the experiment called with macros.","category":"page"},{"location":"submodules/experiments/SingleExperimentDriver/#Docstrings","page":"SingleExperimentDriver","title":"Docstrings","text":"","category":"section"},{"location":"submodules/experiments/SingleExperimentDriver/","page":"SingleExperimentDriver","title":"SingleExperimentDriver","text":"Modules = [DataAssimilationBenchmarks.SingleExperimentDriver]","category":"page"},{"location":"submodules/experiments/SingleExperimentDriver/#DataAssimilationBenchmarks.SingleExperimentDriver.exps","page":"SingleExperimentDriver","title":"DataAssimilationBenchmarks.SingleExperimentDriver.exps","text":"exps[\"Experiment_name\"][\"Parameter_settings\"]\n\nThis dictionary contains standard inputs for experiments, written as named tuples and stored hierarchically by experiment type.  These standard inputs are used in the package for for debugging, testing, benchmarking and profiling. Parallel submission scripts are used for performance on servers.\n\n\n\n\n\n","category":"constant"},{"location":"submodules/experiments/FilterExps/#FilterExps","page":"FilterExps","title":"FilterExps","text":"","category":"section"},{"location":"submodules/experiments/FilterExps/#FilterExps-API","page":"FilterExps","title":"FilterExps API","text":"","category":"section"},{"location":"submodules/experiments/FilterExps/","page":"FilterExps","title":"FilterExps","text":"The FilterExps.jl sub-module contains methods to configure filter twin experiments, using a stored time series as generated by GenerateTimeSeries as the underlying observation generating process.  The frequency of observations in continuous time is defined by the frequency of data saved in the time series and is inferred by the experiment when reading in the data.","category":"page"},{"location":"submodules/experiments/FilterExps/","page":"FilterExps","title":"FilterExps","text":"Filter experiment configurations are generated by supplying a  NamedTuple with the required fields as specified in the experiment method.  Conventions for these arguments are as follows:","category":"page"},{"location":"submodules/experiments/FilterExps/","page":"FilterExps","title":"FilterExps","text":"time_series - the path and file name of the .jld2 truth twin data set;\nmethod - the sub-method analysis scheme string name;\nseed - the pseudo-random seed that will define, e.g., the observation noise sequence;\nnanl - the number of observation / analysis times to produce a posterior estimate;\nobs_un - the observation error standard deviation, assuming a uniform scaling observation error covariance;\nobs_dim - the dimension of the observation vector;\nγ - defines nonliearity in the DataAssimilationBenchmarks.ObsOperators.alternating_obs_operator;\nN_ens - the ensemble size for ensemble-based filters;\ns_infl - the multiplicative inflation for the empirical model state covariance;\np_infl - the multiplicative inlfation for the empirical parameter sample covariance;\np_err - defines initial parameter sample standard deviation as p_err percent of the system parameter value;\np_wlk - defines the standard deviation of a Gaussian random walk as p_wlk percent of the estimated parameter value for a random parameter model.","category":"page"},{"location":"submodules/experiments/FilterExps/","page":"FilterExps","title":"FilterExps","text":"Standard configurations should be defined in the SingleExperimentDriver module, for reproducing results and generating standard tests of methods.","category":"page"},{"location":"submodules/experiments/FilterExps/#Filter-Experiment-Methods","page":"FilterExps","title":"Filter Experiment Methods","text":"","category":"section"},{"location":"submodules/experiments/FilterExps/","page":"FilterExps","title":"FilterExps","text":"Modules = [DataAssimilationBenchmarks.FilterExps]","category":"page"},{"location":"submodules/experiments/FilterExps/#DataAssimilationBenchmarks.FilterExps.ensemble_filter_param-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :obs_un, :obs_dim, :γ, :p_err, :p_wlk, :N_ens, :s_infl, :p_infl), <:Tuple{String, String, Int64, Int64, Float64, Int64, Float64, Float64, Float64, Int64, Float64, Float64}}}","page":"FilterExps","title":"DataAssimilationBenchmarks.FilterExps.ensemble_filter_param","text":"ensemble_filter_param((time_series::String, method::String, seed::Int64, nanl::Int64,\n                       obs_un::Float64, obs_dim::Int64, γ::Float64, p_err::Float64,\n                       p_wlk::Float64, N_ens::Int64, s_infl::Float64,\n                       p_infl::Float64)::NamedTuple)\n\nEnsemble filter joint state-parameter estimation twin experiment.\n\nOutput from the experiment is saved in a dictionary of the form,\n\ndata = Dict{String,Any}(\n                        \"fore_rmse\" => fore_rmse,\n                        \"filt_rmse\" => filt_rmse,\n                        \"param_rmse\" => para_rmse,\n                        \"fore_spread\" => fore_spread,\n                        \"filt_spread\" => filt_spread,\n                        \"param_spread\" => para_spread,\n                        \"method\" => method,\n                        \"seed\" => seed,\n                        \"diffusion\" => diffusion,\n                        \"dx_params\" => dx_params,\n                        \"param_truth\" => param_truth,\n                        \"sys_dim\" => sys_dim,\n                        \"state_dim\" => state_dim,\n                        \"obs_dim\" => obs_dim,\n                        \"obs_un\" => obs_un,\n                        \"gamma\" => γ,\n                        \"p_err\" => p_err,\n                        \"p_wlk\" => p_wlk,\n                        \"nanl\" => nanl,\n                        \"tanl\" => tanl,\n                        \"h\" => h,\n                        \"N_ens\" => N_ens,\n                        \"s_infl\" => round(s_infl, digits=2),\n                        \"p_infl\" => round(p_infl, digits=2)\n                       )\n\nif haskey(ts, \"diff_mat\")\n    data[\"diff_mat\"] = ts[\"diff_mat\"]::Array{Float64,2}\nend\n\nExperiment output is written to a directory defined by\n\npath = pkgdir(DataAssimilationBenchmarks) * \"/src/data/\" * method * \"/\"\n\nwhere the file name is written dynamically according to the selected parameters as follows:\n\nmethod *\n\"_\" * model *\n\"_param_seed_\" * lpad(seed, 4, \"0\") *\n\"_diff_\" * rpad(diffusion, 5, \"0\") *\n\"_sysD_\" * lpad(sys_dim, 2, \"0\") *\n\"_stateD_\" * lpad(state_dim, 2, \"0\") *\n\"_obsD_\" * lpad(obs_dim, 2, \"0\") *\n\"_obsU_\" * rpad(obs_un, 4, \"0\") *\n\"_gamma_\" * lpad(γ, 5, \"0\") *\n\"_paramE_\" * rpad(p_err, 4, \"0\") *\n\"_paramW_\" * rpad(p_wlk, 6, \"0\") *\n\"_nanl_\" * lpad(nanl, 5, \"0\") *\n\"_tanl_\" * rpad(tanl, 4, \"0\") *\n\"_h_\" * rpad(h, 4, \"0\") *\n\"_nens_\" * lpad(N_ens, 3, \"0\") *\n\"_stateInfl_\" * rpad(round(s_infl, digits=2), 4, \"0\") *\n\"_paramInfl_\" * rpad(round(p_infl, digits=2), 4, \"0\") *\n\".jld2\"\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/FilterExps/#DataAssimilationBenchmarks.FilterExps.ensemble_filter_state-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :obs_un, :obs_dim, :γ, :N_ens, :s_infl), <:Tuple{String, String, Int64, Int64, Float64, Int64, Float64, Int64, Float64}}}","page":"FilterExps","title":"DataAssimilationBenchmarks.FilterExps.ensemble_filter_state","text":"ensemble_filter_state((time_series::String, method::String, seed::Int64, nanl::Int64,\n                       obs_un::Float64, obs_dim::Int64, γ::Float64, N_ens::Int64,\n                       s_infl::Float64)::NamedTuple)\n\nEnsemble filter state estimation twin experiment.\n\nOutput from the experiment is saved in a dictionary of the form,\n\ndata = Dict{String,Any}(\n                        \"fore_rmse\" => fore_rmse,\n                        \"filt_rmse\" => filt_rmse,\n                        \"fore_spread\" => fore_spread,\n                        \"filt_spread\" => filt_spread,\n                        \"method\" => method,\n                        \"seed\" => seed,\n                        \"diffusion\" => diffusion,\n                        \"dx_params\" => dx_params,\n                        \"sys_dim\" => sys_dim,\n                        \"obs_dim\" => obs_dim,\n                        \"obs_un\" => obs_un,\n                        \"gamma\" => γ,\n                        \"nanl\" => nanl,\n                        \"tanl\" => tanl,\n                        \"h\" =>  h,\n                        \"N_ens\" => N_ens,\n                        \"s_infl\" => round(s_infl, digits=2)\n                       )\n\nif haskey(ts, \"diff_mat\")\n    data[\"diff_mat\"] = ts[\"diff_mat\"]::Array{Float64,2}\nend\n\nExperiment output is written to a directory defined by\n\npath = pkgdir(DataAssimilationBenchmarks) * \"/src/data/\" * method * \"/\"\n\nwhere the file name is written dynamically according to the selected parameters as follows:\n\nmethod *\n\"_\" * model *\n\"_state_seed_\" * lpad(seed, 4, \"0\") *\n\"_diff_\" * rpad(diffusion, 5, \"0\") *\n\"_sysD_\" * lpad(sys_dim, 2, \"0\") *\n\"_obsD_\" * lpad(obs_dim, 2, \"0\") *\n\"_obsU_\" * rpad(obs_un, 4, \"0\") *\n\"_gamma_\" * lpad(γ, 5, \"0\") *\n\"_nanl_\" * lpad(nanl, 5, \"0\") *\n\"_tanl_\" * rpad(tanl, 4, \"0\") *\n\"_h_\" * rpad(h, 4, \"0\") *\n\"_nens_\" * lpad(N_ens, 3,\"0\") *\n\"_stateInfl_\" * rpad(round(s_infl, digits=2), 4, \"0\") *\n\".jld2\"\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/D3VARExps/#D3VARExps","page":"D3VARExps","title":"D3VARExps","text":"","category":"section"},{"location":"submodules/experiments/D3VARExps/","page":"D3VARExps","title":"D3VARExps","text":"This module defines methods for experiments with classical variational data assimilation with 3D-VAR.  Primal cost functions are defined, with their implicit differentiation performed with automatic differentiation with JuliaDiff methods. Development of gradient-based optimization schemes using automatic differentiation is ongoing, with future development planned to integrate variational benchmark experiments.","category":"page"},{"location":"submodules/experiments/D3VARExps/","page":"D3VARExps","title":"D3VARExps","text":"The basic 3D-VAR cost function API is defined as follows","category":"page"},{"location":"submodules/experiments/D3VARExps/","page":"D3VARExps","title":"D3VARExps","text":"    D3_var_cost(x::VecA(T), obs::VecA(T), x_background::VecA(T), state_cov::CovM(T),\n    obs_cov::CovM(T), kwargs::StepKwargs) where T <: Real","category":"page"},{"location":"submodules/experiments/D3VARExps/","page":"D3VARExps","title":"D3VARExps","text":"where the control variable x is optimized, with fixed hyper-parameters defined in a wrapping function passed to auto-differentiation.","category":"page"},{"location":"submodules/experiments/D3VARExps/#Methods","page":"D3VARExps","title":"Methods","text":"","category":"section"},{"location":"submodules/experiments/D3VARExps/","page":"D3VARExps","title":"D3VARExps","text":"Modules = [DataAssimilationBenchmarks.D3VARExps]","category":"page"},{"location":"submodules/experiments/D3VARExps/#DataAssimilationBenchmarks.D3VARExps.D3_var_filter_analysis-Tuple{NamedTuple{(:time_series, :γ, :is_informed, :tuning_factor, :is_updated), <:Tuple{String, Float64, Bool, Float64, Bool}}}","page":"D3VARExps","title":"DataAssimilationBenchmarks.D3VARExps.D3_var_filter_analysis","text":"function D3varfilteranalysis((timeseries, γ, isinformed, tuningfactor, isupdated)::NamedTuple{     (:timeseries,:γ,:isinformed,:tuningfactor,:is_updated),<:Tuple{String,         Float64,Bool,Float64,Bool}})     Plotting capabilities are commented out for parallel experiment.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/D3VARExps/#DataAssimilationBenchmarks.D3VARExps.D3_var_filter_analysis_simple-Tuple{}","page":"D3VARExps","title":"DataAssimilationBenchmarks.D3VARExps.D3_var_filter_analysis_simple","text":"D3_var_filter_analysis_simple()\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SmootherExps/#SmootherExps","page":"SmootherExps","title":"SmootherExps","text":"","category":"section"},{"location":"submodules/experiments/SmootherExps/#SmootherExps-API","page":"SmootherExps","title":"SmootherExps API","text":"","category":"section"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"The SmootherExps.jl sub-module contains methods to configure filter twin experiments, using a stored time series as generated by GenerateTimeSeries as the underlying observation generating process.  The frequency of observations in continuous time is defined by the frequency of data saved in the time series and is inferred by the experiment when reading in the data.","category":"page"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"<div sytle=\"float:left; width:100%;\">\n<img style=\"width:95%\" src=\"../cyclingSDA.png\" alt=\"Observation analysis forecast cycle over multiple data assimilation windows\">\n</div>","category":"page"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"Smoother experiment configurations are generated by supplying a  NamedTuple with the required fields as specified in the experiment method.  Conventions for these arguments are the same as with the FilterExps, with the additional options that configure  the data assimilation window (DAW) and how this is shifted in time:","category":"page"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"lag - the number of past observation / analysis times to reanalyze in a DAW, corresponding to L in the figure above;\nshift- the nunber of observation / analysis times to shift the DAW, corresponding to S in the figure above;\nmda - (Multiple Data Assimilation), type Bool, determines whether the technique of multiple data assimilation is used (only compatible with single_iteration and iterative smoothers.","category":"page"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"Currently debugged and validated smoother experiment configurations include","category":"page"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"classic_state - classic ETKS style state estimation\nclassic_param - classic ETKS style state-parameter estimation\nsingle_iteration_state - SIEnKS state estimation\nsingle_iteration_param - SIEnKS state-parameter estimation\niterative_state - IEnKS Gauss-Newton style state estimation\niterative_param - IEnKS Gauss-Newton style state-parameter estimation","category":"page"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"Note, the single-iteration and fully iterative Gauss-Newton style smoothers are only defined for MDA compatible values of lag and shift where the lag is an integer multiple of the shift.","category":"page"},{"location":"submodules/experiments/SmootherExps/#Smoother-Experiment-Methods","page":"SmootherExps","title":"Smoother Experiment Methods","text":"","category":"section"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"Modules = [DataAssimilationBenchmarks.SmootherExps]","category":"page"},{"location":"submodules/experiments/SmootherExps/#DataAssimilationBenchmarks.SmootherExps.classic_ensemble_param-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :lag, :shift, :obs_un, :obs_dim, :γ, :p_err, :p_wlk, :N_ens, :s_infl, :p_infl), <:Tuple{String, String, Int64, Int64, Int64, Int64, Float64, Int64, Float64, Float64, Float64, Int64, Float64, Float64}}}","page":"SmootherExps","title":"DataAssimilationBenchmarks.SmootherExps.classic_ensemble_param","text":"classic_ensemble_param((time_series::String, method::String, seed::Int64, nanl::Int64,\n                        lag::Int64, shift::Int64, obs_un::Float64, obs_dim::Int64,\n                        γ::Float64, p_err::Float64, p_wlk::Float64, N_ens::Int64,\n                        s_infl::Float64, s_infl::Float64})::NamedTuple)\n\nClassic ensemble Kalman smoother joint state-parameter estimation twin experiment.\n\nNOTE: the classic scheme does not use multiple data assimilation and we hard code mda=false in the function for consistency with other methods.\n\nOutput from the experiment is saved in a dictionary of the form,\n\ndata = Dict{String,Any}(\n                        \"fore_rmse\" => fore_rmse,\n                        \"filt_rmse\" => filt_rmse,\n                        \"post_rmse\" => post_rmse,\n                        \"param_rmse\" => para_rmse,\n                        \"fore_spread\" => fore_spread,\n                        \"filt_spread\" => filt_spread,\n                        \"post_spread\" => post_spread,\n                        \"param_spread\" => para_spread,\n                        \"method\" => method,\n                        \"seed\" => seed,\n                        \"diffusion\" => diffusion,\n                        \"dx_params\" => dx_params,\n                        \"param_truth\" => param_truth,\n                        \"sys_dim\" => sys_dim,\n                        \"state_dim\" => state_dim,\n                        \"obs_dim\" => obs_dim,\n                        \"obs_un\" => obs_un,\n                        \"gamma\" => γ,\n                        \"p_err\" => p_err,\n                        \"p_wlk\" => p_wlk,\n                        \"nanl\" => nanl,\n                        \"tanl\" => tanl,\n                        \"lag\" => lag,\n                        \"shift\" => shift,\n                        \"mda\" => mda,\n                        \"h\" => h,\n                        \"N_ens\" => N_ens,\n                        \"s_infl\" => round(s_infl, digits=2),\n                        \"p_infl\"  => round(p_infl, digits=2)\n                       )\n\nif haskey(ts, \"diff_mat\")\n    data[\"diff_mat\"] = ts[\"diff_mat\"]\nend\n\nExperiment output is written to a directory defined by\n\npath = pkgdir(DataAssimilationBenchmarks) * \"/src/data/\" * method * \"-classic/\"\n\nwhere the file name is written dynamically according to the selected parameters as follows:\n\nmethod * \"-classic_\" * model *\n         \"_state_seed_\" * lpad(seed, 4, \"0\") *\n         \"_diff_\" * rpad(diffusion, 5, \"0\") *\n         \"_sysD_\" * lpad(sys_dim, 2, \"0\") *\n         \"_obsD_\" * lpad(obs_dim, 2, \"0\") *\n         \"_obsU_\" * rpad(obs_un, 4, \"0\") *\n         \"_gamma_\" * lpad(γ, 5, \"0\") *\n         \"_nanl_\" * lpad(nanl, 5, \"0\") *\n         \"_tanl_\" * rpad(tanl, 4, \"0\") *\n         \"_h_\" * rpad(h, 4, \"0\") *\n         \"_lag_\" * lpad(lag, 3, \"0\") *\n         \"_shift_\" * lpad(shift, 3, \"0\") *\n         \"_mda_\" * string(mda) *\n         \"_nens_\" * lpad(N_ens, 3,\"0\") *\n         \"_stateInfl_\" * rpad(round(s_infl, digits=2), 4, \"0\") *\n         \".jld2\"\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SmootherExps/#DataAssimilationBenchmarks.SmootherExps.classic_ensemble_state-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :lag, :shift, :obs_un, :obs_dim, :γ, :N_ens, :s_infl), <:Tuple{String, String, Int64, Int64, Int64, Int64, Float64, Int64, Float64, Int64, Float64}}}","page":"SmootherExps","title":"DataAssimilationBenchmarks.SmootherExps.classic_ensemble_state","text":"classic_ensemble_state((time_series::String, method::String, seed::Int64, nanl::Int64,\n                        lag::Int64, shift::Int64, obs_un::Float64, obs_dim::Int64,\n                        γ::Float64, N_ens::Int64, s_infl::Float64)::NamedTuple)\n\nClassic ensemble Kalman smoother state estimation twin experiment.\n\nNOTE: the classic scheme does not use multiple data assimilation and we hard code mda=false in the function for consistency with the API of other methods.\n\nOutput from the experiment is saved in a dictionary of the form,\n\ndata = Dict{String,Any}(\n                        \"fore_rmse\" => fore_rmse,\n                        \"filt_rmse\" => filt_rmse,\n                        \"post_rmse\" => post_rmse,\n                        \"fore_spread\" => fore_spread,\n                        \"filt_spread\" => filt_spread,\n                        \"post_spread\" => post_spread,\n                        \"method\" => method,\n                        \"seed\"  => seed,\n                        \"diffusion\" => diffusion,\n                        \"dx_params\" => dx_params,\n                        \"sys_dim\" => sys_dim,\n                        \"obs_dim\" => obs_dim,\n                        \"obs_un\" => obs_un,\n                        \"gamma\" => γ,\n                        \"nanl\" => nanl,\n                        \"tanl\" => tanl,\n                        \"lag\" => lag,\n                        \"shift\" => shift,\n                        \"h\" => h,\n                        \"N_ens\" => N_ens,\n                        \"mda\"  => mda,\n                        \"s_infl\" => round(s_infl, digits=2)\n                       )\n\nif haskey(ts, \"diff_mat\")\n    data[\"diff_mat\"] = ts[\"diff_mat\"]\nend\n\nExperiment output is written to a directory defined by\n\npath = pkgdir(DataAssimilationBenchmarks) * \"/src/data/\" * method * \"-classic/\"\n\nwhere the file name is written dynamically according to the selected parameters as follows:\n\nmethod * \"-classic_\" * model *\n         \"_state_seed_\" * lpad(seed, 4, \"0\") *\n         \"_diff_\" * rpad(diffusion, 5, \"0\") *\n         \"_sysD_\" * lpad(sys_dim, 2, \"0\") *\n         \"_obsD_\" * lpad(obs_dim, 2, \"0\") *\n         \"_obsU_\" * rpad(obs_un, 4, \"0\") *\n         \"_gamma_\" * lpad(γ, 5, \"0\") *\n         \"_nanl_\" * lpad(nanl, 5, \"0\") *\n         \"_tanl_\" * rpad(tanl, 4, \"0\") *\n         \"_h_\" * rpad(h, 4, \"0\") *\n         \"_lag_\" * lpad(lag, 3, \"0\") *\n         \"_shift_\" * lpad(shift, 3, \"0\") *\n         \"_mda_\" * string(mda) *\n         \"_nens_\" * lpad(N_ens, 3,\"0\") *\n         \"_stateInfl_\" * rpad(round(s_infl, digits=2), 4, \"0\") *\n         \".jld2\"\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SmootherExps/#DataAssimilationBenchmarks.SmootherExps.iterative_ensemble_param-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :lag, :shift, :mda, :obs_un, :obs_dim, :γ, :p_err, :p_wlk, :N_ens, :s_infl, :p_infl), <:Tuple{String, String, Int64, Int64, Int64, Int64, Bool, Float64, Int64, Float64, Float64, Float64, Int64, Float64, Float64}}}","page":"SmootherExps","title":"DataAssimilationBenchmarks.SmootherExps.iterative_ensemble_param","text":"iterative_ensemble_param((time_series:String, method:String, seed::Int64, nanl::Int64,\n                          lag::Int64, shift::Int64, mda::Bool, obs_un::Float64,\n                          obs_dim::Int64, γ::Float64, p_err::Float64, p_wlk::Float64,\n                          N_ens::Int64, s_infl::Float64, p_infl::Float64)::NamedTuple)\n\n4DEnVAR joint state-parameter estimation twin experiment using the IEnKS formalism.\n\nOutput from the experiment is saved in a dictionary of the form,\n\ndata = Dict{String,Any}(\n                        \"fore_rmse\" => fore_rmse,\n                        \"filt_rmse\" => filt_rmse,\n                        \"post_rmse\" => post_rmse,\n                        \"param_rmse\" => para_rmse,\n                        \"fore_spread\" => fore_spread,\n                        \"filt_spread\" => filt_spread,\n                        \"post_spread\" => post_spread,\n                        \"param_spread\" => para_spread,\n                        \"iteration_sequence\" => iteration_sequence,\n                        \"method\" => method,\n                        \"seed\" => seed,\n                        \"diffusion\" => diffusion,\n                        \"dx_params\" => dx_params,\n                        \"sys_dim\" => sys_dim,\n                        \"obs_dim\" => obs_dim,\n                        \"obs_un\" => obs_un,\n                        \"gamma\" => γ,\n                        \"p_wlk\" => p_wlk,\n                        \"p_infl\" => p_infl,\n                        \"nanl\" => nanl,\n                        \"tanl\" => tanl,\n                        \"lag\" => lag,\n                        \"shift\" => shift,\n                        \"mda\" => mda,\n                        \"h\" => h,\n                        \"N_ens\" => N_ens,\n                        \"s_infl\" => round(s_infl, digits=2),\n                        \"p_infl\" => round(p_infl, digits=2)\n                       )\n\nif haskey(ts, \"diff_mat\")\n    data[\"diff_mat\"] = ts[\"diff_mat\"]\nend\n\nExperiment output is written to a directory defined by\n\npath = pkgdir(DataAssimilationBenchmarks) * \"/src/data/\" * method * \"/\"\n\nwhere the file name is written dynamically according to the selected parameters as follows:\n\nmethod * \"_\" * model *\n         \"_param_seed_\" * lpad(seed, 4, \"0\") *\n         \"_diff_\" * rpad(diffusion, 5, \"0\") *\n         \"_sysD_\" * lpad(sys_dim, 2, \"0\") *\n         \"_obsD_\" * lpad(obs_dim, 2, \"0\") *\n         \"_obsU_\" * rpad(obs_un, 4, \"0\") *\n         \"_gamma_\" * lpad(γ, 5, \"0\") *\n         \"_paramE_\" * rpad(p_err, 4, \"0\") *\n         \"_paramW_\" * rpad(p_wlk, 6, \"0\") *\n         \"_nanl_\" * lpad(nanl, 5, \"0\") *\n         \"_tanl_\" * rpad(tanl, 4, \"0\") *\n         \"_h_\" * rpad(h, 4, \"0\") *\n         \"_lag_\" * lpad(lag, 3, \"0\") *\n         \"_shift_\" * lpad(shift, 3, \"0\") *\n         \"_mda_\" * string(mda) *\n         \"_nens_\" * lpad(N_ens, 3,\"0\") *\n         \"_stateInfl_\" * rpad(round(s_infl, digits=2), 4, \"0\") *\n         \"_paramInfl_\" * rpad(round(p_infl, digits=2), 4, \"0\") *\n         \".jld2\"\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SmootherExps/#DataAssimilationBenchmarks.SmootherExps.iterative_ensemble_state-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :lag, :shift, :mda, :obs_un, :obs_dim, :γ, :N_ens, :s_infl), <:Tuple{String, String, Int64, Int64, Int64, Int64, Bool, Float64, Int64, Float64, Int64, Float64}}}","page":"SmootherExps","title":"DataAssimilationBenchmarks.SmootherExps.iterative_ensemble_state","text":"iterative_ensemble_state((time_series::String, method::String, seed::Int64, nanl::Int64,\n                          lag::Int64, shift::Int64, mda::Bool, obs_un::Float64,\n                          obs_dim::Int64, γ::Float64, N_ens::Int64,\n                          s_infl::Float64)::NamedTuple)\n\n4DEnVAR state estimation twin experiment using the IEnKS formalism.\n\nOutput from the experiment is saved in a dictionary of the form,\n\ndata = Dict{String,Any}(\n                        \"fore_rmse\" => fore_rmse,\n                        \"filt_rmse\" => filt_rmse,\n                        \"post_rmse\" => post_rmse,\n                        \"fore_spread\" => fore_spread,\n                        \"filt_spread\" => filt_spread,\n                        \"post_spread\" => post_spread,\n                        \"iteration_sequence\" => iteration_sequence,\n                        \"method\" => method,\n                        \"seed\" => seed,\n                        \"diffusion\" => diffusion,\n                        \"dx_params\" => dx_params,\n                        \"sys_dim\" => sys_dim,\n                        \"obs_dim\" => obs_dim,\n                        \"obs_un\" => obs_un,\n                        \"gamma\" => γ,\n                        \"nanl\" => nanl,\n                        \"tanl\" => tanl,\n                        \"lag\" => lag,\n                        \"shift\" => shift,\n                        \"mda\" => mda,\n                        \"h\" => h,\n                        \"N_ens\" => N_ens,\n                        \"s_infl\" => round(s_infl, digits=2)\n                       )\n\nif haskey(ts, \"diff_mat\")\n    data[\"diff_mat\"] = ts[\"diff_mat\"]\nend\n\nExperiment output is written to a directory defined by\n\npath = pkgdir(DataAssimilationBenchmarks) * \"/src/data/\" * method * \"/\"\n\nwhere the file name is written dynamically according to the selected parameters as follows:\n\nmethod * \"_\" * model *\n         \"_state_seed_\" * lpad(seed, 4, \"0\") *\n         \"_diff_\" * rpad(diffusion, 5, \"0\") *\n         \"_sysD_\" * lpad(sys_dim, 2, \"0\") *\n         \"_obsD_\" * lpad(obs_dim, 2, \"0\") *\n         \"_obsU_\" * rpad(obs_un, 4, \"0\") *\n         \"_gamma_\" * lpad(γ, 5, \"0\") *\n         \"_nanl_\" * lpad(nanl, 5, \"0\") *\n         \"_tanl_\" * rpad(tanl, 4, \"0\") *\n         \"_h_\" * rpad(h, 4, \"0\") *\n         \"_lag_\" * lpad(lag, 3, \"0\") *\n         \"_shift_\" * lpad(shift, 3, \"0\") *\n         \"_mda_\" * string(mda) *\n         \"_nens_\" * lpad(N_ens, 3,\"0\") *\n         \"_stateInfl_\" * rpad(round(s_infl, digits=2), 4, \"0\") *\n         \".jld2\"\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SmootherExps/#DataAssimilationBenchmarks.SmootherExps.single_iteration_ensemble_param-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :lag, :shift, :mda, :obs_un, :obs_dim, :γ, :p_err, :p_wlk, :N_ens, :s_infl, :p_infl), <:Tuple{String, String, Int64, Int64, Int64, Int64, Bool, Float64, Int64, Float64, Float64, Float64, Int64, Float64, Float64}}}","page":"SmootherExps","title":"DataAssimilationBenchmarks.SmootherExps.single_iteration_ensemble_param","text":"single_iteration_ensemble_param((time_series::String, method::String, seed:Int64,\n                                 nanl::Int64, lag::Int64, shift::Int64, mda::Bool,\n                                 obs_un::Float64, obs_dim::Int64, γ::Float64,\n                                 p_err::Float64, p_wlk::Float64, N_ens::Int64,\n                                 s_infl::Float64, p_infl::Float64)::NamedTuple)\n\nSIEnKS joint state-parameter estimation twin experiment.\n\nOutput from the experiment is saved in a dictionary of the form,\n\ndata = Dict{String,Any}(\n                        \"fore_rmse\" => fore_rmse,\n                        \"filt_rmse\" => filt_rmse,\n                        \"post_rmse\" => post_rmse,\n                        \"param_rmse\" => para_rmse,\n                        \"fore_spread\" => fore_spread,\n                        \"filt_spread\" => filt_spread,\n                        \"post_spread\" => post_spread,\n                        \"param_spread\" => para_spread,\n                        \"method\" => method,\n                        \"seed\" => seed,\n                        \"diffusion\" => diffusion,\n                        \"dx_params\" => dx_params,\n                        \"param_truth\" => param_truth,\n                        \"sys_dim\" => sys_dim,\n                        \"obs_dim\" => obs_dim,\n                        \"obs_un\" => obs_un,\n                        \"gamma\" => γ,\n                        \"p_wlk\" => p_wlk,\n                        \"p_infl\" => p_infl,\n                        \"nanl\" => nanl,\n                        \"tanl\" => tanl,\n                        \"lag\" => lag,\n                        \"shift\" => shift,\n                        \"mda\" => mda,\n                        \"h\" => h,\n                        \"N_ens\" => N_ens,\n                        \"s_infl\" => round(s_infl, digits=2),\n                        \"p_infl\" => round(p_infl, digits=2)\n                       )\n\nif haskey(ts, \"diff_mat\")\n    data[\"diff_mat\"] = ts[\"diff_mat\"]\nend\n\nExperiment output is written to a directory defined by\n\npath = pkgdir(DataAssimilationBenchmarks) * \"/src/data/\" * method * \"-single-iteration/\"\n\nwhere the file name is written dynamically according to the selected parameters as follows:\n\nmethod * \"-single-iteration_\" * model *\n         \"_param_seed_\" * lpad(seed, 4, \"0\") *\n         \"_diff_\" * rpad(diffusion, 5, \"0\") *\n         \"_sysD_\" * lpad(sys_dim, 2, \"0\") *\n         \"_obsD_\" * lpad(obs_dim, 2, \"0\") *\n         \"_obsU_\" * rpad(obs_un, 4, \"0\") *\n         \"_gamma_\" * lpad(γ, 5, \"0\") *\n         \"_paramE_\" * rpad(p_err, 4, \"0\") *\n         \"_paramW_\" * rpad(p_wlk, 6, \"0\") *\n         \"_nanl_\" * lpad(nanl, 5, \"0\") *\n         \"_tanl_\" * rpad(tanl, 4, \"0\") *\n         \"_h_\" * rpad(h, 4, \"0\") *\n         \"_lag_\" * lpad(lag, 3, \"0\") *\n         \"_shift_\" * lpad(shift, 3, \"0\") *\n         \"_mda_\" * string(mda) *\n         \"_nens_\" * lpad(N_ens, 3,\"0\") *\n         \"_stateInfl_\" * rpad(round(s_infl, digits=2), 4, \"0\") *\n         \"_paramInfl_\" * rpad(round(p_infl, digits=2), 4, \"0\") *\n         \".jld2\"\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SmootherExps/#DataAssimilationBenchmarks.SmootherExps.single_iteration_ensemble_state-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :lag, :shift, :mda, :obs_un, :obs_dim, :γ, :N_ens, :s_infl), <:Tuple{String, String, Int64, Int64, Int64, Int64, Bool, Float64, Int64, Float64, Int64, Float64}}}","page":"SmootherExps","title":"DataAssimilationBenchmarks.SmootherExps.single_iteration_ensemble_state","text":"single_iteration_ensemble_state((time_series::String, method::String, seed::Int64,\n                                 nanl::Int64, lag::Int64, shift::Int64, mda::Bool,\n                                 obs_un::Float64, obs_dim::Int64, γ::Float64,\n                                 N_ens::Int64, s_infl::Float64})::NamedTuple)\n\nSIEnKS state estimation twin experiment.\n\nOutput from the experiment is saved in a dictionary of the form,\n\ndata = Dict{String,Any}(\n                        \"fore_rmse\" => fore_rmse,\n                        \"filt_rmse\" => filt_rmse,\n                        \"post_rmse\" => post_rmse,\n                        \"fore_spread\" => fore_spread,\n                        \"filt_spread\" => filt_spread,\n                        \"post_spread\" => post_spread,\n                        \"method\" => method,\n                        \"seed\" => seed,\n                        \"diffusion\" => diffusion,\n                        \"dx_params\" => dx_params,\n                        \"sys_dim\" => sys_dim,\n                        \"obs_dim\" => obs_dim,\n                        \"obs_un\" => obs_un,\n                        \"gamma\" => γ,\n                        \"nanl\" => nanl,\n                        \"tanl\" => tanl,\n                        \"lag\" => lag,\n                        \"shift\" => shift,\n                        \"mda\" => mda,\n                        \"h\" => h,\n                        \"N_ens\" => N_ens,\n                        \"s_infl\" => round(s_infl, digits=2)\n                       )\n\nif haskey(ts, \"diff_mat\")\n    data[\"diff_mat\"] = ts[\"diff_mat\"]\nend\n\nExperiment output is written to a directory defined by\n\npath = pkgdir(DataAssimilationBenchmarks) * \"/src/data/\" * method * \"-single-iteration/\"\n\nwhere the file name is written dynamically according to the selected parameters as follows:\n\nmethod * \"-single-iteration_\" * model *\n         \"_state_seed_\" * lpad(seed, 4, \"0\") *\n         \"_diff_\" * rpad(diffusion, 5, \"0\") *\n         \"_sysD_\" * lpad(sys_dim, 2, \"0\") *\n         \"_obsD_\" * lpad(obs_dim, 2, \"0\") *\n         \"_obsU_\" * rpad(obs_un, 4, \"0\") *\n         \"_gamma_\" * lpad(γ, 5, \"0\") *\n         \"_nanl_\" * lpad(nanl, 5, \"0\") *\n         \"_tanl_\" * rpad(tanl, 4, \"0\") *\n         \"_h_\" * rpad(h, 4, \"0\") *\n         \"_lag_\" * lpad(lag, 3, \"0\") *\n         \"_shift_\" * lpad(shift, 3, \"0\") *\n         \"_mda_\" * string(mda) *\n         \"_nens_\" * lpad(N_ens, 3,\"0\") *\n         \"_stateInfl_\" * rpad(round(s_infl, digits=2), 4, \"0\") *\n         \".jld2\"\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/XdVAR/#XdVAR","page":"XdVAR","title":"XdVAR","text":"","category":"section"},{"location":"submodules/methods/XdVAR/","page":"XdVAR","title":"XdVAR","text":"This module defines methods for classical variational data assimilation such as 3D- / 4D-VAR.  Primal cost functions are defined, with their implicit differentiation performed with automatic differentiation with JuliaDiff methods. Development of gradient-based optimization schemes using automatic differentiation is ongoing, with future development planned to integrate variational benchmark experiments.","category":"page"},{"location":"submodules/methods/XdVAR/","page":"XdVAR","title":"XdVAR","text":"The basic 3D-VAR cost function API is defined as follows","category":"page"},{"location":"submodules/methods/XdVAR/","page":"XdVAR","title":"XdVAR","text":"    D3_var_cost(x::VecA(T), obs::VecA(T), x_background::VecA(T), state_cov::CovM(T),\n    obs_cov::CovM(T), kwargs::StepKwargs) where T <: Real","category":"page"},{"location":"submodules/methods/XdVAR/","page":"XdVAR","title":"XdVAR","text":"where the control variable x is optimized, with fixed hyper-parameters defined in a wrapping function passed to auto-differentiation.","category":"page"},{"location":"submodules/methods/XdVAR/#Methods","page":"XdVAR","title":"Methods","text":"","category":"section"},{"location":"submodules/methods/XdVAR/","page":"XdVAR","title":"XdVAR","text":"Modules = [DataAssimilationBenchmarks.XdVAR]","category":"page"},{"location":"submodules/methods/XdVAR/#DataAssimilationBenchmarks.XdVAR.D3_var_cost-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Function, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Dict{String, Any}}} where T<:Real","page":"XdVAR","title":"DataAssimilationBenchmarks.XdVAR.D3_var_cost","text":"D3_var_cost(x::VecA(T), obs::VecA(T), x_background::VecA(T), state_cov::CovM(T),\nobs_cov::CovM(T), kwargs::StepKwargs) where T <: Real\n\n\n\n\n\n","category":"method"},{"location":"home/Getting Started/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"home/Getting Started/#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"The main module DataAssimilationBenchmarks.jl declares global types and type constructors. These conventions are utilized in sub-modules that implement the core numerical solvers for ordinary and stochastic differential equations, solvers for data assimilation routines and the core process model code for running twin experiments with benchmark models, collected in the methods and models sub-directories.  Experiments define routines for driving standard benchmark case studies with NamedTuples as arguments to these methods defining the associated experimental hyper-parameters.","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"In order to get the full functionality of this package you will need to install the dev version. This provides access to create new experiments and to define performance benchmarks for these experiments","category":"page"},{"location":"home/Getting Started/#Installing-a-dev-package-from-the-Julia-General-registries","page":"Getting Started","title":"Installing a dev package from the Julia General registries","text":"","category":"section"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"In order to install the dev version to your Julia environment, you can use the following commands in the REPL","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"pkg> dev DataAssimilationBenchmarks","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"The installed version will be included in your","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"~/.julia/dev/","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"on Linux and the analogous directory with respect Windows and Mac systems. Alternatively, you can install this from the main Github branch directly as follows:","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"pkg> dev https://github.com/cgrudz/DataAssimilationBenchmarks.jl","category":"page"},{"location":"home/Getting Started/#Repository-structure","page":"Getting Started","title":"Repository structure","text":"","category":"section"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"The repository is structured as follows:","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"<ul>\n  <li><code>src</code> - contains the main parent module</li>\n  <ul>\n\t\t<li><code>models</code> - contains code for defining the dynamic model equations in twin\n\t\texperiments.</li>\n\t\t<li><code>methods</code> - contains DA solvers and general numerical routines for running\n\t\ttwin experiments.</li>\n\t\t<li><code>experiments</code> - contains the outer-loop scripts that set up twin\n\t\texperiments.</li>\n\t\t<li><code>data</code> - this is an input / output directory for the inputs to and\n\t\touptuts from experiments.</li>\n\t\t<li><code>analysis</code> - contains auxilliary scripts for batch processing experiment\n\t\tresults and for plotting (currently in Python).</li>\n\t</ul>\n  <li><code>scratch</code> - this is a storage directory for backups.</li>\n  <li><code>test</code> - contains test cases for the package.</li>\n\t<li><code>docs</code> - contains the documenter files.</li>\n</ul>","category":"page"},{"location":"submodules/analysis/PlotExperimentData/#Analysis","page":"PlotExperimentData","title":"Analysis","text":"","category":"section"},{"location":"submodules/analysis/PlotExperimentData/#Processing-experiment-outputs","page":"PlotExperimentData","title":"Processing experiment outputs","text":"","category":"section"},{"location":"submodules/analysis/PlotExperimentData/","page":"PlotExperimentData","title":"PlotExperimentData","text":"The analysis directory contains scripts for batch processing the outputs from experiments into time-averaged RMSE and spread and arranging these outputs in an array for plotting.  This should be modified based on the local paths to stored data.  This will try to load files based on parameter settings written in the name of the output .jld2 file and if this is not available, this will store Inf values in the place of missing data.","category":"page"},{"location":"submodules/analysis/PlotExperimentData/#Validating-results","page":"PlotExperimentData","title":"Validating results","text":"","category":"section"},{"location":"submodules/analysis/PlotExperimentData/","page":"PlotExperimentData","title":"PlotExperimentData","text":"Benchmark configurations for the above filtering and smoothing experiments are available in the open access article A fast, single-iteration ensemble Kalman smoother for sequential data assimilation, with details on the algorithm and parameter specifications discussed in the experiments section.  Performance of filtering and smoothing schemes should be validated versus the numerical results presented there for root mean square error and ensemble spread. Simple versions of these diagnostics are built for automatic testing of the filter and smoother experiments for state and parameter estimation in the L96-s model.  Further test cases are currently in development.  The deterministic Runge-Kutta and Euler scheme for ODEs are validated in the package tests, estimating the order of convergence with the least-squares log-10 line fit between step size and discretization error.  Test cases for the stochastic integration schemes are in development, but numerical results with these schemes can be validated versus the results in the open-access article  On the numerical integration of the Lorenz-96 model, with scalar additive noise, for benchmark twin experiments.","category":"page"},{"location":"submodules/experiments/ParallelExperimentDriver/#ParallelExperimentDriver","page":"ParallelExperimentDriver","title":"ParallelExperimentDriver","text":"","category":"section"},{"location":"submodules/experiments/ParallelExperimentDriver/#ParallelExperimentDriver-API","page":"ParallelExperimentDriver","title":"ParallelExperimentDriver API","text":"","category":"section"},{"location":"submodules/experiments/ParallelExperimentDriver/","page":"ParallelExperimentDriver","title":"ParallelExperimentDriver","text":"The ParallelExperimentDriver.jl is a simple parallel implementation of calling experiment parameter arrays with pmap and Julia's native distributed computing.  This defines argumentless functions to construct the parameter array and input data necessary to generate a sensitivity test, and implements a soft-fail for experiments instability is encountered causing a crash of an experiment. This means that if a single experiment configuration in the parameter array fails due to overflow, the remaining configurations will continue their own course unaffected.","category":"page"},{"location":"submodules/experiments/ParallelExperimentDriver/#Methods","page":"ParallelExperimentDriver","title":"Methods","text":"","category":"section"},{"location":"submodules/experiments/ParallelExperimentDriver/","page":"ParallelExperimentDriver","title":"ParallelExperimentDriver","text":"Modules = [DataAssimilationBenchmarks.ParallelExperimentDriver]","category":"page"},{"location":"submodules/experiments/ParallelExperimentDriver/#DataAssimilationBenchmarks.ParallelExperimentDriver.classic_ensemble_param-Tuple{}","page":"ParallelExperimentDriver","title":"DataAssimilationBenchmarks.ParallelExperimentDriver.classic_ensemble_param","text":"args, exp = ensemble_filter_adaptive_inflation()\n\nConstucts a parameter map and experiment wrapper for sensitivity test of parameter estimation.\n\nEnsemble schemes sample the forcing parameter for the Lorenz-96 system and vary the random walk parameter model for its time evolution / search over parameter space.  Methods vary the ETKS and MLES analysis, with different lag lengths, multiplicative inflation parameters, and different pameter models.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/ParallelExperimentDriver/#DataAssimilationBenchmarks.ParallelExperimentDriver.classic_ensemble_state-Tuple{}","page":"ParallelExperimentDriver","title":"DataAssimilationBenchmarks.ParallelExperimentDriver.classic_ensemble_state","text":"args, exp = classic_ensemble_state()\n\nConstucts a parameter map and experiment wrapper for sensitivity test of nonlinear obs.\n\nThe ETKS / MLES estimators vary over different multiplicative inflation parameters, smoother lag lengths and the nonlinearity of the observation operator.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/ParallelExperimentDriver/#DataAssimilationBenchmarks.ParallelExperimentDriver.ensemble_filter_adaptive_inflation-Tuple{}","page":"ParallelExperimentDriver","title":"DataAssimilationBenchmarks.ParallelExperimentDriver.ensemble_filter_adaptive_inflation","text":"args, exp = ensemble_filter_adaptive_inflation()\n\nConstucts a parameter map and experiment wrapper for sensitivity test of adaptive inflation.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/ParallelExperimentDriver/#DataAssimilationBenchmarks.ParallelExperimentDriver.ensemble_filter_param-Tuple{}","page":"ParallelExperimentDriver","title":"DataAssimilationBenchmarks.ParallelExperimentDriver.ensemble_filter_param","text":"args, exp = ensemble_filter_param()\n\nConstucts a parameter map and experiment wrapper for sensitivity test of parameter estimation.\n\nEnsemble schemes sample the forcing parameter for the Lorenz-96 system and vary the random walk parameter model for its time evolution / search over parameter space.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/DeSolvers/#Differential-Equation-Solvers","page":"DeSolvers","title":"Differential Equation Solvers","text":"","category":"section"},{"location":"submodules/methods/DeSolvers/#API-for-differential-equation-solvers","page":"DeSolvers","title":"API for differential equation solvers","text":"","category":"section"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"Three general schemes are developed for ordinary and stochastic differential equations,","category":"page"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"the four-stage Runge-Kutta DataAssimilationBenchmarks.DeSolvers.rk4_step! scheme,\nthe second order autonomous Taylor DataAssimilationBenchmarks.DeSolvers.tay2_step! scheme, and\nthe Euler-(Maruyama) DataAssimilationBenchmarks.DeSolvers.em_step! scheme.","category":"page"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"These schemes have arguments with the conventions:","category":"page"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"x - model states of type VecA possibly including a statistical replicate of model parameter values;\nt - time value of type Float64 for present model state (a dummy argument is used for autonomous dynamics);\nkwargs - a dictionary of type StepKwargs.","category":"page"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"Details of these schemes are available in the manuscript Grudzien, C. et al. (2020). Because the second order Taylor-Stratonovich scheme relies specifically on the structure of the Lorenz-96 model with additive noise, this is included separately in the Lorenz-96 model sub-module.  These time steppers over-write the value of the model state x in-place for efficient ensemble integration.","category":"page"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"The four-stage Runge-Kutta scheme follows the convention in data assimilation of the extended state formalism for parameter estimation. In particular, the parameter sample should be included as trailing state variables in the columns of the ensemble array.  If the following conditional is true:","category":"page"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"true == haskey(kwargs, \"param_sample\")","category":"page"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"the state_dim parameter specifies the dimension of the dynamical states and creates a view of the vector x including all entries up to this index.  The remaining entries in the state vector x will be passed to the dx_dt function in a dictionary merged with the dx_params  ParamDict, according to the param_sample indices and parameter values specified in param_sample. The parameter sample values will remain unchanged by the time stepper when the dynamical state entries in x are over-written in place.","category":"page"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"Setting diffusion > 0.0 introduces additive noise to the dynamical system.  The main DataAssimilationBenchmarks.DeSolvers.rk4_step! has convergence on order 4.0 when diffusion is equal to zero, and both strong and weak convergence on order 1.0 when stochasticity is introduced.  This is the recommended out-of-the-box solver for any generic DA simulation for the statistically robust performance, versus Euler-(Maruyama). When specifically generating the truth-twin for the Lorenz-96 model with additive noise, this should be performed with the DataAssimilationBenchmarks.L96.l96s_tay2_step!, while the ensemble should be generated with the DataAssimilationBenchmarks.DeSolvers.rk4_step!.  See the benchmarks on the L96-s model for a full discussion of statistically robust model configurations.","category":"page"},{"location":"submodules/methods/DeSolvers/#Methods","page":"DeSolvers","title":"Methods","text":"","category":"section"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"Modules = [DataAssimilationBenchmarks.DeSolvers]","category":"page"},{"location":"submodules/methods/DeSolvers/#DataAssimilationBenchmarks.DeSolvers.em_step!-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Dict{String, Any}}} where T<:Real","page":"DeSolvers","title":"DataAssimilationBenchmarks.DeSolvers.em_step!","text":"em_step!(x::VecA(T), t::Float64, kwargs::StepKwargs) where T <: Real\n\nSteps model state with the Euler-Maruyama scheme.\n\nThis method has order 1.0 convergence for ODEs and for SDEs with additive noise, though has inferior performance to the four stage Runge-Kutta scheme when the amplitude of the SDE noise purturbations are small-to-moderately large.\n\nThis overwrites the input in-place and returns the updated\n\nreturn x\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/DeSolvers/#DataAssimilationBenchmarks.DeSolvers.rk4_step!-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Dict{String, Any}}} where T<:Real","page":"DeSolvers","title":"DataAssimilationBenchmarks.DeSolvers.rk4_step!","text":"rk4_step!(x::VecA(T), t::Float64, kwargs::StepKwargs) where T <: Real\n\nSteps model state with the 4 stage Runge-Kutta scheme.\n\nThe rule has strong convergence order 1.0 for generic SDEs and order 4.0 for ODEs. This method overwrites the input in-place and returns the updated\n\nreturn x\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/DeSolvers/#DataAssimilationBenchmarks.DeSolvers.tay2_step!-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Dict{String, Any}}} where T<:Real","page":"DeSolvers","title":"DataAssimilationBenchmarks.DeSolvers.tay2_step!","text":"tay2_step!(x::VecA(T), t::Float64, kwargs::StepKwargs) where T<: Real\n\nSteps model state with the deterministic second order autonomous Taylor method.\n\nThis method has order 2.0 convergence for autonomous ODEs. Time variable t is just a dummy variable, where this method is not defined for non-autonomous dynamics. This overwrites the input in-place and returns the updated\n\nreturn x\n\n\n\n\n\n","category":"method"},{"location":"submodules/models/ObsOperators/#Observation-Operators","page":"ObsOperators","title":"Observation Operators","text":"","category":"section"},{"location":"submodules/models/ObsOperators/","page":"ObsOperators","title":"ObsOperators","text":"The methods in this module define observation operators mapping the state model to the observation space.  In current experiments, the observation operator is hard-coded in the driver script with a statement","category":"page"},{"location":"submodules/models/ObsOperators/","page":"ObsOperators","title":"ObsOperators","text":"H_obs = alternating_obs_operator","category":"page"},{"location":"submodules/models/ObsOperators/","page":"ObsOperators","title":"ObsOperators","text":"defining the observation operator. The dimension of the observation and the nonlinear transform applied can be controlled with the parameters of DataAssimilationBenchmarks.ObsOperators.alternating_obs_operator.","category":"page"},{"location":"submodules/models/ObsOperators/","page":"ObsOperators","title":"ObsOperators","text":"Additional observation models are pending, following the convention where observation operators will be defined both for vector arguments and multi-arrays using mutliple dispatch with the conventions:","category":"page"},{"location":"submodules/models/ObsOperators/","page":"ObsOperators","title":"ObsOperators","text":"function H_obs(x::VecA(T), obs_dim::Int64, kwargs::StepKwargs) where T <: Real\nfunction H_obs(x::ArView(T), obs_dim::Int64, kwargs::StepKwargs) where T <: Real","category":"page"},{"location":"submodules/models/ObsOperators/","page":"ObsOperators","title":"ObsOperators","text":"allowing for the same naming to be used for single states, time series of states and ensembles of states.","category":"page"},{"location":"submodules/models/ObsOperators/#Methods","page":"ObsOperators","title":"Methods","text":"","category":"section"},{"location":"submodules/models/ObsOperators/","page":"ObsOperators","title":"ObsOperators","text":"Modules = [DataAssimilationBenchmarks.ObsOperators]","category":"page"},{"location":"submodules/models/ObsOperators/#DataAssimilationBenchmarks.ObsOperators.alternating_obs_operator-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Int64, Dict{String, Any}}} where T<:Real","page":"ObsOperators","title":"DataAssimilationBenchmarks.ObsOperators.alternating_obs_operator","text":"alternating_obs_operator(x::VecA(T), obs_dim::Int64, kwargs::StepKwargs) where T <: Real\nalternating_obs_operator(ens::ArView(T), obs_dim::Int64,\n                         kwargs::StepKwargs) where T <: Real\n\nThis produces observations of alternating state vector components for generating pseudo-data.\n\nreturn obs\n\nThis operator takes a single model state x of type VecA, a truth twin time series or an ensemble of states of type ArView, and maps this data to the observation space via the method alternating_projector and (possibly) a nonlinear transform. The truth twin in this version is assumed to be 2D, where the first index corresponds to the state dimension and the second index corresponds to the time dimension.  The ensemble is assumed to be 2D where the first index corresponds to the state dimension and the second index corresponds to the ensemble dimension. The γ parameter (optional) in kwargs of type  StepKwargs controls the component-wise transformation of the remaining state vector components mapped to the observation space.  For γ=1.0, there is no transformation applied, and the observation operator acts as a linear projection onto the remaining components of the state vector, equivalent to not specifying γ. For γ>1.0, the nonlinear observation operator of Asch, et al. (2016)., pg. 181 is applied,\n\nbeginalign\nmathcalH(pmbx) = fracpmbx2circleftpmb1 + left(fracvertpmbxvert10 right)^gamma - 1right\nendalign\n\nwhere circ is the Schur product, and which limits to the identity for γ=1.0. If γ=0.0, the quadratic observation operator of Hoteit, et al. (2012).,\n\nbeginalign\nmathcalH(pmbx) =005 pmbx circ pmbx\nendalign\n\nis applied to the remaining state components (note, this is not a continuous limit). If γ<0.0, the exponential observation operator of Wu, et al. (2014).\n\nbeginalign\nmathcalH(pmbx) = pmbx circ exp- gamma pmbx \nendalign\n\nis applied to the remaining state vector components, where the exponential is applied componentwise (note, this is also not a continuous limit).\n\n\n\n\n\n","category":"method"},{"location":"submodules/models/ObsOperators/#DataAssimilationBenchmarks.ObsOperators.alternating_projector-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Int64}} where T<:Real","page":"ObsOperators","title":"DataAssimilationBenchmarks.ObsOperators.alternating_projector","text":"alternating_projector(x::VecA(T), obs_dim::Int64) where T <: Real\nalternating_projector(ens::ArView(T), obs_dim::Int64) where T <: Real\n\nUtility method produces a projection of alternating vector or ensemble components via slicing.\n\nreturn x\nreturn ens\n\nThis operator takes a single model state x of type VecA, a truth twin time series or an ensemble of states of type ArView, and maps this data to alternating row components.  If truth twin is 2D, then the first index corresponds to the state dimension and the second index corresponds to the time dimension.  The ensemble is assumed to be 2D where the first index corresponds to the state dimension and the second index corresponds to the ensemble dimension.\n\nThe operator selects row components of the input to keep based on the obs_dim. States correpsonding to even state dimension indices are removed from the state vector until the observation dimension is appropriate. If the observation dimension is less than half the state dimension, states corresponding to odd state dimension idices are subsequently removed until the observation dimension is appropriate.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/VarAnalysisExperimentDriver/#VarAnalysisExperimentDriver","page":"VarAnalysisExperimentDriver","title":"VarAnalysisExperimentDriver","text":"","category":"section"},{"location":"submodules/experiments/VarAnalysisExperimentDriver/#Methods","page":"VarAnalysisExperimentDriver","title":"Methods","text":"","category":"section"},{"location":"submodules/experiments/VarAnalysisExperimentDriver/","page":"VarAnalysisExperimentDriver","title":"VarAnalysisExperimentDriver","text":"Modules = [DataAssimilationBenchmarks.VarAnalysisExperimentDriver]","category":"page"},{"location":"submodules/experiments/VarAnalysisExperimentDriver/#DataAssimilationBenchmarks.VarAnalysisExperimentDriver.D3_var_filter_tuning-Tuple{}","page":"VarAnalysisExperimentDriver","title":"DataAssimilationBenchmarks.VarAnalysisExperimentDriver.D3_var_filter_tuning","text":"args, exp = D3_var_filter_tuning()\n\nConstucts a parameter map and experiment wrapper for sensitivity test of covariance tuning.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/Slurm/#Slurm","page":"Slurm","title":"Slurm","text":"","category":"section"},{"location":"submodules/experiments/Slurm/#SlurmExperimentDrivers","page":"Slurm","title":"SlurmExperimentDrivers","text":"","category":"section"},{"location":"submodules/experiments/Slurm/","page":"Slurm","title":"Slurm","text":"These are a collection of templates for automatically generating an array of parameter tuples to pass to the experiment functions as configurations.  This uses a simple looping strategy, while writing out the configurations to a .jld2 file to be read by the parallel experiment driver within the slurm_submit_scripts directory.  The paralell submit script  should be run within the slurm_submit_scripts directory to specify the correct paths to the time series data, the experiment configuration data and to save to the correct output directory, specified by the method used.","category":"page"},{"location":"submodules/experiments/GenerateTimeSeries/#GenerateTimeSeries","page":"GenerateTimeSeries","title":"GenerateTimeSeries","text":"","category":"section"},{"location":"submodules/experiments/GenerateTimeSeries/","page":"GenerateTimeSeries","title":"GenerateTimeSeries","text":"GenerateTimeSeries is a sub-module used to generate a time series for a twin experiment based on tuneable model configuration parameters. Example syntax for the configuration of a time series is as follows, where arguments are defined in a  NamedTuple to be passed to the specific experiment function:","category":"page"},{"location":"submodules/experiments/GenerateTimeSeries/","page":"GenerateTimeSeries","title":"GenerateTimeSeries","text":"    (seed::Int64, h::Float64, state_dim::Int64, tanl::Float64, nanl::Int64, spin::Int64,\n     diffusion::Float64)::NamedTuple)","category":"page"},{"location":"submodules/experiments/GenerateTimeSeries/","page":"GenerateTimeSeries","title":"GenerateTimeSeries","text":"Conventions for these arguments are as follows:","category":"page"},{"location":"submodules/experiments/GenerateTimeSeries/","page":"GenerateTimeSeries","title":"GenerateTimeSeries","text":"seed - specifies initial condition for the pseudo-random number generator on which various simulation settings will depend, and will be reproduceable with the same seed value;\nh - is the numerical integration step size, controling the discretization error of the model evolution;\nstate_dim - controls the size of the Lorenz-96 model model though other models such as the IEEE39bus model are of pre-defined size;\ntanl - (time-between-analysis)defines the length of continuous time units between sequential observations;\nnanl - (number-of-analyses) defines the number of observations / analyses to be saved;\nspin - discrete number of tanl intervals to spin-up for the integration of the dynamical system solution to guarantee a stationary observation generating process;\ndiffusion - determines intensity of the random perturbations in the integration scheme;","category":"page"},{"location":"submodules/experiments/GenerateTimeSeries/","page":"GenerateTimeSeries","title":"GenerateTimeSeries","text":"Results are saved in .jld2 format in the data directory to be called by filter / smoother experiments cycling over the pseudo-observations.","category":"page"},{"location":"submodules/experiments/GenerateTimeSeries/#Time-series-experiments","page":"GenerateTimeSeries","title":"Time series experiments","text":"","category":"section"},{"location":"submodules/experiments/GenerateTimeSeries/","page":"GenerateTimeSeries","title":"GenerateTimeSeries","text":"Modules = [DataAssimilationBenchmarks.GenerateTimeSeries]","category":"page"},{"location":"submodules/experiments/GenerateTimeSeries/#DataAssimilationBenchmarks.GenerateTimeSeries.IEEE39bus_time_series-Tuple{NamedTuple{(:seed, :h, :tanl, :nanl, :spin, :diffusion), <:Tuple{Int64, Float64, Float64, Int64, Int64, Float64}}}","page":"GenerateTimeSeries","title":"DataAssimilationBenchmarks.GenerateTimeSeries.IEEE39bus_time_series","text":"IEEE39bus_time_series((seed::Int64, h:Float64, tanl::Float64, nanl::Int64, spin::Int64,\n                       diffusion::Float64)::NamedTuple)\n\nSimulate a \"free run\" time series of the IEEE39bus for generating an observation process and truth twin for data assimilation twin experiments. Output from the experiment is saved in a dictionary of the form,\n\nDict{String, Any}(\n                  \"seed\" => seed,\n                  \"h\" => h,\n                  \"diffusion\" => diffusion,\n                  \"diff_mat\" => diff_mat,\n                  \"dx_params\" => dx_params,\n                  \"tanl\" => tanl,\n                  \"nanl\" => nanl,\n                  \"spin\" => spin,\n                  \"obs\" => obs,\n                  \"model\" => \"IEEE39bus\"\n                 )\n\nExperiment output is written to a directory defined by\n\npath = pkgdir(DataAssimilationBenchmarks) * \"/src/data/time_series/\"\n\nwhere the file name is written dynamically according to the selected parameters as follows:\n\n\"IEEE39bus_time_series_seed_\" * lpad(seed, 4, \"0\") *\n\"_diff_\" * rpad(diffusion, 5, \"0\") *\n\"_tanl_\" * rpad(tanl, 4, \"0\") *\n\"_nanl_\" * lpad(nanl, 5, \"0\") *\n\"_spin_\" * lpad(spin, 4, \"0\") *\n\"_h_\" * rpad(h, 5, \"0\") *\n\".jld2\"\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/GenerateTimeSeries/#DataAssimilationBenchmarks.GenerateTimeSeries.L96_time_series-Tuple{NamedTuple{(:seed, :h, :state_dim, :tanl, :nanl, :spin, :diffusion, :F), <:Tuple{Int64, Float64, Int64, Float64, Int64, Int64, Float64, Float64}}}","page":"GenerateTimeSeries","title":"DataAssimilationBenchmarks.GenerateTimeSeries.L96_time_series","text":"L96_time_series((seed::Int64, h::Float64, state_dim::Int64, tanl::Float64, nanl::Int64,\n                 spin::Int64, diffusion::Float64, F::Float64)::NamedTuple)\n\nSimulate a \"free run\" time series of the Lorenz-96 model model for generating an observation process and truth twin for data assimilation twin experiments. Output from the experiment is saved in a dictionary of the form,\n\nDict{String, Any}(\n                  \"seed\" => seed,\n                  \"h\" => h,\n                  \"diffusion\" => diffusion,\n                  \"dx_params\" => dx_params,\n                  \"tanl\" => tanl,\n                  \"nanl\" => nanl,\n                  \"spin\" => spin,\n                  \"state_dim\" => state_dim,\n                  \"obs\" => obs,\n                  \"model\" => \"L96\"\n                 )\n\nExperiment output is written to a directory defined by\n\npath = pkgdir(DataAssimilationBenchmarks) * \"/src/data/time_series/\"\n\nwhere the file name is written dynamically according to the selected parameters as follows:\n\n\"L96_time_series_seed_\" * lpad(seed, 4, \"0\") *\n\"_dim_\" * lpad(state_dim, 2, \"0\") *\n\"_diff_\" * rpad(diffusion, 5, \"0\") *\n\"_F_\" * lpad(F, 4, \"0\") *\n\"_tanl_\" * rpad(tanl, 4, \"0\") *\n\"_nanl_\" * lpad(nanl, 5, \"0\") *\n\"_spin_\" * lpad(spin, 4, \"0\") *\n\"_h_\" * rpad(h, 5, \"0\") *\n\".jld2\"\n\n\n\n\n\n","category":"method"},{"location":"submodules/models/IEEE39bus/#IEEE39bus","page":"IEEE39bus","title":"IEEE39bus","text":"","category":"section"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"This is a version of the IEEE-39 bus test case as described by  Nishikawa, T. et al. The model, denoted the \"effective network\", consists of the ten generator buses in the network with all other buses eliminated by the classical Kron reduction. The power flow is described in steady state by a fixed point of the nonlinear swing equations","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"beginalign\nfrac2H_iomega_mathrmR ddotdelta_i + fracD_iomega_mathrmR dotdelta_i = A_i^mathrmEN - sum_j =1 jneq i^n_g K_ijsinleft(delta_i - delta_j -gamma_ij^mathrmENright)\nendalign","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"where we define each of the following:","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"the angular reference frequency (in radians) about which the steady state synchronizes is defined as omega_mathrmR;\nthe angle of rotation of the generator rotor at bus i, relative to the frame rotating at the reference frequency, is defined as delta_i(t);\nthe difference between the reference frequency and the frequency of the rotor at bus i is defined dotdelta_i(t);\nthe rate of acceleration of the difference between the angle of the rotor at bus i and the frame rotating at the reference frequency is defined as ddotdelta_i(t);\nthe values of the inertia and damping at bus i are defined as H_i and D_i respectively;\nthe strength of the dynamical coupling of the buses i and j is defined as K_ij, while gamma_ij represents the phase shift involved in the coupling of these buses;\nthe active power injected into the network by the generator at bus i is represented by A^mathrmEN_i; and\nthe number of generators in the network is defined as n_g =10.","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"This model assumes constant, passive loads at each bus that draws power. The actual parameters used in the model are defined by files in the","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"DataAssimilationBenchmarks/src/models/IEEE39bus_inputs/","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"directory, taken from the configuration studied by  Nishikawa, T. et al., with details on their interpretation in section 4.1.","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"The stochastic form in this code loosens the assumption of constant loads in this model by assuming that, at the time scale of interest, the draw of power fluctuates randomly about the constant level that defines the steady state. We introduce a Wiener process to  the above equations of the form  s W_i(t), where s is a parameter in the model controlling the relative diffusion level.  We assume that the fluctuations in the net power are uncorrelated across buses and that the diffusion in all buses is proportional to s. ","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"Making a change of variables psi_i =  dotdelta_i, we recover the system of nonlinear SDEs,","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"beginalign\ndotdelta_i = psi_i\nendalign","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"beginalign\ndotpsi_i = fracA^mathrmEN_i omega_mathrmR2H_i - fracD_i2H_i psi_i -\nsum_j=1jneq i^n_g fracK_ij^mathrmENomega_mathrmR2H_i sinleft(delta_i - delta_j -gamma_ij^mathrmENright) + frac s omega_R2 H_i mathrmdW_i(t)\nendalign","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"The diffusion level s controls the standard deviation of the Gaussian process","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"beginalign\nfracs omega_R2H_i W_iDelta_tdoteq fracs omega_R2H_ileft(W_i(Delta + t) - W_i(t)right)\nendalign","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"By definition the standard deviation of W_iDelta_t is equal to sqrtDelta so that for each time-discretization of the Wiener process of step size Delta, fracs omega_R2 H_iW_iDelta_t is a mean zero, Gaussian distributed variable with standard deviation fracs omega_mathrmR2sqrtDelta.  The reference frequency in North America is 60 Hz and the tolerable deviation from this frequency under normal operations is approximately pm 005 Hz, or of magnitude approximately 008.  In the above model, the reference frequency is in radians, related to the reference frequency in Hz as omega_mathrmR = 60 mathrmHz times 2 pi approx 37699.  This makes the tolerable limit of perturbations to the frequency approximately 03 radians under normal operations.","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"By definition psi_i is the i-th frequency relative to the reference frequency omega_mathrmR. One should choose s sufficiently small such that the probability that the size of a perturbation to the frequency ","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"beginalign\nparallel fracs omega_mathrmR2 H_imathbfW_Delta_t parallelgeq 03\nendalign","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"is small.  Simulating the model numerically with the four-stage, stochastic Runge-Kutta algorithm DataAssimilationBenchmarks.DeSolvers.rk4_step! a step size of Delta=001 is recommended, so that the standard deviation of a perturbation to the i-th relative frequency psi_i at any time step is fracs omega_mathrmR20 H_i. The smallest inertia parameter in the model is approximately 243, so that three standard deviations of the perturbation to the frequency is bounded as","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"beginalign\nfracsomega_mathrmR20 times 243 times 3 leq 003  Leftrightarrow  s leqfrac486omega_mathrmR approx 00129\nendalign","category":"page"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"For s leq 0012, we bound the standard deviation of each component, fracs omega_mathrmR2H_isqrtDelta, of the perturbation vector by 001 so that over 997 of perturbations to the i-th frequency have size less than 003.","category":"page"},{"location":"submodules/models/IEEE39bus/#Methods","page":"IEEE39bus","title":"Methods","text":"","category":"section"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"Modules = [DataAssimilationBenchmarks.IEEE39bus]","category":"page"},{"location":"submodules/models/IEEE39bus/#DataAssimilationBenchmarks.IEEE39bus.dx_dt-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Union{Dict{String, Array{T1}}, Dict{String, Vector{T1}}} where T1<:T}} where T<:Real","page":"IEEE39bus","title":"DataAssimilationBenchmarks.IEEE39bus.dx_dt","text":"dx_dt(x::VecA(T), t::Float64, dx_params::ParamDict(T)) where T <: Real\n\nTime derivative of the phase and fequency of the effective-network swing equation model. Input x is a 2 n_g VecA of the phase and fequency at each of the n_g generator buses. The input dx_params of type ParamDict containing system parameters to be passed to the integration scheme.  The system is currenty defined autonomously to be run as an SDE, noise perturbed steady state.\n\n\n\n\n\n","category":"method"},{"location":"home/Introduction/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"home/Introduction/#Statement-of-purpose","page":"Introduction","title":"Statement of purpose","text":"","category":"section"},{"location":"home/Introduction/","page":"Introduction","title":"Introduction","text":"The purpose of this package is to provide a research framework for the theoretical development and empirical validation of novel data assimilation techniques. While analytical proofs can be derived for classical methods such as the Kalman filter in linear-Gaussian dynamics, most currently developed DA techniques are designed for estimation in nonlinear, non-Gaussian models where no analytical solution typically exists.  Rigorous validation of novel data assimilation methods, therefore, must be performed with reproducible numerical simulations in standard test-cases in order to demonstrate the effectiveness and computational performance of the proposed technique. Pursuant to proposing a novel DA method, one should likewise compare its performance with other standard methods within the same class of estimators.","category":"page"},{"location":"home/Introduction/","page":"Introduction","title":"Introduction","text":"This package implements a variety of standard data assimilation algorithms, including some of the widely used performance modifications that are used in practice to tune these estimators. Standard libraries exist for full-scale DA system research and development, e.g., the Data Assimilation Research Testbed (DART), but there are fewer standard options for theoretical research and algorithm development in simple test systems. Many basic research frameworks, furthermore, do not include standard operational techniques developed from classical VAR methods, due to the  difficulty in constructing tangent linear and adjoint codes. DataAssimilationBenchmarks.jl provides one framework for studying squential filters and smoothers that are commonly used in online, geoscientific prediction settings, including ensemble estimators, classical VAR techniques (currently in-development) and (in-planning) hybrid-EnVAR methods. ","category":"page"},{"location":"home/Introduction/#Validated-methods-currently-in-use","page":"Introduction","title":"Validated methods currently in use","text":"","category":"section"},{"location":"home/Introduction/","page":"Introduction","title":"Introduction","text":"For a discussion of the below methods and benchmarks for their validation, please see the manuscript A fast, single-iteration ensemble Kalman smoother for sequential data assimilation.","category":"page"},{"location":"home/Introduction/","page":"Introduction","title":"Introduction","text":"<table>\n<tr>\n\t<th>Estimator / implemented techniques</th>\n\t<th>Tuned multiplicative inflation</th>\n\t<th>Adaptive inflation, finite-size formalism (perfect model dual / primal)</th>\n\t<th>Adaptive inflation, finite-size formalism (imperfect model)</th>\n\t<th>Linesearch</th>\n\t<th>Localization / Hybridization</th>\n\t<th>Multiple data assimilation (general shift and lag)</th>\n</tr>\n<tr>\n  <td> ETKF </td>\n\t<td> X  </td>\n\t<td> X  </td>\n\t<td>    </td>\n\t<td> NA </td>\n\t<td>    </td>\n\t<td> NA </td>\n</tr>\n<tr>\n  <td> MLEF, transform / bundle variants</td>\n\t<td> X  </td>\n\t<td> X  </td>\n\t<td>    </td>\n\t<td> X  </td>\n\t<td>    </td>\n\t<td> NA </td>\n</tr>\n<tr>\n  <td> ETKS</td>\n\t<td> X  </td>\n\t<td> X  </td>\n\t<td>    </td>\n\t<td> NA </td>\n\t<td>    </td>\n\t<td> NA </td>\n</tr>\n<tr>\n  <td> MLES, transform / bundle variants</td>\n\t<td> X  </td>\n\t<td> X  </td>\n\t<td>    </td>\n\t<td> X  </td>\n\t<td>    </td>\n\t<td> NA </td>\n</tr>\n<tr>\n  <td>SIEnKS, ETKF / MLEF-transform variants</td>\n\t<td> X </td>\n\t<td> X </td>\n\t<td>   </td>\n\t<td> X </td>\n\t<td>   </td>\n\t<td> X </td>\n</tr>\n<tr>\n  <td>Gauss-Newton IEnKS, transform / bundle variants</td>\n\t<td> X </td>\n\t<td> X </td>\n\t<td>   </td>\n\t<td>   </td>\n\t<td>   </td>\n\t<td> X </td>\n</tr>\n</table>","category":"page"},{"location":"submodules/analysis/ProcessExperimentData/#Analysis","page":"ProcessExperimentData","title":"Analysis","text":"","category":"section"},{"location":"submodules/analysis/ProcessExperimentData/#Processing-experiment-outputs","page":"ProcessExperimentData","title":"Processing experiment outputs","text":"","category":"section"},{"location":"submodules/analysis/ProcessExperimentData/","page":"ProcessExperimentData","title":"ProcessExperimentData","text":"The analysis directory contains scripts for batch processing the outputs from experiments into time-averaged RMSE and spread and arranging these outputs in an array for plotting.  This should be modified based on the local paths to stored data.  This will try to load files based on parameter settings written in the name of the output .jld2 file and if this is not available, this will store Inf values in the place of missing data.","category":"page"},{"location":"submodules/analysis/ProcessExperimentData/#Validating-results","page":"ProcessExperimentData","title":"Validating results","text":"","category":"section"},{"location":"submodules/analysis/ProcessExperimentData/","page":"ProcessExperimentData","title":"ProcessExperimentData","text":"Benchmark configurations for the above filtering and smoothing experiments are available in the open access article A fast, single-iteration ensemble Kalman smoother for sequential data assimilation, with details on the algorithm and parameter specifications discussed in the experiments section.  Performance of filtering and smoothing schemes should be validated versus the numerical results presented there for root mean square error and ensemble spread. Simple versions of these diagnostics are built for automatic testing of the filter and smoother experiments for state and parameter estimation in the L96-s model.  Further test cases are currently in development.  The deterministic Runge-Kutta and Euler scheme for ODEs are validated in the package tests, estimating the order of convergence with the least-squares log-10 line fit between step size and discretization error.  Test cases for the stochastic integration schemes are in development, but numerical results with these schemes can be validated versus the results in the open-access article  On the numerical integration of the Lorenz-96 model, with scalar additive noise, for benchmark twin experiments.","category":"page"},{"location":"#Description","page":"Home","title":"Description","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is a data assimilation research code base with an emphasis on prototyping, testing and validating sequential filters and smoothers in toy model twin experiments. This code is meant to be performant in the sense that large hyper-parameter discretizations can be explored to determine hyper-parameter sensitivity and reliability of results across different experimental regimes, with parallel implementations in native Julia distributed computing.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package currently includes code for developing and testing data assimilation schemes in the L96-s model and the IEEE 39 bus test case in the form of the effective network model model equations. New toy models and data assimilation schemes are in continuous development in the development branch.  Currently validated techniques are available in the master branch.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package supported the development of all numerical results and benchmark simulations in the pre-print A fast, single-iteration ensemble Kalman smoother for sequential data assimilation available currently in open review in Geoscientific Model Development.","category":"page"},{"location":"submodules/models/L96/#Lorenz-96-model","page":"L96","title":"Lorenz-96 model","text":"","category":"section"},{"location":"submodules/models/L96/","page":"L96","title":"L96","text":"The classical form for the (single-layer) Lorenz-96 equations are defined as ","category":"page"},{"location":"submodules/models/L96/","page":"L96","title":"L96","text":"beginalign\nfracmathrmdpmbxmathrmd t = pmbf(pmbx)\nendalign","category":"page"},{"location":"submodules/models/L96/","page":"L96","title":"L96","text":"where for each state component iin1cdotsn,","category":"page"},{"location":"submodules/models/L96/","page":"L96","title":"L96","text":"beginalign\nf^i(pmbx) =-x^i-2x^i-1 + x^i-1x^i+1 - x^i + F\nendalign","category":"page"},{"location":"submodules/models/L96/","page":"L96","title":"L96","text":"such that the components of the vector pmbx are given by the variables x^i with periodic boundary conditions, x^0=x^n, x^-1=x^n-1 and x^n+1=x^1.  The term F in the Lorenz-96 system is the forcing parameter that injects energy to the model. With the above definition for the classical Lorenz-96 equations, we define the L96-s model with additive noise (of scalar covariance) as","category":"page"},{"location":"submodules/models/L96/","page":"L96","title":"L96","text":"beginalign\nfracmathrmd pmbxmathrmd t = pmbf(pmbx) + s(t)mathbfI_npmbW(t)\nendalign","category":"page"},{"location":"submodules/models/L96/","page":"L96","title":"L96","text":"where pmbf is defined as in the classical equations, mathbfI_n is the ntimes n identity matrix, pmbW(t) is an n-dimensional Wiener process and s(t)mathbbRrightarrow mathbbR is a measurable function of (possibly) time-varying diffusion coefficients. This model is analyzed in-depth for data assimilation twin experiments in the manuscript Grudzien, C. et al. (2020). and further details of using the system for data assimilation benchmarks in stochastic dynamics are discussed there.  The methods in the below define the model equations, the Jacobian, and the order 2.0 Taylor-Stratonovich scheme derived especially for statistically robust numerical simulation of the truth twin of the L96-s system.","category":"page"},{"location":"submodules/models/L96/#Methods","page":"L96","title":"Methods","text":"","category":"section"},{"location":"submodules/models/L96/","page":"L96","title":"L96","text":"Modules = [DataAssimilationBenchmarks.L96]","category":"page"},{"location":"submodules/models/L96/#DataAssimilationBenchmarks.L96.compute_α_ρ-Tuple{Int64}","page":"L96","title":"DataAssimilationBenchmarks.L96.compute_α_ρ","text":"compute_α_ρ(p::Int64)\n\nComputes auxiliary functions for the 2nd order Taylor-Stratonovich expansion. The constants α and ρ need to be computed once, only as a function of the order of truncation of the Fourier series, the argument p, for the integration method.  These constants are then supplied as arguments to l96s_tay2_step! in kwargs. See l96s_tay2_step! for the interpretation and usage of these constants.\n\nreturn α(p)::Float64, ρ(p)::Float64\n\n\n\n\n\n","category":"method"},{"location":"submodules/models/L96/#DataAssimilationBenchmarks.L96.dx_dt-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Union{Dict{String, Array{T1}}, Dict{String, Vector{T1}}} where T1<:T}} where T<:Real","page":"L96","title":"DataAssimilationBenchmarks.L96.dx_dt","text":"dx_dt(x::VecA(T), t::Float64, dx_params::ParamDict(T)) where T <: Real\n\nTime derivative for Lorenz-96 model, x is a  model state of size state_dim and type VecA, t is a dummy time argument for consistency with integration methods, dx_params is of type ParamDict which is called for the forcing parameter.\n\nReturns time derivative of the state vector\n\nreturn dx\n\n\n\n\n\n","category":"method"},{"location":"submodules/models/L96/#DataAssimilationBenchmarks.L96.jacobian-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Union{Dict{String, Array{T1}}, Dict{String, Vector{T1}}} where T1<:T}} where T<:Real","page":"L96","title":"DataAssimilationBenchmarks.L96.jacobian","text":"jacobian(x::VecA(T), t::Float64, dx_params::ParamDict(T)) where T <: Real\n\nComputes the Jacobian of Lorenz-96 about the state x of type VecA. The time variable t is a dummy variable for consistency with integration methods, dx_params is of type ParamDict which is called for the forcing parameter. Note that this is designed to load entries in a zeros array and return a sparse array to make a compromise between memory and computational resources.\n\nreturn sparse(dxF)\n\n\n\n\n\n","category":"method"},{"location":"submodules/models/L96/#DataAssimilationBenchmarks.L96.l96s_tay2_step!-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Dict{String, Any}}} where T<:Real","page":"L96","title":"DataAssimilationBenchmarks.L96.l96s_tay2_step!","text":"l96s_tay2_step!(x::VecA(T), t::Float64, kwargs::StepKwargs) where T <: Real\n\nOne step of integration rule for l96 second order taylor rule The constants ρ and α are to be computed with compute_α_ρ, depending only on p, and supplied for all steps. This is the general formulation which includes, e.g., dependence on the truncation of terms in the auxilliary function C with respect to the parameter p.  In general, truncation at p=1 is all that is necessary for order 2.0 convergence.\n\nThis method is derived in Grudzien, C. et al. (2020). NOTE: this Julia version still pending validation as in the manuscript\n\nreturn x\n\n\n\n\n\n","category":"method"},{"location":"submodules/models/L96/#DataAssimilationBenchmarks.L96.mod_indx!-Tuple{Int64, Int64}","page":"L96","title":"DataAssimilationBenchmarks.L96.mod_indx!","text":"mod_indx!(indx::Int64, dim::Int64)\n\nAuxiliary function to return state vector indices for the Lorenz-96 model, where indx is taken mod dim.  Mod zero is replaced with dim for indexing in Julia state vectors.\n\n\n\n\n\n","category":"method"}]
}

var documenterSearchIndex = {"docs":
[{"location":"submodules/methods/EnsembleKalmanSchemes/#Ensemble-Kalman-Schemes","page":"EnsembleKalmanSchemes","title":"Ensemble Kalman Schemes","text":"","category":"section"},{"location":"submodules/methods/EnsembleKalmanSchemes/#API-for-data-assimilation-solvers","page":"EnsembleKalmanSchemes","title":"API for data assimilation solvers","text":"","category":"section"},{"location":"submodules/methods/EnsembleKalmanSchemes/","page":"EnsembleKalmanSchemes","title":"EnsembleKalmanSchemes","text":"There are currently four families of data assimilation solvers available in this package, which define the outer-loop of the data assimilation cycle.  Particularly, these define how the sequential data assimilation cycle will pass over a time series of observations.  Ensemble filters run only forward-in-time.  The classic lag-shift smoother runs identically to the filter in its forecast and filter steps, but includes an additional retrospective analysis to past ensemble states stored in memory.  The single iteration smoother follows the same convention as the classic smoother, except in that new cycles are initiated from a past, reanlyzed ensemble state.  The Gauss-Newton iterative smoothers are 4D smoothers, which iteratively optimize the initial condition at the beginning of a data assimilation cycle, and propagate this initial condition to initialize the subsequent cycle.  A full discussion of these methods can be found in Grudzien, et al. 2021.","category":"page"},{"location":"submodules/methods/EnsembleKalmanSchemes/","page":"EnsembleKalmanSchemes","title":"EnsembleKalmanSchemes","text":"For each outer-loop method defining the data assimilation cycle, different types of analyses can be specified within their arguments.  Likewise, these outer-loop methods require arguments such as the ensemble state or the range of ensemble states to analyze, an observation to assimilate or a range of observations to assimilate, as the observation error covariances, the ensemble covariance inflation parameter and key word arguments for running the underlying dynamical state model. Examples of the syntax are below:","category":"page"},{"location":"submodules/methods/EnsembleKalmanSchemes/","page":"EnsembleKalmanSchemes","title":"EnsembleKalmanSchemes","text":"ensemble_filter(analysis::String, ens::ArView(T), obs::VecA(T), obs_cov::CovM(T),\n    state_infl::Float64, kwargs::StepKwargs) where T <: Float64\n\nls_smoother_classic(analysis::String, ens::ArView(T), obs::ArView(T), obs_cov::CovM(T),\n    state_infl::Float64, kwargs::StepKwargs) where T <: Float64\n\nls_smoother_single_iteration(analysis::String, ens::ArView(T), obs::ArView(T),\n    obs_cov::CovM(T), state_infl::Float64, kwargs::StepKwargs) where T <: Float64\n\nls_smoother_gauss_newton(analysis::String, ens::ArView(T), obs::ArView(T), obs_cov::CovM(T),\n    state_infl::Float64, kwargs::StepKwargs; ϵ::Float64=0.0001, tol::Float64=0.001,\n\t\tmax_iter::Int64=10) where T <: Float64\n\n\n\"\"\"\nanalysis   -- string name analysis scheme given to the transform sub-routine\nens        -- ensemble matrix defined by the array with columns given by the replicates of\n              the model state\nobs        -- observation vector for the current analysis in ensemble_filter / array with\n              columns given by the observation vectors for the ordered sequence of analysis\n\t\t\t\t\t\t\ttimes in the current smoothing window\nobs_cov    -- observation error covariance matrix\nstate_infl -- multiplicative covariance inflation factor for the state variable covariance\nkwargs     -- keyword arguments for parameter estimation or other functionality, including\n              integration parameters for the state model in smoothing schemes\n\"\"\"","category":"page"},{"location":"submodules/methods/EnsembleKalmanSchemes/","page":"EnsembleKalmanSchemes","title":"EnsembleKalmanSchemes","text":"The type of analysis to be passed to the transform step is specified with the analysis string, with partiuclar analysis methods described below.  Observations for the filter schemes correspond to information available at a single analysis time giving an observation of the state vector of type VecA. The ls (lag-shift) smoothers require an array of observations of type ArView corresponding to all analysis times within the DAW. Observation covariances are typed as CovM for efficiency. The state_infl is a required tuneable parameter for multiplicative covariance inflation.   Extended parameter state covariance inflation can be specified in kwargs.  These outer-loops will pass the required values to the DataAssimilationBenchmarks.EnsembleKalmanSchemes.transform_R method that generates the ensemble transform for conditioning on observations. Utility scripts to generate observation operators, analyze ensemble statistics, etc, are included in the below. ","category":"page"},{"location":"submodules/methods/EnsembleKalmanSchemes/#Methods","page":"EnsembleKalmanSchemes","title":"Methods","text":"","category":"section"},{"location":"submodules/methods/EnsembleKalmanSchemes/","page":"EnsembleKalmanSchemes","title":"EnsembleKalmanSchemes","text":"Modules = [DataAssimilationBenchmarks.EnsembleKalmanSchemes]","category":"page"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_obs_operator-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Int64, Dict{String, Any}}} where T<:Real","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_obs_operator","text":"alternating_obs_operator(ens::ArView(T), obs_dim::Int64,\n                         kwargs::StepKwargs) where T <: Real\n\nThis produces observations of alternating state vector components for generating pseudo-data.\n\nreturn obs\n\nThis operator takes either a truth twin time series or an ensemble of states of type ArView, and maps this data to the observation space via the method alternating_projector and (possibly) a nonlinear transform.  The truth twin in this version is assumed to be 2D, where the first index corresponds to the state dimension and the second index corresponds to the time dimension.  The ensemble is assumed to be 2D where the first index corresponds to the state dimension and the second index corresponds to the ensemble dimension.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_obs_operator-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Int64, Dict{String, Any}}} where T<:Real","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_obs_operator","text":"alternating_obs_operator(x::VecA(T), obs_dim::Int64, kwargs::StepKwargs) where T <: Real\n\nThis produces observations of alternating state vector components for generating pseudo-data.\n\nreturn obs\n\nThis operator takes a single model state x of type VecA and maps this data to the observation space via the method alternating_projector and (possibly) a  nonlinear transform. The γ parameter (optional) in kwargs of type  StepKwargs controls the component-wise transformation of the remaining state vector components mapped to the observation space.  For γ=1.0, there is no transformation applied, and the observation operator acts as a linear projection onto the remaining components of the state vector, equivalent to not specifying γ. For γ>1.0, the nonlinear observation operator of  Asch, et al. (2016)., pg. 181 is applied, which limits to the identity for γ=1.0.  If γ=0.0, the quadratic observation operator of Hoteit, et al. (2012). is applied to the remaining state components.  If γ<0.0, the exponential observation operator of Wu, et al. (2014). is applied to the remaining state vector components.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_projector!-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Int64}} where T<:Real","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_projector!","text":"alternating_projector!(ens::ArView(T), obs_dim::Int64) where T <: Real\n\nUtility method produces a projection of alternating ensemble components in-place via slicing.\n\nreturn ens\n\nThis operator takes either a truth twin time series or an ensemble of states of type ArView, and maps this data to alternating row components.  The truth twin in this version is assumed to be 2D, where the first index corresponds to the state dimension and the second index corresponds to the time dimension.  The ensemble is assumed to be 2D where the first index corresponds to the state dimension and the second index corresponds to the ensemble dimension. States correpsonding to even state dimension indices are removed from the state vector until the observation dimension is appropriate.  If the observation dimension is less than half the state dimension, states corresponding to odd state dimension idices are subsequently removed until the observation dimension is appropriate.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_projector!-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Int64}} where T<:Real","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_projector!","text":"alternating_projector!(x::VecA(T), obs_dim::Int64) where T <: Real\n\nUtility method produces a projection of alternating vector components via slicing.\n\nreturn x\n\nThis operator takes a single model state x of type VecA and maps this data to alternating entries.  The operator selects components of the vector based on the observation dimension.  States correpsonding to even state dimension indices are removed from the state vector until the observation dimension is appropriate. If the observation dimension is less than half the state dimension, states corresponding to odd state dimension idices are subsequently removed until the observation dimension is appropriate.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Vector{T1}, SubArray{T1, 1}} where T1<:T}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens","text":"analyze_ens(ens::ArView(T), truth::VecA(T)) where T <: Float64\n\nComputes the ensemble state RMSE as compared with truth twin, and the ensemble spread.\n\nreturn rmse, spread\n\nNote: the ensemble ens should only include the state vector components to compare with the truth twin state vector truth, without replicates of the model parameters.  These can be passed as an ArView for efficient memory usage.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens_param-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Vector{T1}, SubArray{T1, 1}} where T1<:T}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.analyze_ens_param","text":"analyze_ens_param(ens::ArView(T), truth::VecA(T)) where T <: Float64\n\nComputes the ensemble parameter RMSE as compared with truth twin, and the ensemble spread.\n\nreturn rmse, spread\n\nNote: the ensemble ens should only include the extended state vector components consisting of model parameter replicates to compare with the truth twin's governing model parameters truth.  These can be passed as an ArView for efficient memory usage.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_gauss_newton-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Dict{String, Any}}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_gauss_newton","text":"ens_gauss_newton(analysis::String, ens::ArView(T), obs::VecA(T), \n                 obs_cov::CovM(T), kwargs::StepKwargs;\n                 conditioning::ConM(T)=1000.0I, \n                 m_err::ArView(T)=(1.0 ./ zeros(1,1)),\n                 tol::Float64 = 0.0001,\n                 j_max::Int64=40,\n                 Q::CovM(T)=1.0I) where T <: Float64\n\nComputes the ensemble estimated gradient and Hessian terms for nonlinear least-squares\n\nreturn ∇_J, Hess_J\n\nm_err, tol, j_max, Q are optional arguments depending on the analysis, with  default values provided.\n\nServes as an auxilliary function for IEnKS(-N), where \"analysis\" is a string which determines the method of transform update ensemble Gauss-Newton calculation.  The observation error covariance obs_cov is of type CovM, the conditioning matrix conditioning is of type ConM, the keyword arguments dictionary kwargs is of type StepKwargs and the model error covariance matrix Q is of type CovM.\n\nCurrently validated analysis options:\n\nanalysis == \"ienks-bundle\" || \"ienks-n-bundle\" || \"ienks-transform\" || \"ienks-n-transform\" computes the weighted observed anomalies as per the   bundle or transform version of the IEnKS, described in Bocquet & Sakov 2013, Grudzien, et al. 2021. Bundle versus tranform versions of the scheme are specified by the trailing analysis string as -bundle or -transform.  The bundle version uses a small uniform  scalar ϵ, whereas the transform version uses a matrix square root inverse as the conditioning operator. This form of analysis differs from other schemes by returning a sequential-in-time value for the cost function gradient and Hessian, which will is utilized within the iterative smoother optimization.  A finite-size inflation scheme, based on the EnKF-N above, can be utilized by appending additionally a -n to the -bundle or -transform version of the IEnKS scheme specified in analysis.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_update_RT!-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Tuple{LinearAlgebra.Symmetric{T1, Matrix{T1}}, Vector{T1}, Matrix{T1}}, Tuple{LinearAlgebra.Symmetric{T1, Matrix{T1}}, Matrix{T1}, Matrix{T1}}} where T1<:T}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.ens_update_RT!","text":"ens_update_RT!(ens::ArView(T), transform::TransM(T)) where T <: Float64\n\nUpdates forecast ensemble to the analysis ensemble by right transform (RT) method. \n\nreturn ens\n\nArguments include the ensemble of type ArView and the 3-tuple including the right transform for the anomalies, the weights for the mean and the random, mean-preserving orthogonal matrix, type TransM.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ensemble_filter-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Float64, Dict{String, Any}}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.ensemble_filter","text":"ensemble_filter(analysis::String, ens::ArView(T), obs::VecA(T), obs_cov::CovM(T),\n                s_infl::Float64, kwargs::StepKwargs) where T <: Float64\n\nGeneral filter analysis step, wrapping the right transform / update, and inflation steps. Optional keyword argument includes state_dim for extended state including parameters. In this case, a value for the parameter covariance inflation should be included in addition to the state covariance inflation.\n\nreturn Dict{String,Array{Float64,2}}(\"ens\" => ens)\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_param!-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Float64, Int64, Int64}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_param!","text":"inflate_param!(ens::ArView(T), inflation::Float64, sys_dim::Int64,\n               state_dim::Int64) where T <: Float64\n\nApplies multiplicative covariance inflation to parameter replicates in the ensemble matrix.\n\nreturn ens\n\nThe first index of the ensemble matrix ens corresponds to the length sys_dim (extended) state dimension while the second index corresponds to the ensemble dimension.  Dynamic state variables are assumed to be in the leading state_dim rows of ens, while extended state parameter replicates are after. Multiplicative inflation is performed only in the trailing  state_dim + 1: state_dim components of the ensemble anomalies from the ensemble mean, in-place in memory.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_state!-Union{Tuple{T}, Tuple{Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Float64, Int64, Int64}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.inflate_state!","text":"inflate_state!(ens::ArView(T), inflation::Float64, sys_dim::Int64,\n               state_dim::Int64) where T <: Float64\n\nApplies multiplicative covariance inflation to the state components of the ensemble matrix.\n\nreturn ens\n\nThe first index of the ensemble matrix ens corresponds to the length sys_dim (extended) state dimension while the second index corresponds to the ensemble dimension.  Dynamic state variables are assumed to be in the leading state_dim rows of ens, while extended state parameter replicates are after. Multiplicative inflation is performed only in the leading components of the ensemble anomalies from the ensemble mean, in-place in memory.\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_classic-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Float64, Dict{String, Any}}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_classic","text":"ls_smoother_classic(analysis::String, ens::ArView(T), obs::ArView(T),\n                    obs_cov::CovM(T), s_infl::Float64,\n                    kwargs::StepKwargs) where T <: Float64\n\nLag-shift ensemble Kalman smoother analysis step, classical version.\n\nClassic EnKS uses the last filtered state for the forecast, different from the  iterative schemes which use the once or multiple-times re-analized posterior for the initial condition for the forecast of the states to the next shift.\n\nOptional argument includes state dimension for extended state including parameters. In this case, a value for the parameter covariance inflation should be included in addition to the state covariance inflation.\n\nreturn Dict{String,Array{Float64}}(\n                                   \"ens\" => ens, \n                                   \"post\" =>  posterior, \n                                   \"fore\" => forecast, \n                                   \"filt\" => filtered\n                                  ) \n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_gauss_newton-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Float64, Dict{String, Any}}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_gauss_newton","text":"ls_smoother_gauss_newton(analysis::String, ens::ArView(T),\n                         obs::ArView(T), obs_cov::CovM(T), s_infl::Float64,\n                         kwargs::StepKwargs; ϵ::Float64=0.0001,\n                         tol::Float64=0.001, max_iter::Int64=5) where T <: Float64\n\nThis implements a lag-shift Gauss-Newton IEnKS analysis step as in algorithm 4 of Bocquet & Sakov 2014. The IEnKS uses the final re-analyzed initial state in the data assimilation window to generate the forecast, which is subsequently pushed forward in time from the initial conidtion to shift-number of observation times. Optional argument includes state dimension for an extended state including parameters. In this case, a value for the parameter covariance inflation should be included in addition to the state covariance inflation.\n\nreturn Dict{String,Array{Float64}}(\n                                   \"ens\" => ens, \n                                   \"post\" =>  posterior, \n                                   \"fore\" => forecast, \n                                   \"filt\" => filtered\n                                  ) \n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_single_iteration-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Float64, Dict{String, Any}}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.ls_smoother_single_iteration","text":"ls_smoother_single_iteration(analysis::String, ens::ArView(T),\n                             obs::ArView(T), obs_cov::CovM(T),\n                             s_infl::Float64, kwargs::StepKwargs) where T <: Float64\n\nLag-shift, single-iteration ensemble Kalman smoother (SIEnKS) analysis step.\n\nSingle-iteration EnKS uses the final re-analyzed posterior initial state for the forecast, which is pushed forward in time to shift-number of observation times. Optional argument includes state dimension for an extended state including parameters. In this case, a value for the parameter covariance inflation should be included in addition to the state covariance inflation.\n\nreturn Dict{String,Array{Float64}}(\n                                   \"ens\" => ens, \n                                   \"post\" =>  posterior, \n                                   \"fore\" => forecast, \n                                   \"filt\" => filtered\n                                  ) \n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.rand_orth-Tuple{Int64}","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.rand_orth","text":"rand_orth(N_ens::Int64)\n\nThis generates a random, mean-preserving, orthogonal matrix as in Sakov & Oke 2008, depending on the esemble size N_ens.\n\nreturn U\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root-Union{Tuple{LinearAlgebra.UniformScaling{T}}, Tuple{T}} where T<:Real","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root","text":"square_root(M::CovM(T)) where T <: Real\n\nComputes the square root of covariance matrices with parametric type.\n\nMultiple dispatches for the method are defined according to the sub-type of CovM, where the square roots of UniformScaling and Diagonal covariance matrices are computed directly, while the square roots of  the more general class of Symmetric covariance matrices are computed via the singular value decomposition, for stability and accuracy for close-to-singular matrices.\n\nreturn S\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root_inv-Union{Tuple{LinearAlgebra.UniformScaling{T}}, Tuple{T}} where T<:Real","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.square_root_inv","text":"square_root_inv(M::CovM(T); sq_rt::Bool=false, inverse::Bool=false,\n                full::Bool=false) where T <: Real\n\nComputes the square root inverse of covariance matrices with parametric type.\n\nMultiple dispatches for the method are defined according to the sub-type of CovM, where the square root inverses of UniformScaling and Diagonal covariance matrices are computed directly, while the square root inverses of the more general class of Symmetric covariance matrices are computed via the singular value decomposition, for stability and accuracy for close-to-singular matrices. This will optionally return a computation of the inverse and the square root itself all as a byproduct of the singular value decomposition for efficient numerical computation of ensemble analysis / update routines. \n\nOptional keyword arguments are specified as:\n\nsq_rt=true returns the matrix square root in addition to the square root inverse\ninverse=true returns the matrix inverse in addition to the square root inverse\nfull=true returns the square root and the matrix inverse in addition to the square  root inverse\n\nand are evaluated in the above order.\n\nOutput follows control flow:\n\nif sq_rt\n    return S_inv, S\nelseif inverse\n    return S_inv, M_inv\nelseif full\n    return S_inv, S, M_inv\nelse\n    return S_inv\nend\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/EnsembleKalmanSchemes/#DataAssimilationBenchmarks.EnsembleKalmanSchemes.transform_R-Union{Tuple{T}, Tuple{String, Union{Matrix{T1}, SubArray{T1, 2}} where T1<:T, Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Union{LinearAlgebra.Diagonal{T1, Vector{T1}}, LinearAlgebra.Symmetric{T1, Matrix{T1}}, LinearAlgebra.UniformScaling{T1}} where T1<:T, Dict{String, Any}}} where T<:Float64","page":"EnsembleKalmanSchemes","title":"DataAssimilationBenchmarks.EnsembleKalmanSchemes.transform_R","text":"transform_R(analysis::String, ens::ArView(T), obs::VecA(T),        \n            obs_cov::CovM(T), kwargs::StepKwargs; conditioning::ConM=1000.0I, \n            m_err::ArView(T)=(1.0 ./ zeros(1,1)),\n            tol::Float64 = 0.0001,\n            j_max::Int64=40,\n            Q::CovM(T)=1.0I) where T <: Float64\n\nComputes the ensemble transform and related values for various flavors of ensemble Kalman schemes. The output type is a tuple containing a right transform of the ensemble anomalies, the weights for the mean update and a random orthogonal transformation for stabilization:\n\nreturn trans, w, U\n\nwhere the tuple is of type TransM. m_err, tol, j_max, Q are optional arguments depending on the analysis, with  default values provided.\n\nServes as an auxilliary function for EnKF, ETKF(-N), EnKS, ETKS(-N), where \"analysis\" is a string which determines the type of transform update.  The observation error covariance obs_cov is of type CovM, the conditioning matrix conditioning is of type ConM, the keyword arguments dictionary kwargs is of type StepKwargs and the model error covariance matrix Q is of type CovM.\n\nCurrently validated analysis options:\n\nanalysis==\"etkf\" || analysis==\"etks\" computes the deterministic ensemble transform  as in the ETKF described in Grudzien, et al. 2021.\nanalysis[1:7]==\"mlef-ls\" || analysis[1:7]==\"mles-ls\" computes the maximum likelihood ensemble filter transform described in Grudzien, et al.  2021, optimizing the nonlinear cost function with Newton-based  line searches.\nanalysis[1:4]==\"mlef\" || analysis[1:4]==\"mles\" computes the maximum likelihood      ensemble filter transform described in Grudzien, et al. 2021, optimizing the nonlinear cost function with simple Newton-based scheme. \nanalysis==\"enkf-n-dual\" || analysis==\"enks-n-dual\"  computes the dual form of the EnKF-N transform as in Bocquet, et al. 2015 Note: this cannot be used with the nonlinear observation operator. This uses the Brent method for the argmin problem as this has been more reliable at finding a global minimum than Newton optimization.\nanalysis==\"enkf-n-primal\" || analysis==\"enks-n-primal\" computes the primal form of the EnKF-N transform as in Bocquet, et al. 2015, Grudzien, et al. 2021. This differs from the MLEF/S-N in that there is no approximate linearization of the observation operator in the EnKF-N, this only handles the approximation error with respect to the adaptive inflation. This uses a simple Newton-based minimization of the cost function for the adaptive inflation.\nanalysis==\"enkf-n-primal-ls\" || analysis==\"enks-n-primal-ls\" computes the primal form of the EnKF-N transform as in Bocquet, et al. 2015, Grudzien, et al. 2021. This differs from the MLEF/S-N in that there is no approximate linearization of the observation operator in the EnKF-N, this only handles the approximation error with respect to the adaptive inflation. This uses a Newton-based minimization of the cost function for the adaptive inflation with line searches.\n\n\n\n\n\n","category":"method"},{"location":"home/DataAssimilationBenchmarks/#Global-Types","page":"Global Types","title":"Global Types","text":"","category":"section"},{"location":"home/DataAssimilationBenchmarks/","page":"Global Types","title":"Global Types","text":"The following types are declared for optimizing numerical routines, for using multiple dispatch of functions with different specified input forms and for passing arguments  between inner / outer loop steps of the DA twin experiment.","category":"page"},{"location":"home/DataAssimilationBenchmarks/","page":"Global Types","title":"Global Types","text":"Modules = [DataAssimilationBenchmarks]","category":"page"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ParamSample","page":"Global Types","title":"DataAssimilationBenchmarks.ParamSample","text":"ParamSample = Dict{String, Vector{UnitRange{Int64}}}\n\nDictionary containing key and index pairs to subset the state vector and then merge a statistical sample of parameters that govern the equations of motion with the ParamDict dx_params in parameter estimation problems.\n\n\n\n\n\n","category":"type"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.StepKwargs","page":"Global Types","title":"DataAssimilationBenchmarks.StepKwargs","text":"StepKwargs = Dict{String,Any}\n\nKey word arguments for twin experiment time stepping. Arguments are given as:\n\n    REQUIRED:\n    dx_dt        -- time derivative function with arguments x and dx_params\n    dx_params    -- parameters necessary to resolve dx_dt, not including\n                    parameters to be estimated in the extended state vector \n    h            -- numerical time discretization step size\n\n    OPTIONAL:\n    γ            -- controls nonlinearity of the alternating_obs_operator\n    diffusion    -- tunes the standard deviation of the Wiener process, \n                    equal to sqrt(h) * diffusion\n    diff_mat     -- structure matrix for the diffusion coefficients,\n                    replaces the default uniform scaling \n    state_dim    -- keyword for parameter estimation, dimension of the\n                    dynamic state < dimension of full extended state\n    param_sample -- ParamSample dictionary for merging extended state with dx_params\n    ξ            -- random array size state_dim, can be defined in kwargs\n                    to provide a particular realization for method validation\n\nSee DataAssimilationBenchmarks.EnsembleKalmanSchemes.alternating_obs_operator for a discusssion of the γ parameter.\n\n\n\n\n\n","category":"type"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ArView-Tuple{Any}","page":"Global Types","title":"DataAssimilationBenchmarks.ArView","text":"function ArView(type)\n    Union{Array{T, 2}, SubArray{T, 2}} where T <: type\nend\n\nType constructor for union of Arrays and SubArrays for use within ensemble conditioning operations, integration schemes and other array operations.\n\n\n\n\n\n","category":"method"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ConM-Tuple{Any}","page":"Global Types","title":"DataAssimilationBenchmarks.ConM","text":"function ConM(type)\n    Union{UniformScaling{T}, Symmetric{T}} where T <: type\nend\n\nType union of conditioning matrix types, which are used for optimization routines in the transform method.\n\n\n\n\n\n","category":"method"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.CovM-Tuple{Any}","page":"Global Types","title":"DataAssimilationBenchmarks.CovM","text":"function CovM(type)\n    Union{UniformScaling{T}, Diagonal{T, Vector{T}},\n          Symmetric{T, Matrix{T}}} where T <: type\nend\n\nType constructor for union of covariance matrix types, for multiple dispatch based on their special characteristics as symmetric, positive definite operators.\n\n\n\n\n\n","category":"method"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.ParamDict-Tuple{Any}","page":"Global Types","title":"DataAssimilationBenchmarks.ParamDict","text":"function ParamDict(type)\n    Union{Dict{String, Array{T}}, Dict{String, Vector{T}}} where T <: type\nend\n\nType constructor for Dictionary of model parameters to be passed to derivative functions by name.  This allows one to pass both vector parameters (and scalars written as vectors), as well as matrix valued parameters such as diffusion arrays.\n\n\n\n\n\n","category":"method"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.TransM-Tuple{Any}","page":"Global Types","title":"DataAssimilationBenchmarks.TransM","text":"function TransM(type)\n    Union{Tuple{Symmetric{T,Array{T,2}},Array{T,1},Array{T,2}},\n          Tuple{Symmetric{T,Array{T,2}},Array{T,2},Array{T,2}}} where T <: type\nend\n\nType union constructor for tuples representing the ensemble update step with a right ensemble anomaly transformation, mean update weights and mean-preserving orthogonal transformation.\n\n\n\n\n\n","category":"method"},{"location":"home/DataAssimilationBenchmarks/#DataAssimilationBenchmarks.VecA-Tuple{Any}","page":"Global Types","title":"DataAssimilationBenchmarks.VecA","text":"function VecA(type)\n    Union{Vector{T}, SubArray{T, 1}} where T <: type\nend\n\nType constructor for union of Vectors and 1-D SubArrays.  This is utilzed  in order to pass columns of an ensemble maxtrix into integration schemes and related array operations.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SingleExperimentDriver/#SingleExperimentDriver","page":"SingleExperimentDriver","title":"SingleExperimentDriver","text":"","category":"section"},{"location":"submodules/experiments/SingleExperimentDriver/#SingleExperimentDriver-API","page":"SingleExperimentDriver","title":"SingleExperimentDriver API","text":"","category":"section"},{"location":"submodules/experiments/SingleExperimentDriver/","page":"SingleExperimentDriver","title":"SingleExperimentDriver","text":"While the above filter experiments and smoother experiments configure twin experiments, run them and save the outputs, the SingleExperimentDriver.jl and ParallelExperimentDriver.jl can be used as wrappers to run generic model settings for debugging and validation, or to use built-in Julia parallelism to run a collection experiments over a parameter grid. The SingleExperimentDriver.jl is primarily for debugging purposes with tools like BenchmarkTools.jl and Debugger.jl, so that standard inputs can be run with the experiment called with macros.","category":"page"},{"location":"submodules/experiments/SingleExperimentDriver/#Docstrings","page":"SingleExperimentDriver","title":"Docstrings","text":"","category":"section"},{"location":"submodules/experiments/SingleExperimentDriver/","page":"SingleExperimentDriver","title":"SingleExperimentDriver","text":"Modules = [DataAssimilationBenchmarks.SingleExperimentDriver]","category":"page"},{"location":"submodules/experiments/SingleExperimentDriver/#DataAssimilationBenchmarks.SingleExperimentDriver.exps","page":"SingleExperimentDriver","title":"DataAssimilationBenchmarks.SingleExperimentDriver.exps","text":"exps[\"Experiment_name\"][\"Parameter_settings\"]\n\nThis dictionary contains standard inputs for experiments, written as named tuples and stored hierarchically by experiment type.  These standard inputs are used in the package for for debugging, testing, benchmarking and profiling. Parallel submission scripts are used for performance on servers.\n\n\n\n\n\n","category":"constant"},{"location":"submodules/experiments/FilterExps/#FilterExps","page":"FilterExps","title":"FilterExps","text":"","category":"section"},{"location":"submodules/experiments/FilterExps/#FilterExps-API","page":"FilterExps","title":"FilterExps API","text":"","category":"section"},{"location":"submodules/experiments/FilterExps/","page":"FilterExps","title":"FilterExps","text":"The FilterExps.jl sub-module configures twin experiments using stored time series data as generated above for  efficiency when using the same base-line time series to generate possibly different experiment configurations. Experiment configurations are generated by","category":"page"},{"location":"submodules/experiments/FilterExps/","page":"FilterExps","title":"FilterExps","text":"filter_state(args::Tuple{String,String,Int64,Int64,Float64,Int64,Float64,Int64,Float64})\ntime_series, method, seed, nanl, obs_un, obs_dim, γ, N_ens, infl = args","category":"page"},{"location":"submodules/experiments/FilterExps/","page":"FilterExps","title":"FilterExps","text":"where time_series specifies the path to the .jld2 truth twin, method specifies the filter scheme, seed specifies the pseudo-random seed, nanl is the number of observation / analysis times to produce a posterior estimate for,  obs_un specifies the observation error standard deviation, assuming a uniform scaling observation error covariance, obs_dim specifies the dimension of the observation vector, γ specifies the level of the nonliearity in the alternating_obs_operator, N_ens specifies the ensemble size and infl specifies the (static) multiplicative inflation.","category":"page"},{"location":"submodules/experiments/FilterExps/","page":"FilterExps","title":"FilterExps","text":"Similar conventions follow for parameter estimation experiments","category":"page"},{"location":"submodules/experiments/FilterExps/","page":"FilterExps","title":"FilterExps","text":"filter_param(args::Tuple{String,String,Int64,Int64,Float64,Int64,\n                         Float64,Float64,Float64,Int64,Float64,Float64})\ntime_series, method, seed, nanl, obs_un, obs_dim,\nγ, param_err, param_wlk, N_ens, state_infl, param_infl = args","category":"page"},{"location":"submodules/experiments/FilterExps/","page":"FilterExps","title":"FilterExps","text":"with the exception of including the standard deviation, param_err, of the initial iid Gaussian draw of the parameter sample centered at the true value, the standard deviation, param_wlk, of the random walk applied to the parameter sample after each analysis and the multiplicative covariance inflation applied separately to the extended parameter states alone param_infl.","category":"page"},{"location":"submodules/experiments/FilterExps/#Docstrings","page":"FilterExps","title":"Docstrings","text":"","category":"section"},{"location":"submodules/experiments/FilterExps/","page":"FilterExps","title":"FilterExps","text":"Modules = [DataAssimilationBenchmarks.FilterExps]","category":"page"},{"location":"submodules/experiments/FilterExps/#DataAssimilationBenchmarks.FilterExps.filter_param-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :obs_un, :obs_dim, :γ, :p_err, :p_wlk, :N_ens, :s_infl, :p_infl), <:Tuple{String, String, Int64, Int64, Float64, Int64, Float64, Float64, Float64, Int64, Float64, Float64}}}","page":"FilterExps","title":"DataAssimilationBenchmarks.FilterExps.filter_param","text":"filter_param((time_series::String, method::String, seed::Int64, nanl::Int64, \n              obs_un::Float64, obs_dim::Int64, γ::Float64, p_err::Float64, p_wlk::Float64,\n              N_ens::Int64, s_infl::Float64, p_infl::Float64)::NamedTuple)\n\nFilter joint state-parameter estimation twin experiment.  Twin experiment parameters such as the observation dimension, observation uncertainty, data assimilation method, number of cycles, ensemble size etc. are specified in the arguments of the NamedTuple.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/FilterExps/#DataAssimilationBenchmarks.FilterExps.filter_state-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :obs_un, :obs_dim, :γ, :N_ens, :s_infl), <:Tuple{String, String, Int64, Int64, Float64, Int64, Float64, Int64, Float64}}}","page":"FilterExps","title":"DataAssimilationBenchmarks.FilterExps.filter_state","text":"filter_state((time_series::String, method::String, seed::Int64, nanl::Int64,\n              obs_un::Float64, obs_dim::Int64, γ::Float64, N_ens::Int64,\n              s_infl::Float64)::NamedTuple)\n\nFilter state estimation twin experiment.  Twin experiment parameters such as the observation dimension, observation uncertainty, data assimilation method, number of cycles, ensemble size  etc. are specified in the arguments of the NamedTuple.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SmootherExps/#SmootherExps","page":"SmootherExps","title":"SmootherExps","text":"","category":"section"},{"location":"submodules/experiments/SmootherExps/#SmootherExps-API","page":"SmootherExps","title":"SmootherExps API","text":"","category":"section"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"The SmootherExps.jl sub-module configures twin experiments using stored time series data as generated above for  efficiency when using the same base-line time series to generate possibly different experiment configurations. Experiment configurations are generated by function calls as with the filter experiments, but with the additional options of how the outer-loop is configured with a classic, single-iteration or the fully iterative Gauss-Newton style smoother. The parameters lag and shift specify how the data assimilation windows are translated in over the observation and analysis times.  The mda parameter is only applicable to the single-iteration and Gauss-Newton style smoothers, utlizing sequential multiple data assimilation.  Note, the single-iteration and fully iterative Gauss-Newton style smoothers are only defined for MDA compatible values of lag and shift where the lag is an integer multiple of the shift.","category":"page"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"Currently debugged and validated smoother experiment configurations include","category":"page"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"classic_state          -- classic EnKS style state estimation\nclassic_param          -- classic EnKS style state-parameter estimation\nsingle_iteration_state -- single-iteration EnKS state estimation\nsingle_iteration_param -- single-iteration EnKS state-parameter estimation\niterative_state        -- Gauss-Newton style state estimation\niterative_param        -- Gauss-Newton style state-parameter estimation","category":"page"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"Other techniques are still in debugging and validation.  Each of these takes an analysis type as used in the transform function in the EnsembleKalmanSchemes.jl sub-module, like the filter analyses in the filter experiments.","category":"page"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"All experiments are funcitonalized so that they can be called from an array of parameter values which will typically be varied with naive parallelism.  Relevant arguments and experimental results are dumped as a side effect to a dictionary in a JLD2. Experiments return their runtime in minutes.","category":"page"},{"location":"submodules/experiments/SmootherExps/#Docstrings","page":"SmootherExps","title":"Docstrings","text":"","category":"section"},{"location":"submodules/experiments/SmootherExps/","page":"SmootherExps","title":"SmootherExps","text":"Modules = [DataAssimilationBenchmarks.SmootherExps]","category":"page"},{"location":"submodules/experiments/SmootherExps/#DataAssimilationBenchmarks.SmootherExps.classic_param-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :lag, :shift, :obs_un, :obs_dim, :γ, :p_err, :p_wlk, :N_ens, :s_infl, :p_infl), <:Tuple{String, String, Int64, Int64, Int64, Int64, Float64, Int64, Float64, Float64, Float64, Int64, Float64, Float64}}}","page":"SmootherExps","title":"DataAssimilationBenchmarks.SmootherExps.classic_param","text":"classic_param((time_series::String, method::String, seed::Int64, nanl::Int64, lag::Int64,\n               shift::Int64, obs_un::Float64, obs_dim::Int64, γ::Float64, p_err::Float64,\n               p_wlk::Float64, N_ens::Int64, s_infl::Float64,\n               s_infl::Float64})::NamedTuple)\n\nClassic ensemble Kalman smoother joint state-parameter estimation twin experiment.  Twin experiment parameters such as the observation dimension, observation uncertainty, data assimilation method, number of cycles, ensemble size etc. are specified in the arguments. NOTE: the classic scheme does not use multiple data assimilation and we hard code mda=false in the function for consistency with other methods.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SmootherExps/#DataAssimilationBenchmarks.SmootherExps.classic_state-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :lag, :shift, :obs_un, :obs_dim, :γ, :N_ens, :s_infl), <:Tuple{String, String, Int64, Int64, Int64, Int64, Float64, Int64, Float64, Int64, Float64}}}","page":"SmootherExps","title":"DataAssimilationBenchmarks.SmootherExps.classic_state","text":"classic_state((time_series::String, method::String, seed::Int64, nanl::Int64, lag::Int64,\n               shift::Int64, obs_un::Float64, obs_dim::Int64, γ::Float64, N_ens::Int64, \n               s_infl::Float64)::NamedTuple)\n\nClassic ensemble Kalman smoother state estimation twin experiment.  Twin experiment parameters such as the observation dimension, observation uncertainty, data assimilation method, number of cycles, ensemble size etc. are specified in the arguments. NOTE: the classic scheme does not use multiple data assimilation and we hard code mda=false in the function for consistency with other methods.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SmootherExps/#DataAssimilationBenchmarks.SmootherExps.iterative_param-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :lag, :shift, :mda, :obs_un, :obs_dim, :γ, :p_err, :p_wlk, :N_ens, :s_infl, :p_infl), <:Tuple{String, String, Int64, Int64, Int64, Int64, Bool, Float64, Int64, Float64, Float64, Float64, Int64, Float64, Float64}}}","page":"SmootherExps","title":"DataAssimilationBenchmarks.SmootherExps.iterative_param","text":"iterative_param((time_series:String, method:String, seed::Int64, nanl::Int64, lag::Int64,\n                 shift::Int64, mda::Bool, obs_un::Float64, obs_dim::Int64, γ::Float64,\n                 p_err::Float64, p_wlk::Float64, N_ens::Int64,\n                 s_infl::Float64, p_infl::Float64})\n\n4DEnVAR joint state-parameter estimation twin experiment.  Twin experiment parameters such as the observation dimension, observation uncertainty, data assimilation method, number of cycles, ensemble size etc. are specified in the arguments.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SmootherExps/#DataAssimilationBenchmarks.SmootherExps.iterative_state-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :lag, :shift, :mda, :obs_un, :obs_dim, :γ, :N_ens, :s_infl), <:Tuple{String, String, Int64, Int64, Int64, Int64, Bool, Float64, Int64, Float64, Int64, Float64}}}","page":"SmootherExps","title":"DataAssimilationBenchmarks.SmootherExps.iterative_state","text":"iterative_state(args::Tuple{String,String,Int64,Int64,Int64,Int64,Bool,Float64, \n                            Int64,Float64,Int64,Float64})\n\n4DEnVAR state estimation twin experiment.  Twin experiment parameters such as the observation dimension, observation uncertainty, data assimilation method, number of cycles, ensemble size etc. are specified in the arguments.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SmootherExps/#DataAssimilationBenchmarks.SmootherExps.single_iteration_param-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :lag, :shift, :mda, :obs_un, :obs_dim, :γ, :p_err, :p_wlk, :N_ens, :s_infl, :p_infl), <:Tuple{String, String, Int64, Int64, Int64, Int64, Bool, Float64, Int64, Float64, Float64, Float64, Int64, Float64, Float64}}}","page":"SmootherExps","title":"DataAssimilationBenchmarks.SmootherExps.single_iteration_param","text":"single_iteration_param((time_series::String, method::String, seed:Int64, nanl::Int64,\n                        lag::Int64, shift::Int64, mda::Bool, obs_un::Float64,\n                        obs_dim::Int64, γ::Float64, p_err::Float64, p_wlk::Float64,\n                        N_ens::Int64, s_infl::Float64, p_infl::Float64)::NamedTuple)\n\nSIEnKS joint state-parameter estimation twin experiment.  Twin experiment parameters such as the observation dimension, observation uncertainty, data assimilation method, number of cycles, ensemble size etc. are specified in the arguments.\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/SmootherExps/#DataAssimilationBenchmarks.SmootherExps.single_iteration_state-Tuple{NamedTuple{(:time_series, :method, :seed, :nanl, :lag, :shift, :mda, :obs_un, :obs_dim, :γ, :N_ens, :s_infl), <:Tuple{String, String, Int64, Int64, Int64, Int64, Bool, Float64, Int64, Float64, Int64, Float64}}}","page":"SmootherExps","title":"DataAssimilationBenchmarks.SmootherExps.single_iteration_state","text":"single_iteration_state((time_series::String, method::String, seed::Int64, nanl::Int64,\n                        lag::Int64, shift::Int64, mda::Bool, obs_un::Float64,\n                        obs_dim::Int64, γ::Float64, N_ens::Int64,\n                        s_infl::Float64})::NamedTuple)\n\nSIEnKS state estimation twin experiment.  Twin experiment parameters such as the observation dimension, observation uncertainty, data assimilation method, number of cycles, ensemble size etc. are specified in the arguments.\n\n\n\n\n\n","category":"method"},{"location":"home/Getting Started/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"home/Getting Started/#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"The main module DataAssimilationBenchmarks.jl declares global types and wraps sub-modules including the core numerical solvers for ordinary and stochastic differential equations, solvers for data assimilation routines and the core process model code for running twin experiments with benchmark models. These methods can be run stand-alone in other programs by calling these functions from the DeSolvers, EnsembleKalmanSchemes, L96 and IEEE39bus sub-modules from this library. Future solvers and models will be added as sub-modules in the methods and models directories respectively.","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"In order to get the full functionality of this package you will need to install the dev version. This provides the access to edit all of the outer-loop routines for setting up twin experiments. These routines are defined in the modules in the experiments directory. The slurm_submit_scripts directory includes routines for parallel submission of experiments in Slurm. Data processing scripts and visualization scripts (written in Python with Matplotlib and Seaborn) are included in the \"analysis\" directory.","category":"page"},{"location":"home/Getting Started/#Installing-a-dev-package-from-the-Julia-General-registries","page":"Getting Started","title":"Installing a dev package from the Julia General registries","text":"","category":"section"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"In order to install the dev version to your Julia environment, you can use the following commands in the REPL","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"pkg> dev DataAssimilationBenchmarks","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"The installed version will be included in your","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"~/.julia/dev/","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"on Linux and the analogous directory with respect Windows and Mac systems. Alternatively, you can install this from the main Github branch directly as follows:","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"pkg> dev https://github.com/cgrudz/DataAssimilationBenchmarks.jl","category":"page"},{"location":"home/Getting Started/#Repository-structure","page":"Getting Started","title":"Repository structure","text":"","category":"section"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"The repository is structured as follows:","category":"page"},{"location":"home/Getting Started/","page":"Getting Started","title":"Getting Started","text":"<ul>\n  <li><code>src</code> - contains the main parent module</li>\n  <ul>\n\t\t<li><code>models</code> - contains code for defining the dynamic model equations in twin\n\t\texperiments.</li>\n\t\t<li><code>methods</code> - contains DA solvers and general numerical routines for running\n\t\ttwin experiments.</li>\n\t\t<li><code>experiments</code> - contains the outer-loop scripts that set up twin\n\t\texperiments.</li>\n\t\t<li><code>data</code> - this is an input / output directory for the inputs to and\n\t\touptuts fromexperiments.</li>\n\t\t<li><code>analysis</code> - contains auxilliary scripts for batch processing experiment\n\t\tresults and for plotting in Python.</li>\n\t</ul>\n  <li><code>scratch</code> - this is a storage directory for backups.</li>\n  <li><code>test</code> - contains test cases for the package.</li>\n\t<li><code>docs</code> - contains the documenter files.</li>\n</ul>","category":"page"},{"location":"submodules/analysis/PlotExperimentData/#Analysis","page":"PlotExperimentData","title":"Analysis","text":"","category":"section"},{"location":"submodules/analysis/PlotExperimentData/#Processing-experiment-outputs","page":"PlotExperimentData","title":"Processing experiment outputs","text":"","category":"section"},{"location":"submodules/analysis/PlotExperimentData/","page":"PlotExperimentData","title":"PlotExperimentData","text":"The analysis directory contains scripts for batch processing the outputs from experiments into time-averaged RMSE and spread and arranging these outputs in an array for plotting.  This should be modified based on the local paths to stored data.  This will try to load files based on parameter settings written in the name of the output .jld2 file and if this is not available, this will store Inf values in the place of missing data.","category":"page"},{"location":"submodules/analysis/PlotExperimentData/#Validating-results","page":"PlotExperimentData","title":"Validating results","text":"","category":"section"},{"location":"submodules/analysis/PlotExperimentData/","page":"PlotExperimentData","title":"PlotExperimentData","text":"Benchmark configurations for the above filtering and smoothing experiments are available in the open access article A fast, single-iteration ensemble Kalman smoother for sequential data assimilation, with details on the algorithm and parameter specifications discussed in the experiments section.  Performance of filtering and smoothing schemes should be validated versus the numerical results presented there for root mean square error and ensemble spread. Simple versions of these diagnostics are built for automatic testing of the filter and smoother experiments for state and parameter estimation in the L96-s model.  Further test cases are currently in development.  The deterministic Runge-Kutta and Euler scheme for ODEs are validated in the package tests, estimating the order of convergence with the least-squares log-10 line fit between step size and discretization error.  Test cases for the stochastic integration schemes are in development, but numerical results with these schemes can be validated versus the results in the open-access article  On the numerical integration of the Lorenz-96 model, with scalar additive noise, for benchmark twin experiments.","category":"page"},{"location":"submodules/experiments/ParallelExperimentDriver/#ParallelExperimentDriver","page":"ParallelExperimentDriver","title":"ParallelExperimentDriver","text":"","category":"section"},{"location":"submodules/experiments/ParallelExperimentDriver/#ParallelExperimentDriver-API","page":"ParallelExperimentDriver","title":"ParallelExperimentDriver API","text":"","category":"section"},{"location":"submodules/experiments/ParallelExperimentDriver/","page":"ParallelExperimentDriver","title":"ParallelExperimentDriver","text":"The ParallelExperimentDriver.jl is a simple parallel implementation, though currently lacks a soft-fail when numerical instability is encountered.  This means that if a single experiment configuration in the collection fails due to overflow, the entire collection will cancel.  A fix for this is being explored, but the recommendation is to use the slurm submit scripts below as templates for generating large parameter grid configurations and running them on servers.","category":"page"},{"location":"submodules/experiments/ParallelExperimentDriver/#Docstrings","page":"ParallelExperimentDriver","title":"Docstrings","text":"","category":"section"},{"location":"submodules/experiments/ParallelExperimentDriver/","page":"ParallelExperimentDriver","title":"ParallelExperimentDriver","text":"#@autodocs #Modules = [DataAssimilationBenchmarks.ParallelExperimentDriver] #","category":"page"},{"location":"submodules/methods/DeSolvers/#Differential-Equation-Solvers","page":"DeSolvers","title":"Differential Equation Solvers","text":"","category":"section"},{"location":"submodules/methods/DeSolvers/#API-for-differential-equation-solvers","page":"DeSolvers","title":"API for differential equation solvers","text":"","category":"section"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"Three general schemes are developed for ordinary and stochastic differential equations, the four-stage Runge-Kutta DataAssimilationBenchmarks.DeSolvers.rk4_step!, second order autonomous Taylor DataAssimilationBenchmarks.DeSolvers.tay2_step!, and the Euler-(Maruyama) DataAssimilationBenchmarks.DeSolvers.em_step! schemes. Because the second order Taylor-Stratonovich scheme relies specifically on the structure of the Lorenz-96 model with additive noise, this is included separately in the L96 sub-module.  The time steppers over-write the value of the model state x in place as a vector or a view of an array for efficient ensemble integration.  This follows the convention in data assimilation of the extended state formalism for parameter estimation where the parameter sample should be included as trailing state variables in the columns of the ensemble array.  If","category":"page"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"true == haskey(kwargs, \"param_sample\")","category":"page"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"the state_dim parameter specifies the dimension of the dynamical states and creates a view of the vector x including all entries up to this index.  The remaining entries in the state vector x will be passed to the dx_dt function in a dictionary merged with the dx_params  ParamDict, according to the param_sample indices and parameter values specified in param_sample. The parameter sample values will remain unchanged by the time stepper when the dynamical state entries in x are over-written in place.","category":"page"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"Setting diffusion > 0.0 introduces additive noise to the dynamical system.  The main DataAssimilationBenchmarks.DeSolvers.rk4_step! has convergence on order 4.0 when diffusion is equal to zero, and both strong and weak convergence on order 1.0 when stochasticity is introduced.  This is the recommended out-of-the-box solver for any generic DA simulation for the statistically robust performance, versus Euler-(Maruyama).  When specifically generating the truth-twin for the Lorenz-96 model with additive noise, this should be performed with the DataAssimilationBenchmarks.L96.l96s_tay2_step!, while the ensemble should be generated with the DataAssimilationBenchmarks.DeSolvers.rk4_step!.  See the benchmarks on the L96-s model for a full discussion of statistically robust model configurations.","category":"page"},{"location":"submodules/methods/DeSolvers/#Methods","page":"DeSolvers","title":"Methods","text":"","category":"section"},{"location":"submodules/methods/DeSolvers/","page":"DeSolvers","title":"DeSolvers","text":"Modules = [DataAssimilationBenchmarks.DeSolvers]","category":"page"},{"location":"submodules/methods/DeSolvers/#DataAssimilationBenchmarks.DeSolvers.em_step!-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Dict{String, Any}}} where T<:Real","page":"DeSolvers","title":"DataAssimilationBenchmarks.DeSolvers.em_step!","text":"em_step!(x::VecA, t::Float64, kwargs::StepKwargs)\n\nThis will propagate the state x one step forward by Euler-Maruyama scheme. Arguments are given as:\n\n    x      -- type [`VecA`](@ref) of model states possibly including static\n              parameter values\n    t      -- time value for present model state\n    kwargs -- includes state time derivative dx_dt, paramters for the dx_dt\n              and optionals\n\nwhere kwargs is type StepKwargs Details on this scheme are available in the manuscript Grudzien, C. et al.: (2020).\n\nThis overwrites the input in-place and returns the updated\n\nreturn x\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/DeSolvers/#DataAssimilationBenchmarks.DeSolvers.rk4_step!-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Dict{String, Any}}} where T<:Real","page":"DeSolvers","title":"DataAssimilationBenchmarks.DeSolvers.rk4_step!","text":"rk4_step!(x::VecA(T), t::Float64, kwargs::StepKwargs) where T <: Real\n\nStep of integration rule for 4 stage Runge-Kutta as discussed in Grudzien et al. 2020. The rule has strong convergence order 1.0 for generic SDEs and order 4.0 for ODEs. Arguments are given as:\n\n    x      -- type [`VecA`](@ref) of model states possibly including static\n              parameter values\n    t      -- time value for present model state\n    kwargs -- includes state time derivative dx_dt, paramters for the dx_dt\n              and optionals\n\nwhere kwargs is type StepKwargs. Details on this scheme are available in the manuscript Grudzien, C. et al. (2020).\n\nThis method overwrites the input in-place and returns the updated\n\nreturn x\n\n\n\n\n\n","category":"method"},{"location":"submodules/methods/DeSolvers/#DataAssimilationBenchmarks.DeSolvers.tay2_step!-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Dict{String, Any}}} where T<:Real","page":"DeSolvers","title":"DataAssimilationBenchmarks.DeSolvers.tay2_step!","text":"tay2_step!(x::VecA, t::Float64, kwargs::StepKwargs)\n\nDeterministic second order autonomous Taylor method for step size h and state vector x. Time variable t is just a dummy variable, where this method is not defined for non-autonomous dynamics.  Arguments are given as:\n\n    x      -- type [`VecA`](@ref) of model states possibly including static\n              parameter values\n    kwargs -- includes state time derivative dx_dt, paramters for the dx_dt\n              and optionals\n\nwhere kwargs is type StepKwargs.\n\nThis overwrites the input in-place and returns the updated\n\nreturn x\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/Slurm/#Slurm","page":"Slurm","title":"Slurm","text":"","category":"section"},{"location":"submodules/experiments/Slurm/#SlurmExperimentDrivers","page":"Slurm","title":"SlurmExperimentDrivers","text":"","category":"section"},{"location":"submodules/experiments/Slurm/","page":"Slurm","title":"Slurm","text":"These are a collection of templates for automatically generating an array of parameter tuples to pass to the experiment functions as configurations.  This uses a simple looping strategy, while writing out the configurations to a .jld2 file to be read by the parallel experiment driver within the slurm_submit_scripts directory.  The paralell submit script  should be run within the slurm_submit_scripts directory to specify the correct paths to the time series data, the experiment configuration data and to save to the correct output directory, specified by the method used.","category":"page"},{"location":"submodules/experiments/GenerateTimeSeries/#GenerateTimeSeries","page":"GenerateTimeSeries","title":"GenerateTimeSeries","text":"","category":"section"},{"location":"submodules/experiments/GenerateTimeSeries/","page":"GenerateTimeSeries","title":"GenerateTimeSeries","text":"GenerateTimeSeries is a sub-module used to generate a time series for a twin experiment based on tuneable model configuration parameters. Example syntax for the configuration of a time series is as follows, where arguments are defined in a named tuple to be passed to the specific experiment function:","category":"page"},{"location":"submodules/experiments/GenerateTimeSeries/","page":"GenerateTimeSeries","title":"GenerateTimeSeries","text":"    (seed::Int64, h::Float64, state_dim::Int64, tanl::Float64, nanl::Int64, spin::Int64,\n     diffusion::Float64)::NamedTuple)","category":"page"},{"location":"submodules/experiments/GenerateTimeSeries/","page":"GenerateTimeSeries","title":"GenerateTimeSeries","text":"The seed argument specifies initial condition for the pseudo-random number generator on which various simulation settings will depend – simulations will be reproduceable with the same seed value.  The numerical integration step size is given by the argument h which controls the discretization error of the numerically simulated experiment. The size of the Lorenz-96 system scales with the state_dim argument, though other models such as the IEEE39bus model are of pre-defined size. The length of continuous time units between sequential observations is controlled with the tanl (time-between-analysis) argument which defines the frequency of pseudo data outputs. The number of observations / analyses to be saved is controlled with the nanl (number-of-analyses) argument.  The length of the spin-up for the integration of the dynamical system solution to guarantee a stationary observation generating process is controlled with the spin argument. The diffusion parameter determining the intensity of the random perturbations is controlled with the diffusion argument. Results are saved in .jld2 format in the data directory to be called by filter / smoother experiments cycling over the pseudo-observations.","category":"page"},{"location":"submodules/experiments/GenerateTimeSeries/#Docstrings","page":"GenerateTimeSeries","title":"Docstrings","text":"","category":"section"},{"location":"submodules/experiments/GenerateTimeSeries/","page":"GenerateTimeSeries","title":"GenerateTimeSeries","text":"Modules = [DataAssimilationBenchmarks.GenerateTimeSeries]","category":"page"},{"location":"submodules/experiments/GenerateTimeSeries/#DataAssimilationBenchmarks.GenerateTimeSeries.IEEE39bus_time_series-Tuple{NamedTuple{(:seed, :h, :tanl, :nanl, :spin, :diffusion), <:Tuple{Int64, Float64, Float64, Int64, Int64, Float64}}}","page":"GenerateTimeSeries","title":"DataAssimilationBenchmarks.GenerateTimeSeries.IEEE39bus_time_series","text":"IEEE39bus_time_series((seed::Int64, h:Float64, tanl::Float64, nanl::Int64, spin::Int64,\n                       diffusion::Float64)::NamedTuple)\n\nSimulate a \"free run\" time series of the IEEE39 Bus Swing Equation Model for generating an observation process and truth twin for data assimilation twin experiments. Output from the experiment is saved in a dictionary of the form,\n\nDict{String, Any}(\n                  \"seed\" => seed,\n                  \"h\" => h,\n                  \"diffusion\" => diffusion,\n                  \"diff_mat\" => diff_mat,\n                  \"dx_params\" => dx_params, \n                  \"tanl\" => tanl,\n                  \"nanl\" => nanl,\n                  \"spin\" => spin,\n                  \"obs\" => obs,\n                  \"model\" => \"IEEE39bus\"\n                 )\n\nWhere the file name is written dynamically according to the selected parameters as follows:\n\n\"IEEE39bus_time_series_seed_\" * lpad(seed, 4, \"0\") * \n\"_diff_\" * rpad(diffusion, 5, \"0\") * \n\"_tanl_\" * rpad(tanl, 4, \"0\") * \n\"_nanl_\" * lpad(nanl, 5, \"0\") * \n\"_spin_\" * lpad(spin, 4, \"0\") * \n\"_h_\" * rpad(h, 5, \"0\") * \n\".jld2\"\n\n\n\n\n\n","category":"method"},{"location":"submodules/experiments/GenerateTimeSeries/#DataAssimilationBenchmarks.GenerateTimeSeries.L96_time_series-Tuple{NamedTuple{(:seed, :h, :state_dim, :tanl, :nanl, :spin, :diffusion, :F), <:Tuple{Int64, Float64, Int64, Float64, Int64, Int64, Float64, Float64}}}","page":"GenerateTimeSeries","title":"DataAssimilationBenchmarks.GenerateTimeSeries.L96_time_series","text":"L96_time_series((seed::Int64, h::Float64, state_dim::Int64, tanl::Float64, nanl::Int64,\n                 spin::Int64, diffusion::Float64, F::Float64)::NamedTuple)\n\nSimulate a \"free run\" time series of the Lorenz-96 model model  for generating an observation process and truth twin for data assimilation twin experiments. Output from the experiment is saved in a dictionary of the form,\n\nDict{String, Any}(\n                  \"seed\" => seed,\n                  \"h\" => h,\n                  \"diffusion\" => diffusion, \n                  \"dx_params\" => dx_params, \n                  \"tanl\" => tanl,\n                  \"nanl\" => nanl,\n                  \"spin\" => spin,\n                  \"state_dim\" => state_dim,\n                  \"obs\" => obs,\n                  \"model\" => \"L96\"\n                 )\n\nWhere the file name is written dynamically according to the selected parameters as follows:\n\n\"L96_time_series_seed_\" * lpad(seed, 4, \"0\") * \n\"_dim_\" * lpad(state_dim, 2, \"0\") * \n\"_diff_\" * rpad(diffusion, 5, \"0\") * \n\"_F_\" * lpad(F, 4, \"0\") * \n\"_tanl_\" * rpad(tanl, 4, \"0\") * \n\"_nanl_\" * lpad(nanl, 5, \"0\") * \n\"_spin_\" * lpad(spin, 4, \"0\") * \n\"_h_\" * rpad(h, 5, \"0\") * \n\".jld2\"\n\n\n\n\n\n","category":"method"},{"location":"submodules/models/IEEE39bus/#IEEE39-Bus-Swing-Equation-Model","page":"IEEE39bus","title":"IEEE39 Bus Swing Equation Model","text":"","category":"section"},{"location":"submodules/models/IEEE39bus/","page":"IEEE39bus","title":"IEEE39bus","text":"Modules = [DataAssimilationBenchmarks.IEEE39bus]","category":"page"},{"location":"submodules/models/IEEE39bus/#DataAssimilationBenchmarks.IEEE39bus.dx_dt-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Union{Dict{String, Array{T1}}, Dict{String, Vector{T1}}} where T1<:T}} where T<:Real","page":"IEEE39bus","title":"DataAssimilationBenchmarks.IEEE39bus.dx_dt","text":"dx_dt(x::VecA(T), t::Float64, dx_params::ParamDict(T)) where T <: Real\n\nTime derivative of the phase and fequency of the effective-network swing equation model. Input x is a 2 n_g VecA of the phase and fequency at each of the n_g generator buses. The input dx_params of type ParamDict containing system parameters to be passed to the integration scheme.  The system is currenty defined autonomously to be run as an SDE, noise perturbed steady state.\n\n\n\n\n\n","category":"method"},{"location":"home/Introduction/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"home/Introduction/#Statement-of-purpose","page":"Introduction","title":"Statement of purpose","text":"","category":"section"},{"location":"home/Introduction/","page":"Introduction","title":"Introduction","text":"The purpose of this package is to provide a research framework for the theoretical development and empirical validation of novel data assimilation techniques. While analytical proofs can be derived for classical methods such as the Kalman filter in linear-Gaussian dynamics, most currently developed DA techniques are designed for estimation in nonlinear, non-Gaussian models where no analytical solution may exist.  Novel data assimilation methods, therefore, must be studied with rigorous numerical simulation in standard test-cases to demonstrate the effectiveness and computational performance. Pursuant to proposing a novel DA method, one should likewise compare the performance of a proposed scheme with other standard methods within the same class of estimators.","category":"page"},{"location":"home/Introduction/","page":"Introduction","title":"Introduction","text":"This package implements a variety of standard data assimilation algorithms, including widely used performance modifications that are used in practice to tune these estimators. Standard libraries exist for full-scale DA system research and development, e.g., the Data Assimilation Research Testbed (DART), but there are fewer standard options for theoretical research and algorithm development in simple test systems. DataAssimilationBenchmarks.jl provides one framework for studying ensemble-based filters and sequential smoothers that are commonly used in online, geoscientific prediction settings.","category":"page"},{"location":"home/Introduction/#Validated-methods-currently-in-use","page":"Introduction","title":"Validated methods currently in use","text":"","category":"section"},{"location":"home/Introduction/","page":"Introduction","title":"Introduction","text":"For a discussion of the below methods and benchmarks for their validation, please see the manuscript A fast, single-iteration ensemble Kalman smoother for sequential data assimilation.","category":"page"},{"location":"home/Introduction/","page":"Introduction","title":"Introduction","text":"<table>\n<tr>\n\t<th>Estimator / implemented techniques</th>\n\t<th>Tuned multiplicative inflation</th>\n\t<th>Adaptive inflation, finite-size formalism (perfect model dual / primal)</th>\n\t<th>Adaptive inflation, finite-size formalism (imperfect model)</th>\n\t<th>Linesearch</th>\n\t<th>Localization / Hybridization</th>\n\t<th>Multiple data assimilation (general shift and lag)</th>\n</tr>\n<tr>\n  <td> ETKF </td>\n\t<td> X  </td>\n\t<td> X  </td>\n\t<td>    </td>\n\t<td> NA </td>\n\t<td>    </td>\n\t<td> NA </td>\n</tr>\n<tr>\n  <td> MLEF, transform / bundle variants</td>\n\t<td> X  </td>\n\t<td> X  </td>\n\t<td>    </td>\n\t<td> X  </td>\n\t<td>    </td>\n\t<td> NA </td>\n</tr>\n<tr>\n  <td> ETKS</td>\n\t<td> X  </td>\n\t<td> X  </td>\n\t<td>    </td>\n\t<td> NA </td>\n\t<td>    </td>\n\t<td> NA </td>\n</tr>\n<tr>\n  <td> MLES, transform / bundle variants</td>\n\t<td> X  </td>\n\t<td> X  </td>\n\t<td>    </td>\n\t<td> X  </td>\n\t<td>    </td>\n\t<td> NA </td>\n</tr>\n<tr>\n  <td>SIEnKS, perturbed obs / ETKF / MLEF variants</td>\n\t<td> X </td>\n\t<td> X </td>\n\t<td>   </td>\n\t<td> X </td>\n\t<td>   </td>\n\t<td> X </td>\n</tr>\n<tr>\n  <td>Gauss-Newton IEnKS, transform / bundle variants</td>\n\t<td> X </td>\n\t<td> X </td>\n\t<td>   </td>\n\t<td>   </td>\n\t<td>   </td>\n\t<td> X </td>\n</tr>\n</table>","category":"page"},{"location":"submodules/analysis/ProcessExperimentData/#Analysis","page":"ProcessExperimentData","title":"Analysis","text":"","category":"section"},{"location":"submodules/analysis/ProcessExperimentData/#Processing-experiment-outputs","page":"ProcessExperimentData","title":"Processing experiment outputs","text":"","category":"section"},{"location":"submodules/analysis/ProcessExperimentData/","page":"ProcessExperimentData","title":"ProcessExperimentData","text":"The analysis directory contains scripts for batch processing the outputs from experiments into time-averaged RMSE and spread and arranging these outputs in an array for plotting.  This should be modified based on the local paths to stored data.  This will try to load files based on parameter settings written in the name of the output .jld2 file and if this is not available, this will store Inf values in the place of missing data.","category":"page"},{"location":"submodules/analysis/ProcessExperimentData/#Validating-results","page":"ProcessExperimentData","title":"Validating results","text":"","category":"section"},{"location":"submodules/analysis/ProcessExperimentData/","page":"ProcessExperimentData","title":"ProcessExperimentData","text":"Benchmark configurations for the above filtering and smoothing experiments are available in the open access article A fast, single-iteration ensemble Kalman smoother for sequential data assimilation, with details on the algorithm and parameter specifications discussed in the experiments section.  Performance of filtering and smoothing schemes should be validated versus the numerical results presented there for root mean square error and ensemble spread. Simple versions of these diagnostics are built for automatic testing of the filter and smoother experiments for state and parameter estimation in the L96-s model.  Further test cases are currently in development.  The deterministic Runge-Kutta and Euler scheme for ODEs are validated in the package tests, estimating the order of convergence with the least-squares log-10 line fit between step size and discretization error.  Test cases for the stochastic integration schemes are in development, but numerical results with these schemes can be validated versus the results in the open-access article  On the numerical integration of the Lorenz-96 model, with scalar additive noise, for benchmark twin experiments.","category":"page"},{"location":"#Description","page":"Home","title":"Description","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is a data assimilation research code base with an emphasis on prototyping, testing and validating sequential filters and smoothers in toy model twin experiments. This code is meant to be performant in the sense that large hyper-parameter discretizations can be explored to determine hyper-parameter sensitivity and reliability of results across different experimental regimes, with parallel implementations in native Julia distributed computing and using workload managers such as Slurm.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package currently includes code for developing and testing data assimilation schemes in the L96-s model and the IEEE 39 bus test case in the form of the effective network model model equations. New toy models and data assimilation schemes are in continuous development in the development branch.  Currently validated techniques are available in the master branch.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package supported the development of all numerical results and benchmark simulations in the pre-print A fast, single-iteration ensemble Kalman smoother for sequential data assimilation available currently in open review in Geoscientific Model Development.","category":"page"},{"location":"submodules/models/L96/#Lorenz-96-model","page":"L96","title":"Lorenz-96 model","text":"","category":"section"},{"location":"submodules/models/L96/","page":"L96","title":"L96","text":"Modules = [DataAssimilationBenchmarks.L96]","category":"page"},{"location":"submodules/models/L96/#DataAssimilationBenchmarks.L96.compute_α_ρ-Tuple{Int64}","page":"L96","title":"DataAssimilationBenchmarks.L96.compute_α_ρ","text":"compute_α_ρ(p::Int64)\n\nComputes auxiliary functions for the 2nd order Taylor-Stratonovich expansion. The constants α and ρ need to be computed once, only as a function of the order of truncation of the Fourier series, the argument p, for the integration method.  These constants are then supplied as arguments to l96s_tay2_step! in kwargs. See l96s_tay2_step! for the interpretation and usage of these constants.\n\nreturn α(p)::Float64, ρ(p)::Float64\n\n\n\n\n\n","category":"method"},{"location":"submodules/models/L96/#DataAssimilationBenchmarks.L96.dx_dt-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Union{Dict{String, Array{T1}}, Dict{String, Vector{T1}}} where T1<:T}} where T<:Real","page":"L96","title":"DataAssimilationBenchmarks.L96.dx_dt","text":"dx_dt(x::VecA(T), t::Float64, dx_params::ParamDict(T)) where T <: Real\n\nTime derivative for Lorenz-96 model, x is a  model state of size state_dim and type VecA, t is a dummy time argument for consistency with integration methods, dx_params is of type ParamDict which is called for the forcing parameter.\n\nReturns time derivative of the state vector\n\nreturn dx\n\n\n\n\n\n","category":"method"},{"location":"submodules/models/L96/#DataAssimilationBenchmarks.L96.jacobian-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Union{Dict{String, Array{T1}}, Dict{String, Vector{T1}}} where T1<:T}} where T<:Real","page":"L96","title":"DataAssimilationBenchmarks.L96.jacobian","text":"jacobian(x::VecA(T), t::Float64, dx_params::ParamDict(T)) where T <: Real\n\nComputes the Jacobian of Lorenz-96 about the state x of type VecA. The time variable t is a dummy variable for consistency with integration methods, dx_params is of type ParamDict which is called for the forcing parameter. Note that this is designed to load entries in a zeros array and return a sparse array to make a compromise between memory and computational resources.\n\nreturn sparse(dxF)\n\n\n\n\n\n","category":"method"},{"location":"submodules/models/L96/#DataAssimilationBenchmarks.L96.l96s_tay2_step!-Union{Tuple{T}, Tuple{Union{Vector{T1}, SubArray{T1, 1}} where T1<:T, Float64, Dict{String, Any}}} where T<:Real","page":"L96","title":"DataAssimilationBenchmarks.L96.l96s_tay2_step!","text":"l96s_tay2_step!(x::VecA(T), t::Float64, kwargs::StepKwargs) where T <: Real\n\nOne step of integration rule for l96 second order taylor rule The constants ρ and α are to be computed with compute_α_ρ, depending only on p, and supplied for all steps. This is the general formulation which includes, e.g., dependence on the truncation of terms in the auxilliary function C with respect to the parameter p.  In general, truncation at p=1 is all that is necessary for order 2.0 convergence.\n\nThis method is derived in Grudzien, C. et al. (2020). NOTE: this Julia version still pending validation as in the manuscript\n\nreturn x\n\n\n\n\n\n","category":"method"},{"location":"submodules/models/L96/#DataAssimilationBenchmarks.L96.mod_indx!-Tuple{Int64, Int64}","page":"L96","title":"DataAssimilationBenchmarks.L96.mod_indx!","text":"mod_indx!(indx::Int64, dim::Int64)\n\nAuxiliary function to return state vector indices for the Lorenz-96 model, where indx is taken mod dim.  Mod zero is replaced with dim for indexing in Julia state vectors.\n\n\n\n\n\n","category":"method"}]
}
